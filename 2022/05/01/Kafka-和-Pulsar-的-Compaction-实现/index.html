<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="format-detection" content="telephone=no"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black"><link rel="icon" href="/images/icons/favicon-16x16.png?v=2.6.2" type="image/png" sizes="16x16"><link rel="icon" href="/images/icons/favicon-32x32.png?v=2.6.2" type="image/png" sizes="32x32"><meta name="google-site-verification" content="hnyb1jnM5Q6co65Dc7FMFxsxfL0wQ_aH1"><meta name="msvalidate.01" content="F2FFFBA1A6155C91A31EAC77F525BBD5"><meta name="baidu-site-verification" content="code-v7NaUITwkJ"><meta name="360-site-verification" content="cd75d354b11109d6f9f4ed94aff26cd6"><meta name="description" content="本文主要对 Kafka 和 Pulsar 的 Log Compaction 原理进行介绍，并以我的理解进行简单的对比说明。 &lt;– more –&gt; 在 Kafka 和 Pulsar 中，都具备 Log Campaction（日志挤压）的能力，Compaction 不同于 Log Compression（日志压缩），Compaction 是指将 Topic 历史日志中相同 Key 的消息只"><meta property="og:type" content="article"><meta property="og:title" content="Kafka 和 Pulsar 的 Compaction 实现"><meta property="og:url" content="http://fxbing.github.io/2022/05/01/Kafka-%E5%92%8C-Pulsar-%E7%9A%84-Compaction-%E5%AE%9E%E7%8E%B0/index.html"><meta property="og:site_name" content="小兵的博客"><meta property="og:description" content="本文主要对 Kafka 和 Pulsar 的 Log Compaction 原理进行介绍，并以我的理解进行简单的对比说明。 &lt;– more –&gt; 在 Kafka 和 Pulsar 中，都具备 Log Campaction（日志挤压）的能力，Compaction 不同于 Log Compression（日志压缩），Compaction 是指将 Topic 历史日志中相同 Key 的消息只"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://s3.bmp.ovh/imgs/2022/04/29/52b607617aa123f4.png"><meta property="article:published_time" content="2022-05-01T08:34:17.000Z"><meta property="article:modified_time" content="2022-05-01T08:45:11.637Z"><meta property="article:author" content="fxbing"><meta property="article:tag" content="Pulsar"><meta property="article:tag" content="kafka"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://s3.bmp.ovh/imgs/2022/04/29/52b607617aa123f4.png"><title>Kafka 和 Pulsar 的 Compaction 实现 | 小兵的博客</title><link ref="canonical" href="http://fxbing.github.io/2022/05/01/Kafka-%E5%92%8C-Pulsar-%E7%9A%84-Compaction-%E5%AE%9E%E7%8E%B0/"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.12.1/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/index.css?v=2.6.2"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="dns-prefetch" href="https://hm.baidu.com"><script src="https://www.googletagmanager.com/gtag/js?id=139855287" async></script><script>function gtag(){dataLayer.push(arguments)}"localhost"!==window.location.hostname&&(window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","139855287"))</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?e195e7c765ecde120b81d5afafa26e4b",e.async=!0;var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>var Stun=window.Stun||{},CONFIG={root:"/",algolia:void 0,assistSearch:void 0,fontIcon:{prompt:{success:"fas fa-check-circle",info:"fas fa-arrow-circle-right",warning:"fas fa-exclamation-circle",error:"fas fa-times-circle"},copyBtn:"fas fa-copy"},sidebar:{offsetTop:"20px",tocMaxDepth:6},header:void 0,postWidget:{endText:!0},nightMode:{enable:!0},back2top:{enable:!0},codeblock:{style:"carbon",highlight:"ocean",wordWrap:!1},reward:!1,fancybox:!1,zoomImage:{gapAside:"20px"},galleryWaterfall:void 0,lazyload:!1,pjax:void 0,externalLink:{icon:{enable:!0,name:"fas fa-external-link-alt"}},shortcuts:void 0,prompt:{copyButton:"复制",copySuccess:"复制成功",copyError:"复制失败"},sourcePath:{js:"js",css:"css",images:"images"}};window.CONFIG=CONFIG</script><meta name="generator" content="Hexo 5.4.0"></head><body><div class="container" id="container"><header class="header" id="header"><div class="header-inner header-inner--height header-inner--bgcolor"><nav class="header-nav header-nav--sticky"><div class="header-nav-inner"><div class="header-nav-menubtn"><i class="fas fa-bars"></i></div><div class="header-nav-menu"><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/"><span class="header-nav-menu-item__icon"><i class="fas fa-home"></i></span><span class="header-nav-menu-item__text">首页</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/archives/"><span class="header-nav-menu-item__icon"><i class="fas fa-folder-open"></i></span><span class="header-nav-menu-item__text">归档</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/tags/"><span class="header-nav-menu-item__icon"><i class="fas fa-tags"></i></span><span class="header-nav-menu-item__text">标签</span></a></div><div class="header-nav-menu-item"><a class="header-nav-menu-item__link" href="/about/"><span class="header-nav-menu-item__icon"><i class="fas fa-user"></i></span><span class="header-nav-menu-item__text">关于</span></a></div></div><div class="header-nav-mode"><div class="mode"><div class="mode-track"><span class="mode-track-moon"></span><span class="mode-track-sun"></span></div><div class="mode-thumb"></div></div></div></div></nav></div></header><main class="main" id="main"><div class="main-inner"><div class="content-wrap" id="content-wrap"><div class="content" id="content"><div id="is-post"></div><div class="post"><header class="post-header"><h1 class="post-title">Kafka 和 Pulsar 的 Compaction 实现</h1><div class="post-meta"><span class="post-meta-item post-meta-item--createtime"><span class="post-meta-item__icon"><i class="far fa-calendar-plus"></i></span><span class="post-meta-item__info">发表于</span><span class="post-meta-item__value">2022-05-01</span></span><span class="post-meta-item post-meta-item--updatetime"><span class="post-meta-item__icon"><i class="far fa-calendar-check"></i></span><span class="post-meta-item__info">更新于</span><span class="post-meta-item__value">2022-05-01</span></span></div></header><div class="post-body"><p>本文主要对 Kafka 和 Pulsar 的 Log Compaction 原理进行介绍，并以我的理解进行简单的对比说明。</p><p>&lt;– more –&gt;</p><p>在 Kafka 和 Pulsar 中，都具备 Log Campaction（日志挤压）的能力，Compaction 不同于 Log Compression（日志压缩），Compaction 是指将 Topic 历史日志中相同 Key 的消息只保留最新的一条，而 Compression 是指消息维度利用各种压缩算法（如：gzip、lz4、zstd等）减小消息大小但不改变消息内容。Compaction 的使用场景的特点：一是消息有 key，二是相同 key 的消息只关心最新的内容，例如：记录每支股票价格变动的 Topic，股票名称设置为 key，股票价格设置为 value，一般只关心股票的最新价格。在这种场景下，配置 Compaction 可以让 Topic 存储的数据更少，从而在需要全量读取 Topic 内容时速度更快。</p><h2 id="Kafka-Log-Compaction"><a href="#Kafka-Log-Compaction" class="heading-link"><i class="fas fa-link"></i></a><a href="#Kafka-Log-Compaction" class="headerlink" title="Kafka Log Compaction"></a>Kafka Log Compaction</h2><blockquote><p>本文介绍基于 Kafka 2.8，并且忽略了幂等消息、事务消息的相关处理逻辑，如有兴趣，可以自行阅读源码了解。</p></blockquote><p>在 Kafka 中，Topic 配置 <code>cleanup.policy</code>用来控制 Topic 的数据清理策略，该配置的可选值有两个：一个是<code>delete</code>，表示 Topic 中数据超过保留时间或保留大小限制时，直接删除最旧的数据；另一个是<code>compact</code>，表示对于 Topic 中的旧数据（非 Active Segment 中的数据）执行挤压，一定范围内，对于 key 相同（没有 key 的消息会被删除）的消息，只保留最新的一条。对于每个 Topic 可以选择一种清理策略进行配置，也可以同时配置两种策略。本文介绍的是 <code>compact</code>这个策略，在 Kafka 使用过程中，用来存放 commit offset 信息的的内部 Topic:<code>__consumer_offsets</code> 会被配置为该策略，普通 Topic 一般很少使用。</p><h3 id="实现原理"><a href="#实现原理" class="heading-link"><i class="fas fa-link"></i></a><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p>对于一台 Kafka Broker， Log Compaction 的主要流程如下：</p><ol><li>创建 LogCleaner，启动配置指定数量的 CleanerThread，负责该 Broker 的 Log Compaction。</li><li>每个 CleanerThread 循环执行日志清理工作，循环过程如下：<ol><li>寻找一个待清理的 TopicPartition。</li><li>遍历该TopicPartition 中所有待清理的 Segment，构造 OffsetMap 记录每个 key 最新的 offset 及对应的消息时间。</li><li>对该TopicPartition 中所有待清理的 Segment 进行分组，保证每组 Segment 的 Log 文件总大小和 Index 文件总大小不会超过 LogConfig 允许的范围并且每组 Segment 的 offset 极差不会超过<code>Int.MaxValue</code>（Kafka 中 Segment 内的相对 offset 为整型，这个检查是为了避免相对 offset 溢出）。</li><li>将 Segment 按照分好的组进行清理，每一组 Segment 聚合为一个新的 Segment。每组 Segment 的清理过程为：创建一个新的 Segment，然后根据 OffsetMap 中记录的信息选择需要保留的消息，存入新 Segment，最后使用新 Segment 覆盖这一组旧 Segment。</li><li>对于所有已经执行完成 Compaction 流程并且<code>cleanup.policy</code>配置包含<code>compact</code>策略的 Log 进行删除，本次删除不是前面用一个新 Segment 替换一组旧 Segment 中的删除，而是调用<code>Log.deleteOldSegments</code>。该方法会删除<code>LogStartOffset</code>之前的所有 Segment，如果<code>cleanup.policy</code>配置同时还包含<code>delete</code>策略，也会删除超过保留时间或保留大小限制的 Segment。</li></ol></li></ol><h3 id="详细说明"><a href="#详细说明" class="heading-link"><i class="fas fa-link"></i></a><a href="#详细说明" class="headerlink" title="详细说明"></a>详细说明</h3><p>下面以Q&amp;A的方式介绍日志清理的细节和逻辑：</p><h4 id="多个-CleanerThread-是如何保证-Compaction-过程线程安全的"><a href="#多个-CleanerThread-是如何保证-Compaction-过程线程安全的" class="heading-link"><i class="fas fa-link"></i></a><a href="#多个-CleanerThread-是如何保证-Compaction-过程线程安全的" class="headerlink" title="多个 CleanerThread 是如何保证 Compaction 过程线程安全的?"></a>多个 CleanerThread 是如何保证 Compaction 过程线程安全的?</h4><p>Kafka 中 Log Compaction 的实现主要是<code>LogCleaner</code>和<code>LogCleanerManager</code>两个类，<code>LogCleaner</code>是 Compaction 工作的主类，负责整体的工作流程，<code>LogCleanerManager</code>负责 Compaction 状态机的管理。所有状态如下：</p><p><img src="https://s3.bmp.ovh/imgs/2022/04/29/52b607617aa123f4.png"></p><ol><li><code>None</code> ：TopicPartition 未清理状态。</li><li><code>LogCleaningInProgress</code> ：清理正在进行中，当 TopicPartition 被选中为待清理 Log 时会变为该状态。</li><li><code>LogCleaningAborted</code> ：清理中止，这是一个从<code>LogCleaningInProgress</code>到<code>LogCleaningPaused(1)</code>的中间状态，在外部发生 truncate、坏盘等情况时需要放弃现在正在的清理操作， 终止后该 TopicPartition 会标记为 <code>LogCleaningAborted</code>。</li><li><code>LogCleaningPaused(i)</code>：清理暂停，i 的初始值为1，这是一个重入的状态，即：如果当前状态是<code>LogCleaningPaused(i)</code>，再次暂停该 TopicPartition 的话，状态会变为<code>LogCleaningPaused(i+1)</code>，从暂停状态恢复的话，状态会变为<code>LogCleaningPaused(i-1)</code>（i-1=0 时直接变为<code>None</code>状态）。会触发状态变为<code>LogCleaningPaused(i)</code>的情况如下（下面的“暂停”和“暂停恢复”分别代表 i + 1 和 i - 1）：<ol><li>Topic 配置<code>cleanup.policy</code>不包含<code>compact</code>：暂停</li><li>外部发生 truncate、坏盘等情况时该 TopicPartition 状态为<code>None</code>或<code>LogCleaningPaused(i)</code>：暂停</li><li>本轮清理完成且该 TopicPartition 状态为<code>LogCleaningAborted</code>：暂停</li><li>触发暂停的操作完成：暂停恢复</li></ol></li></ol><blockquote><p>我理解中止状态和暂停状态的区别是：是否可以在本轮清理中恢复。在外部发生 truncate、坏盘等情况时，如果一个 TopicPartition 没有处于清理过程中，可以标记为暂停，在触发暂停的情况结束后，恢复清理流程就会重新执行清理流程。但是如果该 TopicPartition 处于清理过程中，则必须标记为终止，在触发暂停的情况结束后，即使本轮清理没结束，也必须要先标记为暂停，在下轮操作进行清理。这是因为如果已经在清理过程中了，本轮清理会有一些中间态的信息，不容易从中间态进行恢复。</p></blockquote><p>对于每个 CleanerThread，每次都会通过<code>LogCleanerManager.grabFilthiestCompactedLog</code>方法来搜索状态为<code>None</code>并且需要被清理的 TopicPartition 进行清理。<code>LogCleanerManager</code>中的所有状态变更都会加锁，保证状态机是线程安全的，多个 CleanerThread 通过该状态机保证了所有 TopicPartition 的 Compaction 过程是线程安全的。</p><h4 id="如何决定哪些-TopicPartition-应该被清理（LogCleanerManager-grabFilthiestCompactedLog的详细流程）"><a href="#如何决定哪些-TopicPartition-应该被清理（LogCleanerManager-grabFilthiestCompactedLog的详细流程）" class="heading-link"><i class="fas fa-link"></i></a><a href="#如何决定哪些-TopicPartition-应该被清理（LogCleanerManager-grabFilthiestCompactedLog的详细流程）" class="headerlink" title="如何决定哪些 TopicPartition 应该被清理（LogCleanerManager.grabFilthiestCompactedLog的详细流程）?"></a>如何决定哪些 TopicPartition 应该被清理（<code>LogCleanerManager.grabFilthiestCompactedLog</code>的详细流程）?</h4><p>可以清理的 TopicPartition 限制条件有以下几个：</p><ul><li><p>Topic 配置<code>cleanup.policy</code>包含<code>compact</code>。</p></li><li><p>TopicPartition 的状态为空：说明没有其他 CleanerThread 操作该 TopicPartition。</p></li><li><p>该 TopicPartition 是可以清理的：因为坏盘等问题某些 TopicPartition 会被标记为不可清理，需要跳过。</p></li><li><p>不需要延迟清理：消息在日志中必须存在<code>&quot;max.compaction.lag.ms&quot;</code>指定的时间后才能被删除（详情可参考<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-354">KIP-354</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>），只有第一个未压缩 Segment 的估计最早消息时间戳早于<code>&quot;max.compaction.lag.ms&quot;</code>才会可以进行 Compaction。</p></li><li><p>需要被清理的消息总大小大于0：从 LogStartOffset 或 CleanCheckPoint 开始到满足<code>&quot;max.compaction.lag.ms&quot;</code>配置要求的 offset 之间的消息总大小</p></li><li><p>满足清理频率满足要求：有关清理频率的配置可以直接看下面源码 Doc</p><figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MIN_COMPACTION_LAG_MS_CONFIG = <span class="string">&quot;min.compaction.lag.ms&quot;</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MIN_COMPACTION_LAG_MS_DOC = <span class="string">&quot;The minimum time a message will remain &quot;</span> +</span><br><span class="line">    <span class="string">&quot;uncompacted in the log. Only applicable for logs that are being compacted.&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MAX_COMPACTION_LAG_MS_CONFIG = <span class="string">&quot;max.compaction.lag.ms&quot;</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MAX_COMPACTION_LAG_MS_DOC = <span class="string">&quot;The maximum time a message will remain &quot;</span> +</span><br><span class="line">    <span class="string">&quot;ineligible for compaction in the log. Only applicable for logs that are being compacted.&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MIN_CLEANABLE_DIRTY_RATIO_CONFIG = <span class="string">&quot;min.cleanable.dirty.ratio&quot;</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MIN_CLEANABLE_DIRTY_RATIO_DOC = <span class="string">&quot;This configuration controls how frequently &quot;</span> +</span><br><span class="line">    <span class="string">&quot;the log compactor will attempt to clean the log (assuming &lt;a href=\&quot;#compaction\&quot;&gt;log &quot;</span> +</span><br><span class="line">    <span class="string">&quot;compaction&lt;/a&gt; is enabled). By default we will avoid cleaning a log where more than &quot;</span> +</span><br><span class="line">    <span class="string">&quot;50% of the log has been compacted. This ratio bounds the maximum space wasted in &quot;</span> +</span><br><span class="line">    <span class="string">&quot;the log by duplicates (at 50% at most 50% of the log could be duplicates). A &quot;</span> +</span><br><span class="line">    <span class="string">&quot;higher ratio will mean fewer, more efficient cleanings but will mean more wasted &quot;</span> +</span><br><span class="line">    <span class="string">&quot;space in the log. If the &quot;</span> + MAX_COMPACTION_LAG_MS_CONFIG + <span class="string">&quot; or the &quot;</span> + MIN_COMPACTION_LAG_MS_CONFIG +</span><br><span class="line">    <span class="string">&quot; configurations are also specified, then the log compactor considers the log to be eligible for compaction &quot;</span> +</span><br><span class="line">    <span class="string">&quot;as soon as either: (i) the dirty ratio threshold has been met and the log has had dirty (uncompacted) &quot;</span> +</span><br><span class="line">    <span class="string">&quot;records for at least the &quot;</span> + MIN_COMPACTION_LAG_MS_CONFIG + <span class="string">&quot; duration, or (ii) if the log has had &quot;</span> +</span><br><span class="line">    <span class="string">&quot;dirty (uncompacted) records for at most the &quot;</span> + MAX_COMPACTION_LAG_MS_CONFIG + <span class="string">&quot; period.&quot;</span>;</span><br></pre></td></tr></table></div></figure></li></ul><h4 id="OffsetMap-的实现原理"><a href="#OffsetMap-的实现原理" class="heading-link"><i class="fas fa-link"></i></a><a href="#OffsetMap-的实现原理" class="headerlink" title="OffsetMap 的实现原理"></a>OffsetMap 的实现原理</h4><p>OffsetMap 的实现类是<code>SkimpyOffsetsMap</code>，用来存储 message key 和 offset 的映射关系，用来保存相同 key 下最新消息的 Offset。此处不介绍该类的详细实现（感兴趣自行阅读<span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/apache/kafka/blob/2.8/core/src/main/scala/kafka/log/OffsetMap.scala">源码</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>），只列举其特点：</p><ul><li>创建时需要指定两个参数，一个是 memory，用来指定存储 offset 的 ByteBuffer 大小，另一个是 hashAlgorithm，用来确定计算 key hash 时使用的哈希算法。</li><li>只允许增加，不允许删除。</li><li>只在 ByteBuffer 中存储需要记录的 offset，每次 put/get 都是先对 key hash 确定 position，然后直接修改/读取 ByteBuffer 中的内容。</li></ul><blockquote><p>我理解该实现的主要优点是避免存储 message key，减少内存消耗。</p></blockquote><h4 id="如何从一组旧的-Segment-中过滤出需要保留的消息以及过滤策略是怎样的"><a href="#如何从一组旧的-Segment-中过滤出需要保留的消息以及过滤策略是怎样的" class="heading-link"><i class="fas fa-link"></i></a><a href="#如何从一组旧的-Segment-中过滤出需要保留的消息以及过滤策略是怎样的" class="headerlink" title="如何从一组旧的 Segment 中过滤出需要保留的消息以及过滤策略是怎样的?"></a>如何从一组旧的 Segment 中过滤出需要保留的消息以及过滤策略是怎样的?</h4><p>过滤消息的流程是，先将旧 Segment 中的消息读入MemoryRecords，然后使用<code>MemoryRecords.filterTo</code>方法进行过滤，该方法支持使用自定义实现的 <code>RecordFilter</code> 过滤消息。</p><p>消息过滤的策略（实际会有事务消息的处理）是：过滤掉相同 key 中非最新 offset 的消息以及满足删除条件的<strong>墓碑消息</strong>（key 不为 null 但是 value 为 null）。墓碑消息的删除条件是指，该墓碑消息所在的 Segment 最后修改时间距离最新 Segment 的最后修改时间超过<code>delete.retention.ms</code>配置的时间。</p><h4 id="如果-Compaction-过程中-Broker-崩溃，重启后如何恢复"><a href="#如果-Compaction-过程中-Broker-崩溃，重启后如何恢复" class="heading-link"><i class="fas fa-link"></i></a><a href="#如果-Compaction-过程中-Broker-崩溃，重启后如何恢复" class="headerlink" title="如果 Compaction 过程中 Broker 崩溃，重启后如何恢复?"></a>如果 Compaction 过程中 Broker 崩溃，重启后如何恢复?</h4><p>宕机恢复的考虑只发生在用新 Segment（文件名后缀是<code>.cleaned</code>） 替换旧 Segment 的过程中，其他阶段发生宕机的话，恢复后重新执行 Compaction 流程即可。</p><p>Segment 替换操作使用<code>replaceSegments</code>方法（源码如下）完成，替换流程是：</p><ol><li>将新 Segment 的文件名后缀从<code>.cleaned</code>改为<code>.swap</code></li><li>删除旧 Segment：删除过程是先将同步将文件后缀改为<code>.deleted</code>，然后进行异步删除</li><li>去掉新 Segment 的文件名后缀，流程结束</li></ol><p>下面是对于所有可能的阶段 Broker 崩溃后的恢复逻辑：</p><ul><li>步骤1之前：如果此时 broker 崩溃，则清理和交换操作将中止，并且在 <code>loadSegments()</code>中恢复时删除 <code>.cleaned</code> 文件。</li><li>步骤1执行过程中崩溃：新 Segment 重命名为 <code>.swap</code>。如果代理在所有 Segment 重命名为 <code>.swap</code> 之前崩溃，则清理和交换操作将中止 <code>.cleaned</code> 以及 <code>.swap</code> 文件在 <code>loadSegments()</code> 恢复时被删除。 <code>.cleaned</code> 重命名为 <code>.swap</code> 是按照文件按偏移量的降序进行的，恢复时，所有偏移量大于最小偏移量 <code>.clean</code>文件的<code>.swap</code> 文件都将被删除。</li><li>步骤1完成后崩溃：如果在所有新 Segment 重命名为 <code>.swap</code> 后代理崩溃，则操作完成，剩余操作流程会在 Broker 恢复时继续执行。</li><li>步骤2执行过程中崩溃：旧 Segment 文件被重命名为 <code>.deleted</code> 并安排了异步删除。如果 Broker 崩溃，任何留下的 <code>.deleted</code> 文件都会在 <code>loadSegments()</code> 恢复时被删除，然后调用 <code>replaceSegments()</code> 以完成替换，其中新 Segment 从 <code>.swap</code> 文件重新创建，旧 Segment 包含在崩溃前未重命名的 Segment。</li><li>步骤3完成后崩溃：此时可能存在未被异步删除完成的旧 Segment，任何可能留下的 <code>.deleted</code> 文件都会在 <code>loadSegments()</code> 恢复时被删除</li></ul><figure class="highlight scala"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span>[log] <span class="function"><span class="keyword">def</span> <span class="title">replaceSegments</span></span>(newSegments: <span class="type">Seq</span>[<span class="type">LogSegment</span>], oldSegments: <span class="type">Seq</span>[<span class="type">LogSegment</span>], isRecoveredSwapFile: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    lock synchronized &#123;</span><br><span class="line">      <span class="keyword">val</span> sortedNewSegments = newSegments.sortBy(_.baseOffset)</span><br><span class="line">      <span class="comment">// Some old segments may have been removed from index and scheduled for async deletion after the caller reads segments</span></span><br><span class="line">      <span class="comment">// but before this method is executed. We want to filter out those segments to avoid calling asyncDeleteSegment()</span></span><br><span class="line">      <span class="comment">// multiple times for the same segment.</span></span><br><span class="line">      <span class="keyword">val</span> sortedOldSegments = oldSegments.filter(seg =&gt; segments.containsKey(seg.baseOffset)).sortBy(_.baseOffset)</span><br><span class="line"></span><br><span class="line">      checkIfMemoryMappedBufferClosed()</span><br><span class="line">      <span class="comment">// need to do this in two phases to be crash safe AND do the delete asynchronously</span></span><br><span class="line">      <span class="comment">// if we crash in the middle of this we complete the swap in loadSegments()</span></span><br><span class="line">      <span class="keyword">if</span> (!isRecoveredSwapFile)</span><br><span class="line">        sortedNewSegments.reverse.foreach(_.changeFileSuffixes(<span class="type">Log</span>.<span class="type">CleanedFileSuffix</span>, <span class="type">Log</span>.<span class="type">SwapFileSuffix</span>))</span><br><span class="line">      sortedNewSegments.reverse.foreach(addSegment(_))</span><br><span class="line">      <span class="keyword">val</span> newSegmentBaseOffsets = sortedNewSegments.map(_.baseOffset).toSet</span><br><span class="line"></span><br><span class="line">      <span class="comment">// delete the old files</span></span><br><span class="line">      sortedOldSegments.foreach &#123; seg =&gt;</span><br><span class="line">        <span class="comment">// remove the index entry</span></span><br><span class="line">        <span class="keyword">if</span> (seg.baseOffset != sortedNewSegments.head.baseOffset)</span><br><span class="line">          segments.remove(seg.baseOffset)</span><br><span class="line">        <span class="comment">// delete segment files, but do not delete producer state for segment objects which are being replaced.</span></span><br><span class="line">        deleteSegmentFiles(<span class="type">List</span>(seg), asyncDelete = <span class="literal">true</span>, deleteProducerStateSnapshots = !newSegmentBaseOffsets.contains(seg.baseOffset))</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// okay we are safe now, remove the swap suffix</span></span><br><span class="line">      sortedNewSegments.foreach(_.changeFileSuffixes(<span class="type">Log</span>.<span class="type">SwapFileSuffix</span>, <span class="string">&quot;&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure><hr><h2 id="Pulsar-Compaction"><a href="#Pulsar-Compaction" class="heading-link"><i class="fas fa-link"></i></a><a href="#Pulsar-Compaction" class="headerlink" title="Pulsar Compaction"></a>Pulsar Compaction</h2><p>Pulsar 官方文档中关于 Compaction 的介绍也比较详细，具体可以参考：</p><ul><li><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://pulsar.apache.org/docs/zh-CN/next/concepts-topic-compaction/#compaction">https://pulsar.apache.org/docs/zh-CN/next/concepts-topic-compaction/#compaction</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li><li><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://pulsar.apache.org/docs/zh-CN/next/cookbooks-compaction/">https://pulsar.apache.org/docs/zh-CN/next/cookbooks-compaction/</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li><li><span class="exturl"><a class="exturl__link" target="_blank" rel="noopener" href="https://github.com/ivankelly/incubator-pulsar-wiki/blob/pip-9/PIP-9:-Topic-Compaction.md">https://github.com/ivankelly/incubator-pulsar-wiki/blob/pip-9/PIP-9:-Topic-Compaction.md</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li></ul><p>在 Pulsar 中，Topic Compaction 与 NonCompaction 两个状态不是相互对立的，Compaction 是通过类似于创建一个Subscription 来消费现有 Topic 的消息，经过 Compaction 处理后，写入新的 Ledger 存储，在 Consumer 消费时，可以通过配置选择读取 Compacted 数据还是 NonCompacted 数据。注意：Compact 只能对 persistent topic 执行。</p><h3 id="触发条件"><a href="#触发条件" class="heading-link"><i class="fas fa-link"></i></a><a href="#触发条件" class="headerlink" title="触发条件"></a>触发条件</h3><p>Pulsar 中触发 Topic Compaction 的方式有两种：</p><ol><li>配置<code>CompactionThreshold</code>：如前面所说，Compaction 过程相当于建立一个 Subscription 来消费原来 Topic 中的数据写入新的 Ledger，Broker 会周期性检查所有 Persistent Topic，如果<code>CompactionThreshold</code>配置不为0并且这个 Subscription 的消息积压超过了配置的阈值，就会自动触发 Compaction。这个配置的粒度可以是 topic、broker、namespace，最终根据优先级（topic &gt; broker &gt; namespace）确定最终配置值。</li><li>外部触发 Topic Compaction：除自动触发 Compaction 外，也可以通过 CLI 工具触发，一种是 AdminCli，需要调用 broker 提供的 RestAPI，另一种是使用专用工具类，不经过 RestAPI 直接指定。</li></ol><figure class="highlight shell"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> bin/pulsar-admin topics compact persistent://my-tenant/my-namespace/my-topic <span class="comment"># AdminCli</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> bin/pulsar compact-topic --topic persistent://my-tenant-namespace/my-topic <span class="comment"># 专用工具</span></span></span><br></pre></td></tr></table></div></figure><h3 id="实现原理-1"><a href="#实现原理-1" class="heading-link"><i class="fas fa-link"></i></a><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h3><p>实现原理总体可以分为 Compaction 的处理过程和 Consumer 读取 Compacted 数据两个部分。</p><h4 id="Compaction-处理"><a href="#Compaction-处理" class="heading-link"><i class="fas fa-link"></i></a><a href="#Compaction-处理" class="headerlink" title="Compaction 处理"></a>Compaction 处理</h4><p>触发 Compaction 的统一入口是<code>Compactor.compact(String topic)</code>方法，<code>Compactor</code>是一个抽象类，目前的实现只有<code>TwoPhaseCompactor</code>一种，下面介绍的是<code>TwoPhaseCompactor</code>的实现逻辑。顾名思义，Compaction 过程分为两个阶段，遍历两次 Topic 内容，第一次遍历用来获取每个 key 中最新的 MessageId（相当于 Kafka 中的 offset），第二次遍历根据第一次遍历取得的结果，只将每个 key 的最新消息写入新的 Ledger 中。</p><h4 id="读取-Compacted-数据"><a href="#读取-Compacted-数据" class="heading-link"><i class="fas fa-link"></i></a><a href="#读取-Compacted-数据" class="headerlink" title="读取 Compacted 数据"></a>读取 Compacted 数据</h4><p>如果 Consumer 希望读取 Compacted 数据，需要在初始化时制定相关配置。</p><figure class="highlight java"><div class="table-container"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Consumer&lt;<span class="keyword">byte</span>[]&gt; compactedTopicConsumer = client.newConsumer()</span><br><span class="line">        .topic(<span class="string">&quot;some-compacted-topic&quot;</span>)</span><br><span class="line">        .readCompacted(<span class="keyword">true</span>)</span><br><span class="line">        .subscribe();</span><br></pre></td></tr></table></div></figure><p>Broker 在收到 Consumer 的请求后，会先获取到 Topic 对应的 cursor 信息，然后从 cursor 信息中找到 Compacted 数据对应的 LedgerId，然后进行对应数据的读取。</p><h4 id="Compacted-Leger-信息如何传递给-Consumer？"><a href="#Compacted-Leger-信息如何传递给-Consumer？" class="heading-link"><i class="fas fa-link"></i></a><a href="#Compacted-Leger-信息如何传递给-Consumer？" class="headerlink" title="Compacted Leger 信息如何传递给 Consumer？"></a>Compacted Leger 信息如何传递给 Consumer？</h4><p>如前文所说，在<code>TwoPhaseCompactor</code>处理过程中，实际是创建了一个 Subscription 来读取原来的数据。在读取数据完成进行 Ack 时，使用的接口是<code>RawReader.acknowledgeCumulativeAsync(MessageId messageId, Map&lt;String, Long&gt; properties)</code>，该接口可以在 Ack 的同时给 Broker 返回一些该 Subscription 的元信息，Broker 会将收到的元信息记录在 cursor 信息中。所以，<code>TwoPhaseCompactor</code>通过这一能力，将创建的用来存储 Compacted 数据的 LedgerId 记录在了 cursor 信息中，方便 Consumer 读取时使用。</p><h2 id="总结思考"><a href="#总结思考" class="heading-link"><i class="fas fa-link"></i></a><a href="#总结思考" class="headerlink" title="总结思考"></a>总结思考</h2><p>Kafka 和 Pulsar 中实现 Compaction 的目的是为了在特定的场景下减少 Topic 的数据量，加快获取 Topic 中全部数据的速度，而不是希望实现类似 KV 存储的能力。之所以这样说，是因为：</p><ol><li>Kafka 和 Pulsar 都没有保证最新数据的 Compaction：对于 Kafka 来说，Log Compaction 只会操作 ActiveSegment 之前的数据；对于 Pulsar 来说，Compaction 是一个周期性执行的工作，每次 Compaction 开始之前，都会先读取当前 Topic 中最后一个 MessageId 作为本轮 Compaction 的终点，因此只要有 Producer 在向 Topic 生产数据。就肯定不能保证所有数据都被 Compacted。</li><li>Kafka 和 Pulsar 的 Compaction 都是一定范围内的，不是全局的：Kafka 和 Pulsar 的 Compaction 都是以一种类似于滑动窗口的过程进行，“key 相同的情况下只保留最新的消息”针对的是一轮 Compaction 内，如果两轮 Compaction 中有相同 key 的消息，是没有办法合并的。</li></ol><p>对比 Kafka 和 Pulsar 两者的实现来看，最主要的区别就是是否保留 Compaction 前的数据。相较于 Kafka 的实现，Pulsar 这种形式一方面整体逻辑更为简单，不需要考虑各种文件替换过程中的崩溃恢复逻辑，另一方面也可以给 Consumer 更多选择的空间，但是这样也会带来一定的存储成本。两者的实现架构是不同的，如果想要 Kafka 也像 Pulsar 一样保留两份数据，由于 Kafka 的存储副本机制是自己的管理的，可能需要比现在更为复杂的实现才能够搞定，而不能像 Pulsar 一样直接通过切换 LedgerId 来选择数据就可以了。</p></div><footer class="post-footer"><div class="post-ending ending"><div class="ending__text">------ 本文结束，感谢您的阅读 ------</div></div><div class="post-copyright copyright"><div class="copyright-author"><span class="copyright-author__name">本文作者: </span><span class="copyright-author__value"><a href="http://fxbing.github.io">fxbing</a></span></div><div class="copyright-link"><span class="copyright-link__name">本文链接: </span><span class="copyright-link__value"><a href="http://fxbing.github.io/2022/05/01/Kafka-%E5%92%8C-Pulsar-%E7%9A%84-Compaction-%E5%AE%9E%E7%8E%B0/">http://fxbing.github.io/2022/05/01/Kafka-%E5%92%8C-Pulsar-%E7%9A%84-Compaction-%E5%AE%9E%E7%8E%B0/</a></span></div><div class="copyright-notice"><span class="copyright-notice__name">版权声明: </span><span class="copyright-notice__value">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" rel="external nofollow" target="_blank">BY-NC-SA</a> 许可协议。转载请注明出处！</span></div></div><div class="post-tags"><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="http://fxbing.github.io/tags/Pulsar/">Pulsar</a></span><span class="post-tags-item"><span class="post-tags-item__icon"><i class="fas fa-tag"></i></span><a class="post-tags-item__link" href="http://fxbing.github.io/tags/kafka/">kafka</a></span></div><nav class="post-paginator paginator"><div class="paginator-next"><a class="paginator-next__link" href="/2022/03/29/Kafka-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/"><span class="paginator-prev__text">Kafka 源码学习：动态配置</span><span class="paginator-next__icon"><i class="fas fa-angle-right"></i></span></a></div></nav></footer></div></div><div class="comments" id="comments"><div id="disqus_thread"></div></div></div><div class="sidebar-wrap" id="sidebar-wrap"><aside class="sidebar" id="sidebar"><div class="sidebar-nav"><span class="sidebar-nav-toc current">文章目录</span><span class="sidebar-nav-ov">站点概览</span></div><section class="sidebar-toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Kafka-Log-Compaction"><span class="toc-number">1.</span> <span class="toc-text">Kafka Log Compaction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">1.1.</span> <span class="toc-text">实现原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%A6%E7%BB%86%E8%AF%B4%E6%98%8E"><span class="toc-number">1.2.</span> <span class="toc-text">详细说明</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E4%B8%AA-CleanerThread-%E6%98%AF%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81-Compaction-%E8%BF%87%E7%A8%8B%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84"><span class="toc-number">1.2.1.</span> <span class="toc-text">多个 CleanerThread 是如何保证 Compaction 过程线程安全的?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%86%B3%E5%AE%9A%E5%93%AA%E4%BA%9B-TopicPartition-%E5%BA%94%E8%AF%A5%E8%A2%AB%E6%B8%85%E7%90%86%EF%BC%88LogCleanerManager-grabFilthiestCompactedLog%E7%9A%84%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B%EF%BC%89"><span class="toc-number">1.2.2.</span> <span class="toc-text">如何决定哪些 TopicPartition 应该被清理（LogCleanerManager.grabFilthiestCompactedLog的详细流程）?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#OffsetMap-%E7%9A%84%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.3.</span> <span class="toc-text">OffsetMap 的实现原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E4%BB%8E%E4%B8%80%E7%BB%84%E6%97%A7%E7%9A%84-Segment-%E4%B8%AD%E8%BF%87%E6%BB%A4%E5%87%BA%E9%9C%80%E8%A6%81%E4%BF%9D%E7%95%99%E7%9A%84%E6%B6%88%E6%81%AF%E4%BB%A5%E5%8F%8A%E8%BF%87%E6%BB%A4%E7%AD%96%E7%95%A5%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84"><span class="toc-number">1.2.4.</span> <span class="toc-text">如何从一组旧的 Segment 中过滤出需要保留的消息以及过滤策略是怎样的?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A6%82%E6%9E%9C-Compaction-%E8%BF%87%E7%A8%8B%E4%B8%AD-Broker-%E5%B4%A9%E6%BA%83%EF%BC%8C%E9%87%8D%E5%90%AF%E5%90%8E%E5%A6%82%E4%BD%95%E6%81%A2%E5%A4%8D"><span class="toc-number">1.2.5.</span> <span class="toc-text">如果 Compaction 过程中 Broker 崩溃，重启后如何恢复?</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Pulsar-Compaction"><span class="toc-number">2.</span> <span class="toc-text">Pulsar Compaction</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%A7%A6%E5%8F%91%E6%9D%A1%E4%BB%B6"><span class="toc-number">2.1.</span> <span class="toc-text">触发条件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86-1"><span class="toc-number">2.2.</span> <span class="toc-text">实现原理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Compaction-%E5%A4%84%E7%90%86"><span class="toc-number">2.2.1.</span> <span class="toc-text">Compaction 处理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AF%BB%E5%8F%96-Compacted-%E6%95%B0%E6%8D%AE"><span class="toc-number">2.2.2.</span> <span class="toc-text">读取 Compacted 数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Compacted-Leger-%E4%BF%A1%E6%81%AF%E5%A6%82%E4%BD%95%E4%BC%A0%E9%80%92%E7%BB%99-Consumer%EF%BC%9F"><span class="toc-number">2.2.3.</span> <span class="toc-text">Compacted Leger 信息如何传递给 Consumer？</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93%E6%80%9D%E8%80%83"><span class="toc-number">3.</span> <span class="toc-text">总结思考</span></a></li></ol></section><section class="sidebar-ov hide"><div class="sidebar-ov-author"><div class="sidebar-ov-author__avatar"><img class="sidebar-ov-author__avatar_img" src="/uploads/avatar.jpg" alt="avatar"></div><p class="sidebar-ov-author__text">既然生活这么苦，那还不笑一笑让自己开心一点。</p></div><div class="sidebar-ov-social"><a class="sidebar-ov-social-item" href="https://github.com/fxbing" target="_blank" rel="noopener" data-popover="Github" data-popover-pos="up"><span class="sidebar-ov-social-item__icon"><i class="fab fa-github"></i></span></a></div><div class="sidebar-ov-state"><a class="sidebar-ov-state-item sidebar-ov-state-item--posts" href="/archives/"><div class="sidebar-ov-state-item__count">18</div><div class="sidebar-ov-state-item__name">归档</div></a><a class="sidebar-ov-state-item sidebar-ov-state-item--tags" href="/tags/"><div class="sidebar-ov-state-item__count">8</div><div class="sidebar-ov-state-item__name">标签</div></a></div><div class="sidebar-ov-cc"><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en" target="_blank" rel="noopener" data-popover="知识共享许可协议" data-popover-pos="up"><img src="/images/cc-by-nc-sa.svg"></a></div></section><div class="sidebar-reading"><div class="sidebar-reading-info"><span class="sidebar-reading-info__text">你已阅读了 </span><span class="sidebar-reading-info__num">0</span><span class="sidebar-reading-info__perc">%</span></div><div class="sidebar-reading-line"></div></div></aside></div><div class="clearfix"></div></div></main><footer class="footer" id="footer"><div class="footer-inner"><div><span>Copyright © 2022</span><span class="footer__icon"><i class="fas fa-heart"></i></span><span>fxbing</span></div><div><span>由 <a href="http://hexo.io/" title="Hexo" target="_blank" rel="noopener">Hexo</a> 强力驱动</span><span> v5.4.0</span><span class="footer__devider">|</span><span>主题 - <a href="https://github.com/liuyib/hexo-theme-stun/" title="Stun" target="_blank" rel="noopener">Stun</a></span><span> v2.6.2</span></div></div></footer><div class="loading-bar" id="loading-bar"><div class="loading-bar__progress"></div></div><div class="back2top" id="back2top"><span class="back2top__icon"><i class="fas fa-rocket"></i></span></div></div><script src="https://cdn.jsdelivr.net/npm/jquery@v3.4.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@1.5.2/velocity.ui.min.js"></script><script>function loadDisqus(){var t,e,i;document.getElementById("disqus_thread")&&(window.DISQUS?DISQUS.reset({reload:!0,config:function(){this.page.url="http://fxbing.github.io/2022/05/01/Kafka-%E5%92%8C-Pulsar-%E7%9A%84-Compaction-%E5%AE%9E%E7%8E%B0/",this.page.identifier="2022/05/01/Kafka-和-Pulsar-的-Compaction-实现/",this.page.title="Kafka 和 Pulsar 的 Compaction 实现"}}):(e=(t=document).createElement("script"),i=t.createElement("script"),e.src="https://fxbingBlog.disqus.com/count.js",e.id="dsq-count-scr",e.async=!0,(t.head||t.body).appendChild(e),i.src="https://fxbingBlog.disqus.com/embed.js",(t.head||t.body).appendChild(i)))}window.addEventListener("DOMContentLoaded",loadDisqus,!1)</script><script src="/js/utils.js?v=2.6.2"></script><script src="/js/stun-boot.js?v=2.6.2"></script><script src="/js/scroll.js?v=2.6.2"></script><script src="/js/header.js?v=2.6.2"></script><script src="/js/sidebar.js?v=2.6.2"></script></body></html>