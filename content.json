{"meta":{"title":"小兵的博客","subtitle":null,"description":"既然生活这么苦，那还不笑一笑让自己开心一点。","author":"fxbing","url":"http://fxbing.github.io"},"posts":[{"title":"Kafka 源码学习：动态配置","slug":"Kafka-源码学习：动态配置","date":"2022-03-29T11:22:27.000Z","updated":"2022-04-01T13:32:22.167Z","comments":true,"path":"2022/03/29/Kafka-源码学习：动态配置/","link":"","permalink":"http://fxbing.github.io/2022/03/29/Kafka-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/","excerpt":"\n          Kafka 动态配置实现\n      Kafka 的动态配置基于 Zookeeper 实现，本文主要梳理了 Kafka（version：2.8） 中动态配置的实现逻辑。","text":"Kafka 动态配置实现 Kafka 的动态配置基于 Zookeeper 实现，本文主要梳理了 Kafka（version：2.8） 中动态配置的实现逻辑。 背景信息 在 Kafka 中，Zookeeper 客户端没有使用常见的客户端工具（如：Curator），而是直接基于原生的客户端实现了自己的 KafkaZkClient，将一些通用或特有的 Zookeeper 操作封装在内。因此，关于 Zookeeper 的使用及回调等逻辑也完全是独立实现的。另外，由于 Zookeeper 中一个节点下的 Watcher 顺序触发，如果同一个节点下有大量的 Watcher，将会产生性能瓶颈。下面将基于这些背景信息来介绍 Kafka 是如何基于 Zookeeper 实现高效的动态配置管理的。 Kafka 动态配置 Zookeeper 目录结构 在当前版本的 Kafka 中，动态配置类型有 5 种：topic, client, user, broker, ip。Kafka 动态配置的目录结构为： /config/entityType/entityName ，entityType 代表配置的类型，entityName 代表具体某个实体，比如：Topic 类型对应的实体就是具体某个 Topic，某个配置类型下所有实体的默认配置的 entityName 为 &lt;deafult&gt; (topic 类型没有 &lt;default&gt; 配置)。具体来说，所有 Topic 的默认动态配置会放在 /config/topic/&lt;default&gt; 的节点信息中，Topic AAA 的所有动态配置会放在 /config/topic/AAA 的节点信息中。 Listener 实现 下面介绍 Kafka 中 Zookeeper Listener 的实现。既然是基于 Zookeeper 实现，必然少不了 Zookeeper 的 Watcher 通知机制，但是，如背景信息中所说，在 Watcher 数量过多的情况下，会存在性能瓶颈。以 Topic 配置变更为例，在生产环境中，一个 Topic 的 Partition 数量可能多达上千，如果每个 Partition Leader 都去监听这个 Topic 配置信息，那么在一个 Kafka 集群内，仅监听 Topic 配置的 Watcher 就会有上万个甚至更多。Kafka 通过独立的通知机制来避免了这一问题，即：每次 AdminClient 进行配置变更时，会在 /config/changes/ 目录下创建以 config_change_ 为前缀的顺序节点，Wather 只监听 /config/changes/ 目录的孩子节点变化，所以对于动态配置来说，所有 Broker 只监听 /config/changes/ 这一个目录，大大减少集群整体的 Watcher 数量。 Kafka 中动态配置的 Zookeeper Listener 的实现在 ZkNodeChangeNotificationListener 类中，该类监听指定目录下的顺序节点添加动作，在收到子节点变化通知后，ZkNodeChangeNotificationListener 一方面执行通知动作，通知对应的 Handler 处理配置变更，另一面会清除所有已经处理过的配置变更。 下面对 ZkNodeChangeNotificationListener 类的实现进行介绍，主要分为以下几个部分： a. 初始化：注册 zk 连接状态变更的 Handler 和 zk 子节点变更的 Handler；调用一次 addChangeNotification() 触发一次配置变更的处理，用来初始化动态配置；启动用来处理配置变更事件的线程 ChangeEventProcessThread。 b. 配置变更处理：每次 zk 状态变更或者动态配置变更都会向 queue 中放入一个处理事件，与此同时，ChangeEventProcessThread 会持续不断的从 queue 中取出事件，执行对应的处理动作，即：processNotifications()。 c. 清除过期通知：每次执行完 processNotifications()，都会调用 purgeObsoleteNotifications 执行过期通知的清理动作，删除所有进行本次 processNotifications() 之前创建的所有变更通知。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182class ZkNodeChangeNotificationListener(private val zkClient: KafkaZkClient, private val seqNodeRoot: String, private val seqNodePrefix: String, private val notificationHandler: NotificationHandler, private val changeExpirationMs: Long = 15 * 60 * 1000, private val time: Time = Time.SYSTEM) extends Logging &#123; private var lastExecutedChange = -1L private val queue = new LinkedBlockingQueue[ChangeNotification] private val thread = new ChangeEventProcessThread(s&quot;$seqNodeRoot-event-process-thread&quot;) private val isClosed = new AtomicBoolean(false) def init(): Unit = &#123; // ZkStateChangeHandler 和 ChangeNotificationHandler 都是 addChangeNotification() zkClient.registerStateChangeHandler(ZkStateChangeHandler) zkClient.registerZNodeChildChangeHandler(ChangeNotificationHandler) addChangeNotification() thread.start() &#125; def close() = &#123; ··· &#125; /** * Process notifications */ private def processNotifications(): Unit = &#123; try &#123; val notifications = zkClient.getChildren(seqNodeRoot).sorted if (notifications.nonEmpty) &#123; info(s&quot;Processing notification(s) to $seqNodeRoot&quot;) val now = time.milliseconds for (notification &lt;- notifications) &#123; val changeId = changeNumber(notification) // 只处理更新的变更信息 if (changeId &gt; lastExecutedChange) &#123; // 调用 notificationHandler.processNotification() 进行配置变更的处理 processNotification(notification) lastExecutedChange = changeId &#125; &#125; purgeObsoleteNotifications(now, notifications) &#125; &#125; catch &#123; ··· &#125; &#125; ··· ··· private def addChangeNotification(): Unit = &#123; if (!isClosed.get &amp;&amp; queue.peek() == null) queue.put(new ChangeNotification) &#125; class ChangeNotification &#123; def process(): Unit = processNotifications() &#125; private def purgeObsoleteNotifications(now: Long, notifications: Seq[String]): Unit = &#123; for (notification &lt;- notifications.sorted) &#123; val notificationNode = seqNodeRoot + &quot;/&quot; + notification val (data, stat) = zkClient.getDataAndStat(notificationNode) if (data.isDefined) &#123; if (now - stat.getCtime &gt; changeExpirationMs) &#123; debug(s&quot;Purging change notification $notificationNode&quot;) zkClient.deletePath(notificationNode) &#125; &#125; &#125; &#125; /* get the change number from a change notification znode */ private def changeNumber(name: String): Long = name.substring(seqNodePrefix.length).toLong class ChangeEventProcessThread(name: String) extends ShutdownableThread(name = name) &#123; override def doWork(): Unit = queue.take().process() &#125; ··· ···&#125; Handler 实现 上面介绍了配置变更通知是如何接收的，实际的处理在 NotificationHandler.processNotification() 中进行，对于动态配置来说， NotificationHandler 接口的实现是类 ConfigChangedNotificationHandler, ConfigChangedNotificationHandler 的 processNotification 会根据配置变更通知版本对配置变更通知内容进行解析，然后调用对应的类型的 ConfigHandler 进行配置更新。 在当前版本中的配置变更通知分为 version1 和 version2 两个版本，不同版本格式不同，以某个 topic 下的某个 clientId 的动态配置为例，version1 的内容为 &#123;&quot;version&quot; : 1, &quot;entity_type&quot;:&quot;topic/client&quot;, &quot;entity_name&quot; : &quot;&lt;topic_name&gt;/&lt;client_id&gt;&quot;&#125;, version2 的内容为 &#123;&quot;version&quot; : 2, &quot;entity_path&quot;:&quot;topic/&lt;topic_name&gt;/client/&lt;client_id&gt;&quot;&#125; 所有动态配置有默认的 entity_name： &lt;default&gt;，当 entity_name 为 &lt;default&gt; ，表示所有 entity 的默认配置，例如： /config/topics/&lt;default&gt; 中的配置表示所有 topic 的默认动态配置。 下面对 ConfigHandler 的实现类进行简单介绍： TopicConfigHandler： 主要处理 3 类配置： a. LogManager 中管理的 topic 配置 b. 副本限流配置 c. controller 中动态开关配置 &quot;unclean.leader.election.enable&quot; ClientIdConfigHandler 和 UserConfigHandler： 都继承自 QuotaConfigHandler，用来更新客户端侧的限流配置，ClientIdConfigHandler 负责 client id 维度的限流配置更新， UserConfigHandler 用来负责用户维度的限流配置更新 IpConfigHandler： 负责连接维度 ConnectionQuotas 的限流配置更新 BrokerConfigHandler： 一方面负责 broker 相关的 quota 配置，另一方面负责 broker 动态配置的更新。broker 的动态配置逻辑在类 DynamicBrokerConfig 中实现，主要逻辑是根据以下优先级顺序进行 broker 配置的更新和覆盖： a. DYNAMIC_BROKER_CONFIG：存储在 ZK 中的 /configs/brokers/&#123;brokerId&#125; b. DYNAMIC_DEFAULT_BROKER_CONFIG：存储在 ZK 中的 /configs/brokers/&lt;default&gt; c. STATIC_BROKER_CONFIG：broker 启动配置，通常来自 server.properties 文件 d. DEFAULT_CONFIG：KafkaConfig 中硬编码的默认配置 其它补充 在 broker 初始化 partition 的过程中，该 topic 的配置可能会发生变化，为了避免漏掉这部分配置的更新，会在 createLog 过程中记录配置变更的情况，在 createLog 结束后处理这部分配置的更新， 具体可以参考：https://issues.apache.org/jira/browse/KAFKA-8813","raw":null,"content":null,"categories":[{"name":"源码","slug":"源码","permalink":"http://fxbing.github.io/categories/%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://fxbing.github.io/tags/kafka/"}]},{"title":"Kafka 源码学习：日志加载与恢复","slug":"Kafka-源码学习：日志加载与恢复","date":"2022-02-20T08:29:48.000Z","updated":"2022-02-20T08:30:58.513Z","comments":true,"path":"2022/02/20/Kafka-源码学习：日志加载与恢复/","link":"","permalink":"http://fxbing.github.io/2022/02/20/Kafka-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%97%A5%E5%BF%97%E5%8A%A0%E8%BD%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/","excerpt":"本文梳理主要梳理 Kafka 日志加载与恢复的源码。（Kafka 版本：2.8）","text":"本文梳理主要梳理 Kafka 日志加载与恢复的源码。（Kafka 版本：2.8） 日志管理：LogManager LogManager 是 kafka 日志管理子系统的入口点。负责日志的创建、检索和清理。所有读取和写入操作都委托给各个日志实例。LogManager 在一个或多个目录中维护日志。在日志最少的数据目录中创建新日志。事后不会尝试移动分区或根据大小或 I/O 速率进行平衡。后台线程通过定期截断多余的日志段来处理日志保留。 LogManger 的启动主要包括三个部分： 日志加载与恢复，即：loadLogs 各个定时任务启动，主要包括：a. cleanupLogs：根据保留时间和保留大小进行历史 segment 的清理b. flushDirtyLogs：定时刷新还没有写到磁盘上日志c. checkpointLogRecoveryOffsets：定时将所有数据目录所有日志的检查点写到检查点文件中d. checkpointLogStartOffsets：将所有日志的当前日志开始偏移量写到日志目录中的文本文件中，以避免暴露已被 DeleteRecordsRequest 删除的数据e. deleteLogs：定时删除标记为 delete 的日志文件 启动 LogCleaner，负责进行日志 compaction 本文主要对第一部分日志加载与恢复进行梳理。 1234567891011121314151617181920212223242526272829303132333435363738// visible for testingprivate[log] def startupWithConfigOverrides(topicConfigOverrides: Map[String, LogConfig]): Unit = &#123; loadLogs(topicConfigOverrides) // this could take a while if shutdown was not clean /* Schedule the cleanup task to delete old logs */ if (scheduler != null) &#123; info(&quot;Starting log cleanup with a period of %d ms.&quot;.format(retentionCheckMs)) scheduler.schedule(&quot;kafka-log-retention&quot;, cleanupLogs _, delay = InitialTaskDelayMs, period = retentionCheckMs, TimeUnit.MILLISECONDS) info(&quot;Starting log flusher with a default period of %d ms.&quot;.format(flushCheckMs)) scheduler.schedule(&quot;kafka-log-flusher&quot;, flushDirtyLogs _, delay = InitialTaskDelayMs, period = flushCheckMs, TimeUnit.MILLISECONDS) scheduler.schedule(&quot;kafka-recovery-point-checkpoint&quot;, checkpointLogRecoveryOffsets _, delay = InitialTaskDelayMs, period = flushRecoveryOffsetCheckpointMs, TimeUnit.MILLISECONDS) scheduler.schedule(&quot;kafka-log-start-offset-checkpoint&quot;, checkpointLogStartOffsets _, delay = InitialTaskDelayMs, period = flushStartOffsetCheckpointMs, TimeUnit.MILLISECONDS) scheduler.schedule(&quot;kafka-delete-logs&quot;, // will be rescheduled after each delete logs with a dynamic period deleteLogs _, delay = InitialTaskDelayMs, unit = TimeUnit.MILLISECONDS) &#125; if (cleanerConfig.enableCleaner) &#123; _cleaner = new LogCleaner(cleanerConfig, liveLogDirs, currentLogs, logDirFailureChannel, time = time) _cleaner.startup() &#125;&#125; 全部日志加载与恢复：loadLogs 所有日志的加载与恢复的流程主要包含以下几步： 加载并记录日志文件夹中标志状态信息的文件（kafka_cleanshutdown、recovery-point-offset-checkpoint、recovery-point-offset-checkpoint） 并发对每个 tp 的日志进行加载与恢复（下一小节详解） 记录并异步处理有问题的日志文件夹123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107/** * Recover and load all logs in the given data directories */private[log] def loadLogs(topicConfigOverrides: Map[String, LogConfig]): Unit = &#123; // 对所有可用的日志目录（liveLogDirs）进行加载，kafka server 启动时可能配置多个磁盘目录用来存储日志文件，但是不一定所有的磁盘都是可用的 info(s&quot;Loading logs from log dirs $liveLogDirs&quot;) val startMs = time.hiResClockMs() val threadPools = ArrayBuffer.empty[ExecutorService] val offlineDirs = mutable.Set.empty[(String, IOException)] val jobs = ArrayBuffer.empty[Seq[Future[_]]] var numTotalLogs = 0 // 遍历所有的磁盘，进行日志加载与恢复，如果出现 IOException，则将该目录记录到 offlineDirs 中进行后续处理 for (dir &lt;- liveLogDirs) &#123; val logDirAbsolutePath = dir.getAbsolutePath var hadCleanShutdown: Boolean = false try &#123; val pool = Executors.newFixedThreadPool(numRecoveryThreadsPerDataDir) threadPools.append(pool) // 如果 .kafka_cleanshutdown 文件存在，则将该文件删除并记录 hadCleanShutdown 状态，后续不需要进行日志恢复的流程。 val cleanShutdownFile = new File(dir, Log.CleanShutdownFile) if (cleanShutdownFile.exists) &#123; info(s&quot;Skipping recovery for all logs in $logDirAbsolutePath since clean shutdown file was found&quot;) // Cache the clean shutdown status and use that for rest of log loading workflow. Delete the CleanShutdownFile // so that if broker crashes while loading the log, it is considered hard shutdown during the next boot up. KAFKA-10471 Files.deleteIfExists(cleanShutdownFile.toPath) hadCleanShutdown = true &#125; else &#123; // log recovery itself is being performed by `Log` class during initialization info(s&quot;Attempting recovery for all logs in $logDirAbsolutePath since no clean shutdown file was found&quot;) &#125; // 从 recovery-point-offset-checkpoint 文件读取所有 tp 目录的 recoveryPoint var recoveryPoints = Map[TopicPartition, Long]() try &#123; recoveryPoints = this.recoveryPointCheckpoints(dir).read() &#125; catch &#123; case e: Exception =&gt; warn(s&quot;Error occurred while reading recovery-point-offset-checkpoint file of directory &quot; + s&quot;$logDirAbsolutePath, resetting the recovery checkpoint to 0&quot;, e) &#125; // 从 log-start-offset-checkpoint 文件读取所有 tp 目录的 logStartOffset var logStartOffsets = Map[TopicPartition, Long]() try &#123; logStartOffsets = this.logStartOffsetCheckpoints(dir).read() &#125; catch &#123; case e: Exception =&gt; warn(s&quot;Error occurred while reading log-start-offset-checkpoint file of directory &quot; + s&quot;$logDirAbsolutePath, resetting to the base offset of the first segment&quot;, e) &#125; // 日志的加载与恢复主流程，并发对所有 tp 的日志执行 loadLog val logsToLoad = Option(dir.listFiles).getOrElse(Array.empty).filter(logDir =&gt; logDir.isDirectory &amp;&amp; Log.parseTopicPartitionName(logDir).topic != KafkaRaftServer.MetadataTopic) val numLogsLoaded = new AtomicInteger(0) numTotalLogs += logsToLoad.length val jobsForDir = logsToLoad.map &#123; logDir =&gt; val runnable: Runnable = () =&gt; &#123; try &#123; debug(s&quot;Loading log $logDir&quot;) val logLoadStartMs = time.hiResClockMs() val log = loadLog(logDir, hadCleanShutdown, recoveryPoints, logStartOffsets, topicConfigOverrides) val logLoadDurationMs = time.hiResClockMs() - logLoadStartMs val currentNumLoaded = numLogsLoaded.incrementAndGet() info(s&quot;Completed load of $log with $&#123;log.numberOfSegments&#125; segments in $&#123;logLoadDurationMs&#125;ms &quot; + s&quot;($currentNumLoaded/$&#123;logsToLoad.length&#125; loaded in $logDirAbsolutePath)&quot;) &#125; catch &#123; case e: IOException =&gt; offlineDirs.add((logDirAbsolutePath, e)) error(s&quot;Error while loading log dir $logDirAbsolutePath&quot;, e) &#125; &#125; runnable &#125; jobs += jobsForDir.map(pool.submit) &#125; catch &#123; case e: IOException =&gt; offlineDirs.add((logDirAbsolutePath, e)) error(s&quot;Error while loading log dir $logDirAbsolutePath&quot;, e) &#125; &#125; try &#123; // 等待所有并发执行的日志加载流程执行完成 for (dirJobs &lt;- jobs) &#123; dirJobs.foreach(_.get) &#125; // 记录所有有问题的的目录，后续该目录会被 ReplicaManager 执行下线操作 offlineDirs.foreach &#123; case (dir, e) =&gt; logDirFailureChannel.maybeAddOfflineLogDir(dir, s&quot;Error while loading log dir $dir&quot;, e) &#125; &#125; catch &#123; case e: ExecutionException =&gt; error(s&quot;There was an error in one of the threads during logs loading: $&#123;e.getCause&#125;&quot;) throw e.getCause &#125; finally &#123; threadPools.foreach(_.shutdown()) &#125; info(s&quot;Loaded $numTotalLogs logs in $&#123;time.hiResClockMs() - startMs&#125;ms.&quot;)&#125; 单 tp 日志加载与恢复 单个 tp 的日志加载与恢复是在 Log 类的静态代码块中进行的。如果该 tp 的文件夹的后缀为-delete，则认为该 tp 为待删除的，加入到 logsToBeDeleted 集合中等待定时任务对其进行清理。Log 类的静态代码块中通过 loadSegments 加载日志 1234567891011121314151617181920212223242526272829303132333435private def loadSegments(): Long = &#123; // 清理临时文件（.delete 和 .clean 后缀）并保留可用的 swap 文件 val swapFiles = removeTempFilesAndCollectSwapFiles() // retryOnOffsetOverflow 兜住可能发生的 LogSegmentOffsetOverflowException 异常，并进行日志切分处理。 retryOnOffsetOverflow &#123; // 加载文件的中的所有文件并进行必要的完整性检查 logSegments.foreach(_.close()) segments.clear() loadSegmentFiles() &#125; // 根据 swap 文件恢复完成所有被中断的操作 completeSwapOperations(swapFiles) // 如果不是待删除的 tp 日志，执行 recover 流程 if (!dir.getAbsolutePath.endsWith(Log.DeleteDirSuffix)) &#123; val nextOffset = retryOnOffsetOverflow &#123; recoverLog() &#125; // reset the index size of the currently active log segment to allow more entries activeSegment.resizeIndexes(config.maxIndexSize) nextOffset &#125; else &#123; if (logSegments.isEmpty) &#123; addSegment(LogSegment.open(dir = dir, baseOffset = 0, config, time = time, initFileSize = this.initFileSize)) &#125; 0 &#125;&#125; recoverLog 的核心代码如下： 1234567891011121314151617181920212223242526272829303132// if we have the clean shutdown marker, skip recovery// 只有未进行 cleanshutdown 的情况下才需要 recoveryif (!hadCleanShutdown) &#123; // 取出 recoveryPoint 之后的所有 segment（正常情况下只有一个） val unflushed = logSegments(this.recoveryPoint, Long.MaxValue).iterator var truncated = false while (unflushed.hasNext &amp;&amp; !truncated) &#123; val segment = unflushed.next() info(s&quot;Recovering unflushed segment $&#123;segment.baseOffset&#125;&quot;) val truncatedBytes = try &#123; // 清空 segment 对应的 index，逐个 batch 读取校验数据，并重新构造index recoverSegment(segment, leaderEpochCache) &#125; catch &#123; case _: InvalidOffsetException =&gt; val startOffset = segment.baseOffset warn(&quot;Found invalid offset during recovery. Deleting the corrupt segment and &quot; + s&quot;creating an empty one with starting offset $startOffset&quot;) segment.truncateTo(startOffset) &#125; if (truncatedBytes &gt; 0) &#123; // 如果前一个 segment 执行了 truncate， 则之后的所有 segment 直接删除 // unflushed 为迭代器，所以 unflushed.toList 代表的是所有未遍历到的 segment，而不是全部 segment warn(s&quot;Corruption found in segment $&#123;segment.baseOffset&#125;, truncating to offset $&#123;segment.readNextOffset&#125;&quot;) removeAndDeleteSegments(unflushed.toList, asyncDelete = true, reason = LogRecovery) truncated = true &#125; &#125;&#125;","raw":null,"content":null,"categories":[{"name":"源码","slug":"源码","permalink":"http://fxbing.github.io/categories/%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://fxbing.github.io/tags/kafka/"}]},{"title":"二零二一年十二月书单","slug":"二零二一年十二月书单","date":"2021-12-25T09:38:05.000Z","updated":"2021-12-25T08:49:53.626Z","comments":true,"path":"2021/12/25/二零二一年十二月书单/","link":"","permalink":"http://fxbing.github.io/2021/12/25/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E5%8D%81%E4%BA%8C%E6%9C%88%E4%B9%A6%E5%8D%95/","excerpt":"一年即将过去，从七月份记录以来，读了 28 本书，按照这个速度，明年的最低目标得是 50 本，加油加油！💪🏻💪🏻💪🏻","text":"一年即将过去，从七月份记录以来，读了 28 本书，按照这个速度，明年的最低目标得是 50 本，加油加油！💪🏻💪🏻💪🏻 📚以下书籍出现的顺序代表我对这些书的评分排序。 《深入理解Kafka：核心设计与实践原理》：深入讲解 Kafka 原理但没有简单罗列源码 ​ 作者朱小厮写的这本原理解析的书确实不错，相比与其他介绍组件的书籍，既没有冗长的基本操作的罗列，也没有详细到每一段代码的源码解析。对于基础部分，作者介绍了 Kafka 生产者和消费者的基本使用方式，以及如何灵活地使用拦截器、如何做到不丢失数据不重复消费等，对于高级部分，从原理层面介绍了 Kafka 中几个主要的逻辑，没有源码解析，但是包含了不少作者自己的思考，值得学习。 《黑箱》：现实中的被性侵者比电影故事中的更受人同情 ​ 这是一本遭遇性侵女孩的自述，这个日本女孩讲述了自己是如何遭遇性侵的、警察是如何不负责任的以及她最终通过杂志和发布会讲出这件事的原因。在日本这个男权社会中，受性侵者维护自己的权利十分困难，因为警察都认为这是一件正常的事，警察都会倾向让受害人私了。并且在作者就医以及接受警察问询的过程中，真切感受到了什么叫做“二次性侵”，让受害者不断揭开自己的伤疤甚至比第一次遭遇伤害还要残忍。作者是勇敢的，她的表达带动更多的人加入到了#MeToo运动中，也让我们可以更深地了解到这类事件的真相。 《抱住棒棒的自己》：短小却有意义的心理案例合集 ​ 这本书看名字有点无营养畅销书的感觉，实际读起来则不然。这本书出自徐慢慢公众号，通过一个虚拟人物，以漫画的形式刻画了许多我们在生活中会遇到的场景，通过浅显的方式讲出了许多道理： 关于接纳自己：当一个人不被逼迫、不被设限，而是被无条件地接纳时，他自然能感知到接纳背后的爱和期待。 关于自我批判：我们有意识地压抑消极情绪、自我批判，只会让情绪更加强化。自我批判的人其实更容易认输放弃。 关于帮助别人：比一切帮助更为基本的帮助，是让人们意识到，他们总比自己以为的更有办法。 关于自我要求：总想正确地活着，其实是一种虚弱。不要凡事都去想对错。 《公正：该如何是好？》：如何辩证地看待公正这个问题 ​ 最有名的哈佛公开课，作者通过一个个有关公正的故事，引入了卢梭、边沁、康德等人的学说，解释了他们的观点，又推翻了他们的观点。这本书重要的不是告诉我们到底什么才是公正，而是教会我们辩证地思考公正这件事情，凡事无绝对，辩证思考才能跳出思想束缚。 《房价的逻辑》：通过数据解释了为什么那些关于房价的流言不正确 ​ 为什么房价不会跌？为什么说房地产不是泡沫？作者通过与全球范围内的大城市（东京、纽约、伦敦等）对比，用数据对关于买房的种种流言进行反驳。总结起来就是：不论是生育率下降还是政府的严格管控，都不会改变大城市房价上涨的趋势，因为优秀的人才永远都会向好的地方流动，好的地方都是房子供给不足。说明供求关系的最简单逻辑就是：“假设房子降价，你会不会上车？” 《沸腾新十年》：一本互联网科技史 ​ 这本书上下两册，60 多万字，介绍了从 2010 年到 2020 年十年间互联网中重要的历史，内容相当全面，可以看到互联网中每个小领域的变化，也可以看到各个大厂的起起伏伏。但是涉及到的人物确实有点多，看完只能知道大概的事件，却记不得有哪些人。主要还是一些客观事实的描述，主观的解读还是要靠自己的思考。","raw":null,"content":null,"categories":[{"name":"读书","slug":"读书","permalink":"http://fxbing.github.io/categories/%E8%AF%BB%E4%B9%A6/"}],"tags":[{"name":"2021书单","slug":"2021书单","permalink":"http://fxbing.github.io/tags/2021%E4%B9%A6%E5%8D%95/"}]},{"title":"二零二一年十一月书单","slug":"二零二一年十一月书单","date":"2021-12-04T09:34:54.000Z","updated":"2021-12-04T11:30:05.958Z","comments":true,"path":"2021/12/04/二零二一年十一月书单/","link":"","permalink":"http://fxbing.github.io/2021/12/04/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E5%8D%81%E4%B8%80%E6%9C%88%E4%B9%A6%E5%8D%95/","excerpt":"有点迟到，冲冲冲！","text":"有点迟到，冲冲冲！ 📚以下书籍出现的顺序代表我对这些书的评分排序。 《沉默的大多数》：相当有意思吐槽 ​ 正如这本书的名字所言，多数人对于各种事情会有不满，但是会选择沉默，王小波就像是为这些“沉默的大多数”代言，说出了一些我深有同感却想不起来要说、也没这么会说的想法（ps：看到他强推《乡村经济》时还是很开心的）。王小波的表达太有意思了，像一个“愤青”、像一个“吐槽怪”，读起来很是舒服。虽然没有对这本书具体内容的总结，但是不影响我对这本书的评价。 《幸福之路》：从各个角度论述如何更幸福 ​ 罗素的幸福观，从各个角度讲述如何让自己变得更幸福，下面是一些读书笔记，总结了我的理解： 论竞争:竞争让人们忘记了事情的本质，忘记了享受生活，只知道去和别人比较。 论烦闷与兴奋:兴奋就像镇静剂，过少会让生活过于平淡，导致烦闷，但是过多就成了毒品。真正的快乐应该来自于远大稳定的目标这种长久的东西，而不是吸毒这种短暂的东西，因为短暂的兴奋过后，会是更大的烦闷与失落，而长久的目标，才能让我们快乐永驻。用罗素的话说，长久平静的快乐与短暂的兴奋相比，就像是有爱情的性生活与没有爱情的性生活。幸福的生活在很大程度上一定是一种平静的生活，因为真正的快乐只能常驻在平静的环境里。 论疲劳:现代的疲劳大多是精神上的疲劳而不是肌肉上的。一方面是因为恐惧何种最坏的情况，另一方面是因为喜欢兴奋，兴奋消耗了大量的精力。 论嫉妒：不会从自己拥有的东西寻找快乐，而会从其他人拥有的东西寻找痛苦。现代人的嫉妒变多了，因为他们从以前只了解嫉妒自己的邻居，变成了可以了解更多的东西。“希望从绝望中找到正确道路的文明人一定要像拓展自己的思维那样旷达自己的心胸，一定要学会超越自我，从而获得宇宙般无限的自由心灵”。 论犯罪感：犯罪感大多来自于我们从小被灌输的不一定正确的道德观，当感觉到犯罪感时，需要用理性去评估是否真的错误，要以理性的判断为准。 论被虐狂：第一，要记住，你的动机并不总像你想的那样无私；第二，不要过高估计你的价值；第三，不要指望别人也像你一样那么看重你；第四，不要幻想着大多数人总是在想着怎么害你。 论舆论压力：不要过度在意别人的看法，因为大部分人的看法都是偏见，如果有可能，去一个自己喜欢的环境，在这里别人对你的看法就又是另一种。但是，要听取行业专家的意见。 还可以快乐吗：幸福的秘诀在于：兴趣要尽可能的广，尽可能善意的而不是敌意的对待你感兴趣的人和物。 论情趣：情趣是幸福、安康的秘诀，但是必须要让它们与健康、与我们所爱的人的情感、与我们生活着的社会所尊重的东西协调一致。不要过度放纵寻求遗忘，也不要过于受文明社会的约束而处处不敢。 论爱：最好的是可以互惠的爱，各自可以愉快地接受爱，自然地给予爱，每一方都会因为这种互惠的快乐的存在而觉得这个世界更有意思了。 论家庭：父母与孩子之间的感情比任何情感都更加牢固，但是不能对孩子有过多的占有欲，或者强迫孩子必须按照自己的意志成长，教育也可以交给更专业的人做，并且会做得更好。 论工作：明智地度过闲暇时光的能力是文明的终极产物；有意思的工作主要具备两个要素：可以运用技能；具有建设性。 论闲情逸致：我们只是宇宙中很小的一部分，我们遭遇的痛苦、悲伤也是微不足道的，因此，不要沉浸于痛苦不能自拔，应该积极的通过转移目标方式让自己摆脱痛苦。 论努力与放弃：不要让无所谓的小事影响了自己。尽人事，听天命，不要感情用事。 《论人类不平等的起源和基础》：社会产生之后不平等就开始了 ​ 读书摘抄： 如果我们从这些不同的变革中去寻找不平等发展的足迹，我们会发现法律和私有财产权的形成是不平等形成的第一阶段；法官的设立是第二阶段；而第三个也是最后一个阶段，则是合法权利向专制权力的转变。因此，第一个阶段催生的是贫富的差距，第二个阶段造就的是强弱的悬殊，而第三个阶段诞生的则是主人与奴隶的对立。主人与奴隶的对立正是不平等的最后阶段，是所有其他不平等终将抵达的彼岸。这一阶段将一直持续，直到新的革命将政府彻底瓦解或者使其向合法制度靠拢为止。 如果所有未经堕落与变质的政府都能做到不忘初心，严格按照成立之初的目的行事，那么，这个政府的成立通常就不是必需的；在一个国家里，如果没有任何人规避法律、滥用司法，那么这个国家是既不需要法官也不需要法律的。 社会的产生是人类之间互相联系的增加，联系更加紧密之后就避免不了对比与竞争对手有对比和竞争就会有不公平。相反，原始人反而是孤独而平等的。 富人为了让穷人从奴隶身份解放出来，创建了政府，但其实，富人只是为了防止奴隶因为不平等而反抗，所以所谓民主政府的建立并非平等。 《后物欲时代的来临》：人们是如何掉进消费主义陷阱的 在我看来，这本书主要是对“消费主义陷阱”的诠释。我是在看费孝通大佬的《江村经济》时，在书序中发现的这本书，感觉让我眼前一亮的干货没有很多，唯一记住的一段有意思的观点是：“鲍曼：这一社会的精神特质宣告:假如你心情低落，那就吃。这里发生了一个悖论：因为温饱的解决，发生了空虚和无聊的问题;我们却在解决温饱上面加大砝码，来应对空虚和无聊的问题。”","raw":null,"content":null,"categories":[{"name":"读书","slug":"读书","permalink":"http://fxbing.github.io/categories/%E8%AF%BB%E4%B9%A6/"}],"tags":[{"name":"2021书单","slug":"2021书单","permalink":"http://fxbing.github.io/tags/2021%E4%B9%A6%E5%8D%95/"}]},{"title":"二零二一年十月书单","slug":"二零二一年十月书单","date":"2021-10-31T07:23:11.000Z","updated":"2021-12-04T09:42:27.537Z","comments":true,"path":"2021/10/31/二零二一年十月书单/","link":"","permalink":"http://fxbing.github.io/2021/10/31/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E5%8D%81%E6%9C%88%E4%B9%A6%E5%8D%95/","excerpt":"十一长假加休假的一个月，读书量变少了🐶。","text":"十一长假加休假的一个月，读书量变少了🐶。 📚以下书籍出现的顺序代表我对这些书的评分排序。 《被讨厌的勇气》：厘清自己的课题并做好它 ​ 这本书通过长者与青年对话的形式，对阿德勒心理学进行了通俗并深刻的解释，总结起来，主要包含以下几个方面： 人生目标：人生不是与他人比赛，不要有和他人的竞争意识，只需要与理想的自己比较就可以了。健全的自卑感也不是来自于和他人的比较，而是来自于理想的自己的比较。竞争意识不仅会让我们拘泥于胜负而无法做出正确的选择，而且还会让我们增加很多不正常的自卑或者自大的感觉。 人际关系：基本上，一切人际关系矛盾都起因于对别人的课题妄加干涉或者自己的课题被别人妄加干涉。处理人际关系的第一步，要考虑“这是谁的课题”，如果是自己的，不要因为别人的看法来影响自己的决断，如果是别人的，不要对别人的课题过度干涉。依赖或者干涉别人都是没有将彼此放在同一水平的表现，是在潜意识中认为别人比自己高一等或者自己比较别人高一等。但其实人与人之间是平等的，可能有社会层面的长幼尊卑，而作为人，是不存在等级差别的。这个道理不仅限于朋友之间，也包括家人之间甚至父母和子女之间，比如：父母可以在子女需要时提供帮助，但是不能够干涉子女的选择，并且不论是夸奖还是批评，都是一种心理上比子女高一等表现。 自我定位：自己永远是一个独立的个体，不应该依附于任何人，也不比任何人更高级，要让自己在自立的前提下与社会和谐相处。与别人比较、按照别人的看法生活确实会比明确自己的目标更为简单，但这种懒惰是一种不正常的心理。另外，拼命寻求认可也是以自己为中心的不正确表现，与自大一样，都是想要过度强调自己在集体中的地位。 人生意义：“我”是自己人生的主人公，同时也是共同体的一员，是整体的一部分。这里的“共同体”，不是一个家庭、一个学校、一个公司这样的小团体，而是全人类、整个宇宙甚至包含一草一木。当把自己作为自己人生的主人公时，就不会因为别人对自己的评价和看法对自己的心理和决策产生干扰。当把自己作为共同体中普通的一员时，自己才不会因为自己的经里而自卑或自大，才不会去过度干涉别人的课题。要记住，人生只取决于当下，无论之前发生过什么（成功或苦难），都对今后的人生如何度过没有影响。 《一句顶一万句》：平凡琐碎生活中有深刻的感悟 ​ 这本刘震云的小说，被称为“中国版的《百年孤独》”，就像是邻居唠家常，讲述谁家谁谁谁怎么怎么样了，但是简单的生活中却又包含着许多的感悟。这本中最核心的观点，就是人与人之间是不是可以“说到一起去”，朋友之间能不能“说到一起去”可以决定能不能一直成为朋友，夫妻之间能不能“说到一起去”可以决定生活会不会幸福。可能一路走来，会发现能够一直“说到一起去”的人少之又少，但是“日子过的是往后，不是从前。”","raw":null,"content":null,"categories":[{"name":"读书","slug":"读书","permalink":"http://fxbing.github.io/categories/%E8%AF%BB%E4%B9%A6/"}],"tags":[{"name":"2021书单","slug":"2021书单","permalink":"http://fxbing.github.io/tags/2021%E4%B9%A6%E5%8D%95/"}]},{"title":"二零二一年九月书单","slug":"二零二一年九月书单","date":"2021-10-03T10:15:48.000Z","updated":"2021-10-03T10:18:21.518Z","comments":true,"path":"2021/10/03/二零二一年九月书单/","link":"","permalink":"http://fxbing.github.io/2021/10/03/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E4%B9%9D%E6%9C%88%E4%B9%A6%E5%8D%95/","excerpt":"国庆假期补上了第三篇书单。","text":"国庆假期补上了第三篇书单。 📚以下书籍出现的顺序代表我对这些书的评分排序。 《乡土中国》 ​ 费孝通经典作品。一本社会学的书，对我来说，更重要的引发辩证的思考：乡土文化并不是封建守旧，而是在安土重迁的思想下下产生的社会文化，乡土文化在不变的社会中是没有问题的，但是在现代社会，已经不同于原来的社会模式，所以也要适当的思考乡土文化中的哪些内容应当予以改变或摒弃。 《江村经济》 ​ 这本也是费老的书，费老用两个月的时间调查开弦弓村，完成了这篇著作。介绍上说对中国社会学的发展具有重要意义，也只能从门外汉自己的角度说一说感受： 虽然调查只有两个月，但是从描述上可以看出，调查相当翔实，并且文笔上没有冗余的文字，虽然描述不多，但是可以清楚地感受到费老想要展现的内容。 这本书详细描述的一个乡村文化、经济、政治等各个方面内容，是一种十分详细的封建农村生活的真实写照，比小说之类看得更为有画面。 读完上面两本书的感受是，不论是封建传统的思想还是前卫现代的思想，都有其产生的根源，不能单纯的说哪一个更为正确，而是要客观地认识其产生的原因，以及这种文化在当前情况下适合或者不再适合的原因。 《人生海海》 ​ 麦家作品，前后封皮的描述足以概括这本小说的内容。 人生海海，潮落之后是潮起，你说那是消磨、笑柄、罪过，到那就是我的英雄主义。 他是全村最出奇古怪的人，古怪的名目要扳着指头个个数 第一，他当过国民党军队的上校，是革命群众要争的对象。但大家一边斗争他，一边又巴结讨好他，家里出什么事都去我他拿主意。 第二，说他是太监，可我们小孩子经常偷看他那个地方好像还是满当当的，有模有样的。 第三，他向来不出工，不干农活，天天空在家里看报纸瓜子可日子过得比谁家都舒坦。还像养孩子一样养着一对猫，宝贝得不得了，简直神经病！ 《人生海海》讲述了一个人在时代中穿行缠斗的一生，离奇的故事里藏着让人叹息的人生况味，既有日常滋生的残酷，也有时间带来的仁慈。 《活出生命的意义》 ​ 这本书分为两个部分，第一部分是作者在奥斯维辛集中营中经历的描写，以及一些感悟，第二部分则是纯心理学方面的讲述。 ​ “由于生命中每一种情况对人来说都是一种挑战，都会提出需要你去解决的问题，所以生命之意义的问题实际上被颠倒了。人不应该问他的生命之意义是什么，而必须承认是生命向他提出了间题。简单地说，生命对每个人都提出了问题，他必须通过对自己生命的理解来回答生命的提问。对待生命，他只能担当起自己的责任。”负责任，就是自己生命的意义。 《自私的基因》 本以为是一本心理学的书，实际上更像是一本生物学的科普书籍，并不是很感兴趣。作者将基因定义为进化的基本单位，结合博弈论，从各个方面讲述了基因是如何保证物种稳定的。","raw":null,"content":null,"categories":[{"name":"读书","slug":"读书","permalink":"http://fxbing.github.io/categories/%E8%AF%BB%E4%B9%A6/"}],"tags":[{"name":"2021书单","slug":"2021书单","permalink":"http://fxbing.github.io/tags/2021%E4%B9%A6%E5%8D%95/"}]},{"title":"二零二一年八月书单","slug":"二零二一年八月书单","date":"2021-08-28T10:07:53.000Z","updated":"2021-08-28T10:18:47.760Z","comments":true,"path":"2021/08/28/二零二一年八月书单/","link":"","permalink":"http://fxbing.github.io/2021/08/28/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E5%85%AB%E6%9C%88%E4%B9%A6%E5%8D%95/","excerpt":"第二篇书单如期而至。","text":"第二篇书单如期而至。 📚以下书籍出现的顺序代表我对这些书的评分排序。 《蛤蟆先生去看心理医生》 ​ 一本以寓言故事的形式讲心理学的书，这个寓言故事并不是讲给孩子的，而是讲给大人的。书中提到了一组很有意思的概念： 儿童自我状态：“孩子是成年人的父亲”，其实人们成年后的很多思维方式和行为方式都是孩子时的写照。 父母自我状态：成年后的思维方式和行为方式以模仿自己的父母进行。 成人自我状态：指我们用理性而不是情绪化的方式行事。 ​ 反思自己和周围的人，会发现确实会有处于儿童状态，或者父母状态的情况，毕竟一方面无法抛弃自己的过往，另一方面父母又是孩子的老师。之所以处于这两种状态，是因为儿童和父母状态是不需要思考的，自己的思维或者行为就像是表演，表演自己所熟悉的东西。但同时，这两种状态又是最差的，因为没有思考就不会学习。只有处于成人状态下，我们才能够进行学习，才能应对此时正在发生的现实状况。 ​ 我们生活的样子就是我们自己想成为的样子，而不是别人造就了我们的生活。要想更幸福，就需要有足够的情商。情商真正的意思是：了解你内心的情感世界并且还能掌控它。 《牧羊少年的奇幻之旅》 ​ 一本奇幻的书，此处借用豆瓣网友Big Ben的短评：“《小王子》教你放下执念，而《牧羊少年奇幻之旅》是教你寻找执念；两种不同的方法，确有着相同的目的。重点不是你在这个世界上寻找什么，而是在过程中明白什么是不可丢弃的，那将是你生命的意义所在，超越一切，一旦了白于心，就将于永恒同在。” ​ 不要放弃自己的“执念”，需要向其前进。现在的生活中，在一无所有时，可能会怀着有钱之后周游世界的梦想，但是在足够富有之后，因为会渴望更加富有，或者因为害怕风险，只选择相比周游世界更加平稳的享受当下的幸福。前进的过程中，可能会有很多的收获，甚至到达大众所谓的成功，但是这本书要说的不是前进过程中的收获，而是收获到这些附加东西之后，仍然不要忘记自己的“执念”，为了不让自己在看似优渥的生活中留下遗憾，也为了“执念”实现之后意义。 ​ 用书中不断重复的一个阿拉伯语来总结和思考：“马克图布”，可以理解为：命中注定。 《心流》 ​ 这本书的序言确实挺长的，不到400页的书，序言就有50多页🐶。“心流”是积极心理学中的重要概念，是指我们在做某些事情时，那种全神贯注、投入忘我的状态——这种状态下，你甚至感觉不到时间的存在，在这件事情完成之后我们会有一种充满能量并且非常满足的感受。在我们的正常生活中，每个人都会有心流体验，只是多与少的区别，比如：中学上电脑课玩游戏时🐶、没有杂事干扰只有自己一个人专心写代码时🐶。这本书讲的是如何让自己尽可能多得体验心流，下面是一些书中观点的笔记： 大部分人的心流体验来自于工作而非休息。 享乐与乐趣不同，享乐不需要消耗精神能量，而乐趣需要。 竞争只有在它以使个人技巧臻于完美为目标时，才有乐趣；当它本身成为目的时，就不再有乐趣了。 记忆的重要性：记忆足够充足的人，可以不需要外界刺激而保持心流。 未来不仅属于受过教育的人，更属于那些懂得善用闲暇的人。 培养自得其乐的性格：确立目标、全神贯注、避免过于自我、从当前体验中寻找乐趣。 《政治是什么？》 ​ 这是一本台湾人写的政治普及书籍。这本书对政治中的各种概念进行介绍，并且从作者的角度，结合各种观点进行了客观的分析。作者的表达中不会带着对哪种政治制度的偏见，读这本书的过程确实可以引发自己一些关于政治知识的思考，但是却感觉缺乏主线。下面只列举一些我在读书过程中思考记录的想法： 政治是可以在违背他人意愿的情况下实现自己目的的可能性，分为“强制性权力”（例如：武力）和“象征性权力”（例如：信仰），相比强制性权力，象征性权力更会让人们潜意识服从，更不容易反抗推翻。 意识形态可以决定人们是否接受你成为领袖，而能否真正满足人们的需求才是决定你是否可以一直成为领袖的因素。因此，稳固的政治不仅需要一个好的意识形态（借口），还需要让人们感受到自己需求得到满足。 国家并不能称为实体，甚至是一个模糊的概念，比如古代各个国家之间并没有绝对明确的地理划分，也不需要签证。之所以现在这一切变得复杂，是因为各个国家之间的交流过于紧密，如果没有明确的边界感，就会产生争端，为了明确边界感，一个国家需要拥有被其他国家承认的“主权”，如：一个国家的居民必须要有户口等。为什么人不需要说我承认你是人，你才是人？而国家必须要拥有被其他国家承认的主权才是国家？因为人本来就是一个实体，有明确的边界感，而国家本身并非实体，而是一种概念，必须有各种条条框框才能被理解为实体。 《什么是民粹主义？》 ​ 这本书感觉像是一本表达作者本人政治观点的书籍，可能由于我政治知识不够，并没有兴趣读完整本书，只能依照自己的感觉描述一下对这本书的理解。 ​ 根据维基百科的解释，民粹主义通常是精英主义的反义词。在古希腊城邦发明民主制度之后，对于应由精英、贵族还是一般大众来掌握政治，出现了争论。支持民粹主义者则诉求直接民主与基层民主，认为政治精英（当下或未来）只追求自身利益，腐化且不可相信，希望由人民直接决定政治事务。 ​ 这本书作者认为，民粹主义者的本质不是反精英、反多元化、反建制等等，而是对“人民”的定义，民粹主义者们一方面认为只有他们才能代表人民的利益，另一方面又认为只有支持他们的人才算做“人民”，可谓是假民主、真偏见。 ​ 从《你当像鸟飞往你的山》、《蛤蟆先生去看心理医生》和《心流》三本书中都可以看到掌握自己的重要性。了解自己，接纳他人，可以控制自己的情感和思维不被外界干扰，同时又可以完全平和地接纳他人的观点，这是一种很强大的能力，感觉自己现在远远不及，也是自己心理上努力的方向。","raw":null,"content":null,"categories":[{"name":"读书","slug":"读书","permalink":"http://fxbing.github.io/categories/%E8%AF%BB%E4%B9%A6/"}],"tags":[{"name":"2021书单","slug":"2021书单","permalink":"http://fxbing.github.io/tags/2021%E4%B9%A6%E5%8D%95/"}]},{"title":"kafka日志清理引发的core dump问题","slug":"kafka日志清理引发的core-dump问题","date":"2021-08-15T09:55:46.000Z","updated":"2021-08-15T10:44:07.168Z","comments":true,"path":"2021/08/15/kafka日志清理引发的core-dump问题/","link":"","permalink":"http://fxbing.github.io/2021/08/15/kafka%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86%E5%BC%95%E5%8F%91%E7%9A%84core-dump%E9%97%AE%E9%A2%98/","excerpt":"​    团队开发了kafka on hdfs的功能，用以将kafka数据存储在hdfs上，但是在使用的过程中发现，有机器出现core dump现象。","text":"​ 团队开发了kafka on hdfs的功能，用以将kafka数据存储在hdfs上，但是在使用的过程中发现，有机器出现core dump现象。 本文基于kafka版本0.10.2 排查过程 一、排查core dump文件 由于出现了多次core dump问题，所以首先需要从core dump文件中进行分析。从core dump文件可以看出，以下几个问题： 挂掉的线程名称都是hdfs相关的，所以推测与hdfs相关功能有关 挂掉的代码位置都与index读取逻辑有关，所以推测和index清理逻辑有关 二、分析代码 ​ 分析kafka本地日志删除的代码发现，本地日志删除通过asyncDeleteSegment进行，asyncDeleteSegment进行删除时首先会rename本地日志文件和索引文件，然后延迟一定时间进行删除。 12345678910111213141516171819202122232425262728293031323334353637383940/** a file that is scheduled to be deleted */ val DeletedFileSuffix = &quot;.deleted&quot;/** * Perform an asynchronous delete on the given file if it exists (otherwise do nothing) * * @throws KafkaStorageException if the file can&#x27;t be renamed and still exists */ private def asyncDeleteSegment(segment: LogSegment) &#123; segment.changeFileSuffixes(&quot;&quot;, Log.DeletedFileSuffix) def deleteSeg() &#123; info(&quot;Deleting segment %d from log %s.&quot;.format(segment.baseOffset, name)) segment.delete() &#125; scheduler.schedule(&quot;delete-file&quot;, deleteSeg, delay = config.fileDeleteDelayMs) &#125;/** * Change the suffix for the index and log file for this log segment */ def changeFileSuffixes(oldSuffix: String, newSuffix: String) &#123; def kafkaStorageException(fileType: String, e: IOException) = new KafkaStorageException(s&quot;Failed to change the $fileType file suffix from $oldSuffix to $newSuffix for log segment $baseOffset&quot;, e) try log.renameTo(new File(CoreUtils.replaceSuffix(log.file.getPath, oldSuffix, newSuffix))) catch &#123; case e: IOException =&gt; throw kafkaStorageException(&quot;log&quot;, e) &#125; try index.renameTo(new File(CoreUtils.replaceSuffix(index.file.getPath, oldSuffix, newSuffix))) catch &#123; case e: IOException =&gt; throw kafkaStorageException(&quot;index&quot;, e) &#125; try timeIndex.renameTo(new File(CoreUtils.replaceSuffix(timeIndex.file.getPath, oldSuffix, newSuffix))) catch &#123; case e: IOException =&gt; throw kafkaStorageException(&quot;timeindex&quot;, e) &#125; &#125; ​ 但是在hdfs相关的清理功能中，直接进行的日志清理而没有rename和delay操作，所以推测清理日志和索引时，如果文件仍被读取，强行删除会导致core dump。 三、测试结论 编写单测，本地索引lookup过程中强行删除索引文件，确实出现了core dump现象。 解决方案 仿照本地日志的清理策略，在hdfs相关的逻辑中，不直接删除文件，而是先rename文件，然后再延迟一定时间进行删除。 总结 本次问题的出现属于偶发现象，只有在kafka consumer消费lag，读取即将被删除的日志时才有可能会发生。 core dump问题分析的过程中需要通过多个case的相似点来分析问题。","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://fxbing.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://fxbing.github.io/tags/kafka/"},{"name":"问题排查","slug":"问题排查","permalink":"http://fxbing.github.io/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"}]},{"title":"二零二一年七月书单","slug":"二零二一年七月书单","date":"2021-08-15T08:58:12.000Z","updated":"2021-08-15T09:08:39.753Z","comments":true,"path":"2021/08/15/二零二一年七月书单/","link":"","permalink":"http://fxbing.github.io/2021/08/15/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E4%B8%83%E6%9C%88%E4%B9%A6%E5%8D%95/","excerpt":"​    这是我的第一次书单总结，希望以后每个月都能有一次书单总结将自己读过的书记录下来。","text":"​ 这是我的第一次书单总结，希望以后每个月都能有一次书单总结将自己读过的书记录下来。 📚以下书籍出现的顺序代表我对这些书的评分排序。 《朝闻道》 相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长 ​ 宇宙排险者的职责是负责排除宇宙中存在的知识的巨大发展，因为当人们获取到更多的宇宙奥秘时，对宇宙也更加危险。人类第一次触发排险者报警是因为原始人类第一次仰望星空，因为，“当生命意识到宇宙奥秘的存在时，距它最终解开这个奥秘只有一步之遥。” “朝闻道夕死可矣” ​ 这是一句论语中的话，老刘从科幻的角度进行了解释。宇宙排险者的工作是阻止人们获取宇宙的奥秘，防止宇宙被破坏。宇宙排险者知道宇宙的奥秘，却不能告诉人类。丁仪想到了可以既能得到宇宙的终极奥秘，又不违反宇宙排险者的职责的方法：“把宇宙的终极奥秘告诉我，然后再毁灭我。”之后便有大量的顶级学者前赴后继地选择得到宇宙的奥秘然后死去。 ​ 在我看来，普通人不会参与、选择“朝闻道夕死”，是因为越是有知识的人，才会知道自己不知道什么，人们的学习过程，不是一个从“不知道”到“知道”的过程，而是一个“不知道自己不知道”到“知道自己不知道”的过程，普通人“知道自己不知道”的东西，还远到不了需要宇宙排险者来解答的程度。 ​ 但是，如果成为了顶级学者，是否又真的能选择“朝闻道夕死可矣”？ 《你当像鸟飞往你的山》 ​ 这本书讲述了一个女孩关于原生家庭的自述，在她的家里有暴力狂的哥哥、不让孩子受教育的父亲、只会听从父亲话的母亲，十七岁前从未上过学，现在却成为了剑桥大学的博士。虽然主要是作者自身经历的描写，但是作者心路历程的变化清晰可见。从作者心路历程的变化中也可以看到许多关于原生家庭的道理，这些道理在原生家庭与现实世界的冲突没有那么严重时是不容易触及的。 原生家庭的影响很难改变 ​ 作者的成长过程中，即便读书使她见到了更加广阔的世界，认识到父亲那些顽固的观点（读书不好，政府不好，医院里的医生都是恶魔等）不是正确的，但是依旧会对当下的生活持有怀疑，怀疑现在的世界是否真的如父亲所讲。 一个人从不好的原生家庭中走出后总是会想着帮助家人改变 ​ 当作者离开原生家庭，外出读书，知道了生病就应该去医院，知道到了指定年龄就应该去读书。虽然对原生家庭怀有恨意，但是仍然很想帮助他们，让他们知道什么是对的，什么是不对的，想让妹妹去上学，想让母亲不迷恋草药去相信医院。 相比于外界的认可，自我认可才更为重要 ​ 逃离原生家庭的过程中面临着种种困难，来到外面的世界后，作者会有各种不适应，自卑，格格不入的感觉，认为别人听到她的人生经历会不理解，看不起她。其实不然，真正的困难从来不是来自于外界，而是自己，自己都无法认可自己时怎么能到到外界的认可，反之，当自己可以认可自己时，外界的认可也便不再那么重要。 《非暴力沟通》 ​ 这本书介绍了一种沟通模式，不论是表达自己还是倾听他人，都要遵循以下四个步骤：观察、感受、需要、请求。需要在平时的沟通中提醒自己，按照下面的模式进行。 诚实地表达自己，而不批评、指责 观察我所观察（看、听、回忆、想）到的有助于（或无助于）我的福祉的具体行为：“当我（看、听、想到我看到的/听到的）……” 感受对于这些行为，我有什么样的感受（情感而非思想）：“我感到……” 需要什么样的需要或价值（而非偏好或某种具体的行为）导致我那样的感受：“因为我需要/看重……” 请求清楚地请求（而非命令）那些能丰富我生命的具体行为，“你是否愿意……？” 关切地倾听他人，而不解读为批评或指责 观察你所观察（看、听、回忆、想）到的有助于（或无助于）你的福祉的具体行为：“当你（看、听、想到你看到的/听到的）……” 感受对于这些行为，你有什么样的感受（是情感而非思想）：“你感到……吗？” 需要什么样的需要或价值（而非偏好或某种具体的行为）导致你那样的感受：“因为你需要/看重……” 请求关切地倾听那些能丰富你生命的具体请求，而不解读为命令：“所以，你想……” 《代码整洁之道》 ​ 从命名规范、注释、代码规范等各个方面介绍了如果写出一份好的代码，其中有许多内容其实在实际编码过程中已经遵守，只不过自己没有意识到，没有系统化的梳理，但是也存在需要自己没有意识到的事情，比如：尽量避免在函数参数中使用布尔型变量来区分不同功能，而是要写成两个名称不同的函数。代码不只是写给自己的，除了功能正确外，可读性强也是好代码的标准，按照书上的总结进行执行，让自己的代码更好。 《指数基金投资指南》 ​ 这本书可以算一个指数基金的科普手册，通过这本书可以了解大部分主要的指数基金类型的基本知识，并且给出一些投资方面的建议。指数基金的投资，关键还是要稳定投资，长期持有。 《我的第一本人生规划手册》 ​ 这本书更像是一个公众号文章的合集，它会告诉你要赚钱，要规划，会告诉你什么样的目标在每个阶段应该赚得多少钱，但是并没有什么实质性的建议，每个人的实际情况并不相同，每个人需要考虑、选择、努力的事情也并不相同，重要还是自己认真的思考，然后脚踏实地好好努力。","raw":null,"content":null,"categories":[{"name":"读书","slug":"读书","permalink":"http://fxbing.github.io/categories/%E8%AF%BB%E4%B9%A6/"}],"tags":[{"name":"2021书单","slug":"2021书单","permalink":"http://fxbing.github.io/tags/2021%E4%B9%A6%E5%8D%95/"}]},{"title":"kafka源码学习：KafkaApis-LEADER_AND_ISR","slug":"kafka源码学习：KafkaApis-LEADER-AND-ISR","date":"2021-06-05T10:00:12.000Z","updated":"2021-06-05T12:09:27.405Z","comments":true,"path":"2021/06/05/kafka源码学习：KafkaApis-LEADER-AND-ISR/","link":"","permalink":"http://fxbing.github.io/2021/06/05/kafka%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9AKafkaApis-LEADER-AND-ISR/","excerpt":"\n本文源码基于kafka 0.10.2版本\n\n​    每当controller发生状态变更时，都会通过调用sendRequestsToBrokers方法发送leaderAndIsrRequest请求，本文主要介绍kafka服务端处理该请求的逻辑和过程。","text":"本文源码基于kafka 0.10.2版本 ​ 每当controller发生状态变更时，都会通过调用sendRequestsToBrokers方法发送leaderAndIsrRequest请求，本文主要介绍kafka服务端处理该请求的逻辑和过程。 LEADER_AND_ISR 整体逻辑流程 1case ApiKeys.LEADER_AND_ISR =&gt; handleLeaderAndIsrRequest(request) 在server端收到LEADER_AND_ISR请求后，会调用handleLeaderAndIsrRequest方法进行处理，该方法的处理流程如图所示： 源码 handleLeaderAndIsrRequest handleLeaderAndIsrRequest函数的逻辑结果主要分为以下几个部分： 构造callback函数onLeadershipChange,用来回调coordinator处理新增的leader或者follower节点 校验请求权限，如果校验成功调用replicaManager.becomeLeaderOrFollower(correlationId, leaderAndIsrRequest, metadataCache, onLeadershipChange)进行后续处理【此处该函数的主流程】，否则，直接返回错误码Errors.CLUSTER_AUTHORIZATION_FAILED.code 1234567891011121314151617181920212223242526272829303132333435363738def handleLeaderAndIsrRequest(request: RequestChannel.Request) &#123; // ensureTopicExists is only for client facing requests // We can&#x27;t have the ensureTopicExists check here since the controller sends it as an advisory to all brokers so they // stop serving data to clients for the topic being deleted val correlationId = request.header.correlationId val leaderAndIsrRequest = request.body.asInstanceOf[LeaderAndIsrRequest] try &#123; def onLeadershipChange(updatedLeaders: Iterable[Partition], updatedFollowers: Iterable[Partition]) &#123; // for each new leader or follower, call coordinator to handle consumer group migration. // this callback is invoked under the replica state change lock to ensure proper order of // leadership changes updatedLeaders.foreach &#123; partition =&gt; if (partition.topic == Topic.GroupMetadataTopicName) coordinator.handleGroupImmigration(partition.partitionId) &#125; updatedFollowers.foreach &#123; partition =&gt; if (partition.topic == Topic.GroupMetadataTopicName) coordinator.handleGroupEmigration(partition.partitionId) &#125; &#125; val leaderAndIsrResponse = if (authorize(request.session, ClusterAction, Resource.ClusterResource)) &#123; val result = replicaManager.becomeLeaderOrFollower(correlationId, leaderAndIsrRequest, metadataCache, onLeadershipChange) new LeaderAndIsrResponse(result.errorCode, result.responseMap.mapValues(new JShort(_)).asJava) &#125; else &#123; val result = leaderAndIsrRequest.partitionStates.asScala.keys.map((_, new JShort(Errors.CLUSTER_AUTHORIZATION_FAILED.code))).toMap new LeaderAndIsrResponse(Errors.CLUSTER_AUTHORIZATION_FAILED.code, result.asJava) &#125; requestChannel.sendResponse(new Response(request, leaderAndIsrResponse)) &#125; catch &#123; case e: KafkaStorageException =&gt; fatal(&quot;Disk error during leadership change.&quot;, e) Runtime.getRuntime.halt(1) &#125; &#125; becomeLeaderOrFollower ReplicaManager的主要工作有以下几个部分，具体代码位置见中文注释： 校验controller epoch是否合规，只处理比自己epoch大且本地有副本的tp的请求 调用makeLeaders和makeFollowers方法构造新增的leader partition和follower partition【此处为主要逻辑，后面小结详细介绍】 如果是第一次收到请求，启动定时更新hw的线程 停掉空的Fetcher线程 调用回调函数，coordinator处理新增的leader partition和follower partition 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283def becomeLeaderOrFollower(correlationId: Int,leaderAndISRRequest: LeaderAndIsrRequest, metadataCache: MetadataCache, onLeadershipChange: (Iterable[Partition], Iterable[Partition]) =&gt; Unit): BecomeLeaderOrFollowerResult = &#123; leaderAndISRRequest.partitionStates.asScala.foreach &#123; case (topicPartition, stateInfo) =&gt; stateChangeLogger.trace(&quot;Broker %d received LeaderAndIsr request %s correlation id %d from controller %d epoch %d for partition [%s,%d]&quot; .format(localBrokerId, stateInfo, correlationId, leaderAndISRRequest.controllerId, leaderAndISRRequest.controllerEpoch, topicPartition.topic, topicPartition.partition)) &#125; //主要代码，构造返回结果 replicaStateChangeLock synchronized &#123; val responseMap = new mutable.HashMap[TopicPartition, Short] //如果controller epoch不正确，直接返回Errors.STALE_CONTROLLER_EPOCH.code错误码 if (leaderAndISRRequest.controllerEpoch &lt; controllerEpoch) &#123; stateChangeLogger.warn((&quot;Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d since &quot; + &quot;its controller epoch %d is old. Latest known controller epoch is %d&quot;).format(localBrokerId, leaderAndISRRequest.controllerId, correlationId, leaderAndISRRequest.controllerEpoch, controllerEpoch)) BecomeLeaderOrFollowerResult(responseMap, Errors.STALE_CONTROLLER_EPOCH.code) &#125; else &#123; val controllerId = leaderAndISRRequest.controllerId controllerEpoch = leaderAndISRRequest.controllerEpoch // First check partition&#x27;s leader epoch //校验所有的partition信息，分为以下3种情况： //1. 本地不包含该partition，返回Errors.UNKNOWN_TOPIC_OR_PARTITION.code //2. 本地包含该partition，controller epoch比本地epoch大，信息正确 //3. controller epoch比本地epoch小，返回Errors.STALE_CONTROLLER_EPOCH.code val partitionState = new mutable.HashMap[Partition, PartitionState]() leaderAndISRRequest.partitionStates.asScala.foreach &#123; case (topicPartition, stateInfo) =&gt; val partition = getOrCreatePartition(topicPartition) val partitionLeaderEpoch = partition.getLeaderEpoch // If the leader epoch is valid record the epoch of the controller that made the leadership decision. // This is useful while updating the isr to maintain the decision maker controller&#x27;s epoch in the zookeeper path if (partitionLeaderEpoch &lt; stateInfo.leaderEpoch) &#123; if(stateInfo.replicas.contains(localBrokerId)) partitionState.put(partition, stateInfo) else &#123; stateChangeLogger.warn((&quot;Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d &quot; + &quot;epoch %d for partition [%s,%d] as itself is not in assigned replica list %s&quot;) .format(localBrokerId, controllerId, correlationId, leaderAndISRRequest.controllerEpoch, topicPartition.topic, topicPartition.partition, stateInfo.replicas.asScala.mkString(&quot;,&quot;))) responseMap.put(topicPartition, Errors.UNKNOWN_TOPIC_OR_PARTITION.code) &#125; &#125; else &#123; // Otherwise record the error code in response stateChangeLogger.warn((&quot;Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d &quot; + &quot;epoch %d for partition [%s,%d] since its associated leader epoch %d is not higher than the current leader epoch %d&quot;) .format(localBrokerId, controllerId, correlationId, leaderAndISRRequest.controllerEpoch, topicPartition.topic, topicPartition.partition, stateInfo.leaderEpoch, partitionLeaderEpoch)) responseMap.put(topicPartition, Errors.STALE_CONTROLLER_EPOCH.code) &#125; &#125; //处理leader&amp;follower副本，构造partitionsBecomeLeader和partitionsBecomeFollower供callback处理（coordinator处理） val partitionsTobeLeader = partitionState.filter &#123; case (_, stateInfo) =&gt; stateInfo.leader == localBrokerId &#125; val partitionsToBeFollower = partitionState -- partitionsTobeLeader.keys val partitionsBecomeLeader = if (partitionsTobeLeader.nonEmpty) // 主要调用 makeLeaders(controllerId, controllerEpoch, partitionsTobeLeader, correlationId, responseMap) else Set.empty[Partition] val partitionsBecomeFollower = if (partitionsToBeFollower.nonEmpty) // 主要调用 makeFollowers(controllerId, controllerEpoch, partitionsToBeFollower, correlationId, responseMap, metadataCache) else Set.empty[Partition] // we initialize highwatermark thread after the first leaderisrrequest. This ensures that all the partitions // have been completely populated before starting the checkpointing there by avoiding weird race conditions // 在第一次收到收到请求后，就会启动Scheduler，定时更新hw checkpoint if (!hwThreadInitialized) &#123; startHighWaterMarksCheckPointThread() hwThreadInitialized = true &#125; // 因为上面更新了元信息，此处检查停掉不必要的Fetcher线程 replicaFetcherManager.shutdownIdleFetcherThreads() // 回调 onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower) BecomeLeaderOrFollowerResult(responseMap, Errors.NONE.code) &#125; &#125;&#125; makeLeaders 处理新增的leader partition 停止这些partition的follower线程 更新这些partition的metadata cache 构造新增leader集合 123456789101112131415161718192021222324252627282930313233343536373839private def makeLeaders(controllerId: Int, epoch: Int, partitionState: Map[Partition, PartitionState], correlationId: Int, responseMap: mutable.Map[TopicPartition, Short]): Set[Partition] = &#123; // 构造becomeLeaderOrFollower需要的返回结果 for (partition &lt;- partitionState.keys) responseMap.put(partition.topicPartition, Errors.NONE.code) val partitionsToMakeLeaders: mutable.Set[Partition] = mutable.Set() try &#123; // First stop fetchers for all the partitions // 停止Fetcher线程 replicaFetcherManager.removeFetcherForPartitions(partitionState.keySet.map(_.topicPartition)) // Update the partition information to be the leader // 构造新增leader partition集合 partitionState.foreach&#123; case (partition, partitionStateInfo) =&gt; if (partition.makeLeader(controllerId, partitionStateInfo, correlationId)) partitionsToMakeLeaders += partition else stateChangeLogger.info((&quot;Broker %d skipped the become-leader state change after marking its partition as leader with correlation id %d from &quot; + &quot;controller %d epoch %d for partition %s since it is already the leader for the partition.&quot;) .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition)) &#125; &#125; &#125; catch &#123; case e: Throwable =&gt; partitionState.keys.foreach &#123; partition =&gt; val errorMsg = (&quot;Error on broker %d while processing LeaderAndIsr request correlationId %d received from controller %d&quot; + &quot; epoch %d for partition %s&quot;).format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition) stateChangeLogger.error(errorMsg, e) &#125; // Re-throw the exception for it to be caught in KafkaApis throw e &#125; partitionsToMakeLeaders &#125; partition.makeLeader(controllerId, partitionStateInfo, correlationId)会进行元信息的处理，并更新hw，此方法会调用maybeIncrementLeaderHW函数，该函数会尝试追赶hw：如果其他副本落后leader不太远，并且比之前的hw大，会延缓hw增长速度，尽可能让其他副本进队。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def makeLeader(controllerId: Int, partitionStateInfo: PartitionState, correlationId: Int): Boolean = &#123; val (leaderHWIncremented, isNewLeader) = inWriteLock(leaderIsrUpdateLock) &#123; val allReplicas = partitionStateInfo.replicas.asScala.map(_.toInt) // record the epoch of the controller that made the leadership decision. This is useful while updating the isr // to maintain the decision maker controller&#x27;s epoch in the zookeeper path controllerEpoch = partitionStateInfo.controllerEpoch // add replicas that are new // 构造新ISR allReplicas.foreach(replica =&gt; getOrCreateReplica(replica)) val newInSyncReplicas = partitionStateInfo.isr.asScala.map(r =&gt; getOrCreateReplica(r)).toSet // remove assigned replicas that have been removed by the controller // 移除所有不在新ISR中的副本 (assignedReplicas.map(_.brokerId) -- allReplicas).foreach(removeReplica) inSyncReplicas = newInSyncReplicas leaderEpoch = partitionStateInfo.leaderEpoch zkVersion = partitionStateInfo.zkVersion //是否第一次成为该partition的leader val isNewLeader = if (leaderReplicaIdOpt.isDefined &amp;&amp; leaderReplicaIdOpt.get == localBrokerId) &#123; false &#125; else &#123; leaderReplicaIdOpt = Some(localBrokerId) true &#125; val leaderReplica = getReplica().get val curLeaderLogEndOffset = leaderReplica.logEndOffset.messageOffset val curTimeMs = time.milliseconds // initialize lastCaughtUpTime of replicas as well as their lastFetchTimeMs and lastFetchLeaderLogEndOffset. //新leader初始化 (assignedReplicas - leaderReplica).foreach &#123; replica =&gt; val lastCaughtUpTimeMs = if (inSyncReplicas.contains(replica)) curTimeMs else 0L replica.resetLastCaughtUpTime(curLeaderLogEndOffset, curTimeMs, lastCaughtUpTimeMs) &#125; // we may need to increment high watermark since ISR could be down to 1 if (isNewLeader) &#123; // construct the high watermark metadata for the new leader replica leaderReplica.convertHWToLocalOffsetMetadata() // reset log end offset for remote replicas assignedReplicas.filter(_.brokerId != localBrokerId).foreach(_.updateLogReadResult(LogReadResult.UnknownLogReadResult)) &#125; // 尝试追赶hw,如果其他副本落后leader不太远，并且比之前的hw大，会延缓hw增长速度，尽可能让其他副本进队 (maybeIncrementLeaderHW(leaderReplica), isNewLeader) &#125; // some delayed operations may be unblocked after HW changed // hw更新后会处理一些request if (leaderHWIncremented) tryCompleteDelayedRequests() isNewLeader &#125; makeFollowers 处理新增的follower partition 从leaderpartition集合中移除这些partition 标记为follower，阻止producer请求 移除Fetcher线程 根据hw truncate这些partition的本地日志 清理producer和fetch请求 如果没有宕机，从新的leader fetch数据 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586private def makeFollowers(controllerId: Int, epoch: Int, partitionState: Map[Partition, PartitionState], correlationId: Int, responseMap: mutable.Map[TopicPartition, Short], metadataCache: MetadataCache) : Set[Partition] = &#123; partitionState.keys.foreach &#123; partition =&gt; stateChangeLogger.trace((&quot;Broker %d handling LeaderAndIsr request correlationId %d from controller %d epoch %d &quot; + &quot;starting the become-follower transition for partition %s&quot;) .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition)) &#125; // 构造becomeLeaderOrFollower需要的返回结果 for (partition &lt;- partitionState.keys) responseMap.put(partition.topicPartition, Errors.NONE.code) val partitionsToMakeFollower: mutable.Set[Partition] = mutable.Set() try &#123; // TODO: Delete leaders from LeaderAndIsrRequest partitionState.foreach&#123; case (partition, partitionStateInfo) =&gt; val newLeaderBrokerId = partitionStateInfo.leader metadataCache.getAliveBrokers.find(_.id == newLeaderBrokerId) match &#123; // Only change partition state when the leader is available case Some(_) =&gt; // 构造返回结果 if (partition.makeFollower(controllerId, partitionStateInfo, correlationId)) partitionsToMakeFollower += partition else stateChangeLogger.info((&quot;Broker %d skipped the become-follower state change after marking its partition as follower with correlation id %d from &quot; + &quot;controller %d epoch %d for partition %s since the new leader %d is the same as the old leader&quot;) .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch, partition.topicPartition, newLeaderBrokerId)) case None =&gt; // The leader broker should always be present in the metadata cache. // If not, we should record the error message and abort the transition process for this partition stateChangeLogger.error((&quot;Broker %d received LeaderAndIsrRequest with correlation id %d from controller&quot; + &quot; %d epoch %d for partition %s but cannot become follower since the new leader %d is unavailable.&quot;) .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch, partition.topicPartition, newLeaderBrokerId)) // Create the local replica even if the leader is unavailable. This is required to ensure that we include // the partition&#x27;s high watermark in the checkpoint file (see KAFKA-1647) partition.getOrCreateReplica() &#125; &#125;//移除Fetcher线程 replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition)) //根据新hw进行truncate logManager.truncateTo(partitionsToMakeFollower.map &#123; partition =&gt; (partition.topicPartition, partition.getOrCreateReplica().highWatermark.messageOffset) &#125;.toMap) //hw更新，尝试处理请求 partitionsToMakeFollower.foreach &#123; partition =&gt; val topicPartitionOperationKey = new TopicPartitionOperationKey(partition.topicPartition) tryCompleteDelayedProduce(topicPartitionOperationKey) tryCompleteDelayedFetch(topicPartitionOperationKey) &#125; if (isShuttingDown.get()) &#123; partitionsToMakeFollower.foreach &#123; partition =&gt; stateChangeLogger.trace((&quot;Broker %d skipped the adding-fetcher step of the become-follower state change with correlation id %d from &quot; + &quot;controller %d epoch %d for partition %s since it is shutting down&quot;).format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition)) &#125; &#125; else &#123; // we do not need to check if the leader exists again since this has been done at the beginning of this process // 重置fetch位置，加入Fetcher val partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map(partition =&gt; partition.topicPartition -&gt; BrokerAndInitialOffset( metadataCache.getAliveBrokers.find(_.id == partition.leaderReplicaIdOpt.get).get.getBrokerEndPoint(config.interBrokerListenerName), partition.getReplica().get.logEndOffset.messageOffset)).toMap replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset) &#125; &#125; catch &#123; case e: Throwable =&gt; val errorMsg = (&quot;Error on broker %d while processing LeaderAndIsr request with correlationId %d received from controller %d &quot; + &quot;epoch %d&quot;).format(localBrokerId, correlationId, controllerId, epoch) stateChangeLogger.error(errorMsg, e) // Re-throw the exception for it to be caught in KafkaApis throw e &#125; partitionsToMakeFollower&#125;","raw":null,"content":null,"categories":[{"name":"源码","slug":"源码","permalink":"http://fxbing.github.io/categories/%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://fxbing.github.io/tags/kafka/"}]},{"title":"记一次kafka宕机问题排查","slug":"记一次kafka宕机问题排查","date":"2021-05-08T10:22:32.000Z","updated":"2021-05-08T11:51:09.075Z","comments":true,"path":"2021/05/08/记一次kafka宕机问题排查/","link":"","permalink":"http://fxbing.github.io/2021/05/08/%E8%AE%B0%E4%B8%80%E6%AC%A1kafka%E5%AE%95%E6%9C%BA%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","excerpt":"kafka集群出现宕机报警，自动替换新broker一直无法成功。","text":"kafka集群出现宕机报警，自动替换新broker一直无法成功。 排查过程 kafka集群有一个broker宕机，自动替换机器一直无法成功，手动重启时发现该broker对应的zookeeper上的/brokers/ids目录一直被删除导致。 定位zk目录一直被删除的原因：参照Zookeeper日志文件&amp;事务日志&amp;数据快照查看zk事务日志 首先查看zk事务日志所在的目录: 123$ cd zookeeper/conf$ grep dataLogDir *zoo.cfg:dataLogDir=/home/var/lib/zookeeper/ 通过java -classpath .:lib/slf4j-api-1.6.1.jar:zookeeper-3.4.6.jar org.apache.zookeeper.server.LogFormatter /home/var/lib/zookeeper/version-2/log.10263212a| grep brokers/ids查看事务日志，发现/brokers/ids/9984确实在刚刚创建时就被立刻删除了，并且可以找到zk的session id 任一找到一个删除该zk节点的session id，查找zk日志，确定删除操作的客户端 排查过程中发现，好多session id在zk日志中找不到，后面经同学提示才发现原因是zk有5个节点，事务日志在所有节点时相同的，但是普通日志只包含连接本节点的session id，所以需要在所有zk节点的普通日志中进行查找。 session closed时才会打印客户端ip 问题确定：原来是删除操作的broker与新启动的broker id相同，都为9884，但是由于执行删除操作的机器有问题，一直在重启，每次启动时前都会先删除/brokers/ids/9984这个zk节点 经验总结 zk事务日志的查看方式：Zookeeper日志文件&amp;事务日志&amp;数据快照 zk所有节点的事务日志是相同的，但是普通日志中只有与当前节点连接的session信息","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://fxbing.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://fxbing.github.io/tags/kafka/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://fxbing.github.io/tags/zookeeper/"},{"name":"问题排查","slug":"问题排查","permalink":"http://fxbing.github.io/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"}]},{"title":"记一次线上服务Full GC问题排查","slug":"记一次线上服务内存泄漏问题排查","date":"2021-05-05T16:00:00.000Z","updated":"2021-05-09T08:12:09.092Z","comments":true,"path":"2021/05/06/记一次线上服务内存泄漏问题排查/","link":"","permalink":"http://fxbing.github.io/2021/05/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","excerpt":"有一个线上服务多个集群出现FGC，降低集群压力之后并没有改善。","text":"有一个线上服务多个集群出现FGC，降低集群压力之后并没有改善。 背景 这是一个kafka mirror服务，用来在多个kafka集群之间进行数据同步。 mirror服务是无状态的，因此一般情况下FGC不会对系统产生严重影响，但是仍然存在较大风险。 排查过程 一. 缩小范围 ​ FGC是从五一长假期间开始发生的，并且在FGC发生之前，在两个FGC集群中增加过任务，因此推测可能与集群压力较大有关系，为了确定这一推测，在五一长假结束之后，将新增加的任务全部迁移至同一个mirror集群A，使另一个mirror集群B状态与出现FGC之前完全相同，但是，事与愿违，集群B的FGC没有恢复，仍然存在问题。 ​ 因此，基本可以确认本次FGC与五一长假期间集群压力增加没有关系，需要具体分析FGC的原因，确认是否存在内存泄漏的情况。 二. 具体分析 首先通过jmap查看内存的占用情况： 1$ jmap -histo $&#123;PID&#125; 可以发现，com.mysql.cj.jdbc.ByteArrayRow这个对象占了4G多的内存（总内存32G），虽然代码中有查询mysql代码，但是查询结果都已经解析存放在了Map、List等对象中。 为了确认该mysql对象是不是查询的临时变量，会不会被FGC清理，主动找一台机器执行FGC， 1$ jmap -histo:live $&#123;PID&#125; 发现mysql对象占用的大小并未减少且仍在增加，推测这个mysql对象应该是引起FGC的原因。 查看代码发现，除了一处定期执行的SQL查询外，在任务不变的情况下，其他代码在系统启动后都不会进行SQL查询。并且，这条定期执行的SQL执行周期在这个版本中并没有发生变化，一直是2分钟一次。 12345kafkaScheduler.schedule(&quot;update-Maps-Task&quot;, updateMapsTask, 20000, 120000, TimeUnit.MILLISECONDS)def updateMapsTask() &#123; mysqlUtil.updateTopicMap(&quot;SELECT * FROM table2&quot;) &#125; 验证com.mysql.cj.jdbc.ByteArrayRow对象的内存占用是否与上述Scheduler有关： 找一台机器每2分钟查询一次com.mysql.cj.jdbc.ByteArrayRow对象大小，发现每两次查询到的对象大小之间的差值均相同，为395360 根据服务启动时间，按照每两分钟增长395360B的速度进行计算，得到com.mysql.cj.jdbc.ByteArrayRow对象大小为4GB，该估算值与当前通过jmap看到的对象大小一致 基本可以确认是这个定时查询导致的。 进一步验证： 重启服务，发现com.mysql.cj.jdbc.ByteArrayRow对象特别小； 将定时任务周期从2分钟改为3秒，发现com.mysql.cj.jdbc.ByteArrayRow对象3分钟内增长了15MB，且与估算值一致。 问题修复： 通过查看代码和Google发现，需要显式关闭mysql查询使用的Statement对象和ResultSet对象， https://stackoverflow.com/questions/4507440/must-jdbc-resultsets-and-statements-be-closed-separately-although-the-connection/15728512 修复验证： JVM内存设置为50MB，定时任务周期设置为3秒。 修复前，mysql内存不断增加，出现几次FGC，直到OOM 。 修复后，未出现FGC，有YGC，YGC之后mysql内存被回收 。 总结 旧版本代码虽然也是2分钟执行一次查询，但是查询数据表不同，旧版本数据表中只有2条数据，新版本数据表中有7000+数据，内存积累很慢，所以旧版本一致没有发现问题。 查询mysql时需要及时关闭Statement对象和ResultSet对象，否则会因为对象一直被引用而无法自动进行垃圾回收。 分析FGC问题时需要主动使用jmap等工具，尽早发现问题。","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://fxbing.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"问题排查","slug":"问题排查","permalink":"http://fxbing.github.io/tags/%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/"},{"name":"JVM","slug":"JVM","permalink":"http://fxbing.github.io/tags/JVM/"}]},{"title":"CompletableFuture 总结","slug":"2019-08-18-CompletableFuture","date":"2019-08-17T16:00:00.000Z","updated":"2019-08-17T16:00:00.000Z","comments":true,"path":"2019/08/18/2019-08-18-CompletableFuture/","link":"","permalink":"http://fxbing.github.io/2019/08/18/2019-08-18-CompletableFuture/","excerpt":"CompletableFuture 是Java8 中新增的用来进行函数式异步编程的工具类。\n最近学习源码的过程中看到有很多 CompletableFuture 的使用，感觉自己对这个类中的各个方法的使用场景和方法不是很熟悉，遂参考了下面几篇博客进行学习（本文大部分内容也都来自下面几篇博客）：\nJava CompletableFuture 详解\nJava8新的异步编程方式 CompletableFuture(一)\nJava8新的异步编程方式 CompletableFuture(二)\nJava8新的异步编程方式 CompletableFuture(三)\n上面的博客介绍的比较详细，为了自己查阅回看的方便，这里对这些方法进行一下总结（这里只总结不举例，具体使用需要看上面的博客）。","text":"CompletableFuture 是Java8 中新增的用来进行函数式异步编程的工具类。 最近学习源码的过程中看到有很多 CompletableFuture 的使用，感觉自己对这个类中的各个方法的使用场景和方法不是很熟悉，遂参考了下面几篇博客进行学习（本文大部分内容也都来自下面几篇博客）： Java CompletableFuture 详解 Java8新的异步编程方式 CompletableFuture(一) Java8新的异步编程方式 CompletableFuture(二) Java8新的异步编程方式 CompletableFuture(三) 上面的博客介绍的比较详细，为了自己查阅回看的方便，这里对这些方法进行一下总结（这里只总结不举例，具体使用需要看上面的博客）。 Future接口 Feture 接口包含五个方法，介绍如下： boolean cancel (boolean mayInterruptIfRunning) 取消任务的执行。参数指定是否立即中断任务执行，或者等等任务结束 boolean isCancelled () 任务是否已经取消，任务正常完成前将其取消，则返回 true boolean isDone () 任务是否已经完成。需要注意的是如果任务正常终止、异常或取消，都将返回true V get () throws InterruptedException, ExecutionException 等待任务执行结束，然后获得V类型的结果。InterruptedException 线程被中断异常， ExecutionException任务执行异常，如果任务被取消，还会抛出CancellationException V get (long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException 同上面的get功能一样，多了设置超时时间。参数timeout指定超时时间，uint指定时间的单位，在枚举类TimeUnit中有相关的定义。如果计 算超时，将抛出TimeoutException 主动完成计算 CompletableFuture实现了CompletionStage和Future两个接口。 通过阻塞或者轮询获得结果 方法名 描述 public T get() Future接口实现 public T get(long timeout, TimeUnit unit) Future接口实现 public T getNow(T valueIfAbsent) 如果结果已经计算完则返回结果或者抛出异常，否则返回给定的valueIfAbsent值。 public T join() 返回计算的结果或者抛出一个unchecked异常(CompletionException) join()和get()的区别是，join()只会抛出未检查异常（不需要使用try...catch..进行处理），而get()会抛出检查异常。 异步获取结果 下面两个函数的调用会立即执行，并且只能执行一次。 如果该任务已经执行完成，那么下面两个调用会无效，只能获取执行完成的结果。其实就是使任务立即结束（返回指定结果或者指定抛出异常）。 比较适合需要返回CompletableFuture的方法，先创建一个空的CompletableFuture，之后通过下面两个函数指定前面创建的CompletableFuture的返回值。 方法名 描述 complete(T t) 完成异步执行，并返回future的结果 completeExceptionally(Throwable ex) 异步执行不正常的结束 静态工厂方法 run 和 supply 的主要区别是异步操作是否有返回值（下面列出的所有方法也基本都是按照是否有返回值分为两类）。 方法名 描述 runAsync(Runnable runnable) 使用ForkJoinPool.commonPool()作为它的线程池执行异步代码。 runAsync(Runnable runnable, Executor executor) 使用指定的thread pool执行异步代码。 supplyAsync(Supplier&lt;U&gt; supplier) 使用ForkJoinPool.commonPool()作为它的线程池执行异步代码，异步操作有返回值。 supplyAsync(Supplier&lt;U&gt; supplier, Executor executor) 使用指定的thread pool执行异步代码，异步操作有返回值。 下面几乎所有的方法都是一式三份，三种方法的区别是 直接在当前线程执行 换另一个线程（但是不指定线程）异步执行 指定线程执行 转换 相当于 map 操作 方法名 描述 thenApply(Function&lt;? super T,? extends U&gt; fn) 接受一个Function&lt;? super T,? extends U&gt;参数用来转换CompletableFuture thenApplyAsync(Function&lt;? super T,? extends U&gt; fn) 接受一个Function&lt;? super T,? extends U&gt;参数用来转换CompletableFuture，使用ForkJoinPool thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor) 接受一个Function&lt;? super T,? extends U&gt;参数用来转换CompletableFuture，使用指定的线程池 相当于 flatMap 操作 方法名 描述 thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn) 在异步操作完成的时候对异步操作的结果进行一些操作，并且仍然返回CompletableFuture类型。 thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn) 在异步操作完成的时候对异步操作的结果进行一些操作，并且仍然返回CompletableFuture类型。使用ForkJoinPool。 thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn,Executor executor) 在异步操作完成的时候对异步操作的结果进行一些操作，并且仍然返回CompletableFuture类型。使用指定的线程池。 组合 方法名 描述 thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn) 当两个CompletableFuture都正常完成后，执行提供的fn，用它来组合另外一个CompletableFuture的结果。 thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn) 当两个CompletableFuture都正常完成后，执行提供的fn，用它来组合另外一个CompletableFuture的结果。使用ForkJoinPool。 thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn, Executor executor) 当两个CompletableFuture都正常完成后，执行提供的fn，用它来组合另外一个CompletableFuture的结果。使用指定的线程池。 thenAcceptBoth跟thenCombine类似，但是返回CompletableFuture类型。 方法名 描述 thenAcceptBoth(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; action) 当两个CompletableFuture都正常完成后，执行提供的action，用它来组合另外一个CompletableFuture的结果。 thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; action) 当两个CompletableFuture都正常完成后，执行提供的action，用它来组合另外一个CompletableFuture的结果。使用ForkJoinPool。 thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; action, Executor executor) 当两个CompletableFuture都正常完成后，执行提供的action，用它来组合另外一个CompletableFuture的结果。使用指定的线程池。 计算结果完成时的处理 Action的类型是BiConsumer&lt;? super T,? super Throwable&gt;，它可以处理正常的计算结果，或者异常情况。 方法不以Async结尾，意味着Action使用相同的线程执行，而Async可能会使用其它的线程去执行(如果使用相同的线程池，也可能会被同一个线程选中执行 方法名 描述 whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action) 当CompletableFuture完成计算结果时对结果进行处理，或者当CompletableFuture产生异常的时候对异常进行处理。 whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action) 当CompletableFuture完成计算结果时对结果进行处理，或者当CompletableFuture产生异常的时候对异常进行处理。使用ForkJoinPool。 whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor) 当CompletableFuture完成计算结果时对结果进行处理，或者当CompletableFuture产生异常的时候对异常进行处理。使用指定的线程池。 handle()相当于whenComplete()+转换。 handle()也可以理解为和thenApply()的含义更为相似，但是比thenApply()增加异常处理的功能。 方法名 描述 handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn) 当CompletableFuture完成计算结果或者抛出异常的时候，执行提供的fn handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn) 当CompletableFuture完成计算结果或者抛出异常的时候，执行提供的fn，使用ForkJoinPool。 handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn, Executor executor) 当CompletableFuture完成计算结果或者抛出异常的时候，执行提供的fn，使用指定的线程池。 方法名 描述 exceptionally(Function fn) 只有当CompletableFuture抛出异常的时候，才会触发这个exceptionally的计算，调用function计算值。 纯消费 方法名 描述 thenAccept(Consumer&lt;? super T&gt; action) 当CompletableFuture完成计算结果，只对结果执行Action，而不返回新的计算值 thenAcceptAsync(Consumer&lt;? super T&gt; action) 当CompletableFuture完成计算结果，只对结果执行Action，而不返回新的计算值，使用ForkJoinPool。 thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor) 当CompletableFuture完成计算结果，只对结果执行Action，而不返回新的计算值 Either Either 表示的是两个CompletableFuture，当其中任意一个CompletableFuture计算完成的时候就会执行。 方法名 描述 acceptEither(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action) 当任意一个CompletableFuture完成的时候，action这个消费者就会被执行。 acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action) 当任意一个CompletableFuture完成的时候，action这个消费者就会被执行。使用ForkJoinPool acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action, Executor executor) 当任意一个CompletableFuture完成的时候，action这个消费者就会被执行。使用指定的线程池 applyToEither() 是acceptEither()的哥哥. 当两个future其中一个完成后，后者用于只是简单地调用一些代码，applyToEither()会返回一个新的future. 这个future是在前面两个future其中一个完成后进行执行完成。 方法名 描述 applyToEither(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn) 当任意一个CompletableFuture完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture的计算结果。 applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn) 当任意一个CompletableFuture完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture的计算结果。使用ForkJoinPool applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn, Executor executor) 当任意一个CompletableFuture完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture的计算结果。使用指定的线程池 其他方法 方法名 描述 allOf(CompletableFuture&lt;?&gt;... cfs) 在所有Future对象完成后结束，并返回一个future。 anyOf(CompletableFuture&lt;?&gt;... cfs) 在任何一个Future对象结束后结束，并返回一个future。","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://fxbing.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://fxbing.github.io/tags/Java/"}]},{"title":"Pulsar 源码阅读： Backlog","slug":"2019-08-06-Pulsar Backlog","date":"2019-08-05T16:00:00.000Z","updated":"2019-08-09T16:00:00.000Z","comments":true,"path":"2019/08/06/2019-08-06-Pulsar Backlog/","link":"","permalink":"http://fxbing.github.io/2019/08/06/2019-08-06-Pulsar%20Backlog/","excerpt":"对于已经消费但是没有确认的消息，Pulsar 可以通过配置 BacklogQuota 决定保留大小及丢弃策略。\n具体参见官方文档：Message retention and expiry\n当 Backlog 大小未达到限额时，不需要处理，当 Backlog 大小超限时，根据丢弃策略进行处理。\nBacklogQuota 的丢弃策略一共有三种：\n\nproducer_request_hold：① 断开所有的 Producer ② 在新建 Producer 时进行检查，如果超出 BacklogQuota，则拒绝新建请求并等待超时（异步返回结果调用get()时才抛出异常）\nproducer_exception：① 断开所有的 Producer ② 在新建 Producer 时进行检查，如果超出 BacklogQuota，则拒绝新建请求并抛出异常\nconsumer_backlog_eviction：丢弃最早的 Backlog\n","text":"对于已经消费但是没有确认的消息，Pulsar 可以通过配置 BacklogQuota 决定保留大小及丢弃策略。 具体参见官方文档：Message retention and expiry 当 Backlog 大小未达到限额时，不需要处理，当 Backlog 大小超限时，根据丢弃策略进行处理。 BacklogQuota 的丢弃策略一共有三种： producer_request_hold：① 断开所有的 Producer ② 在新建 Producer 时进行检查，如果超出 BacklogQuota，则拒绝新建请求并等待超时（异步返回结果调用get()时才抛出异常） producer_exception：① 断开所有的 Producer ② 在新建 Producer 时进行检查，如果超出 BacklogQuota，则拒绝新建请求并抛出异常 consumer_backlog_eviction：丢弃最早的 Backlog BacklogQuotaManager Pulsar 中有BacklogQuotaManager用来进行 Backlog 处理，有下面几个关键函数。 handleExceededBacklogQuota 该函数用来处理 Backlog 超限的情况，对于consumer_backlog_eviction策略，调用dropBacklog(persistentTopic, quota);；对于producer_exception和producer_request_hold两种策略，调用disconnectProducers(persistentTopic); 1234567891011121314151617181920public void handleExceededBacklogQuota(PersistentTopic persistentTopic) &#123; TopicName topicName = TopicName.get(persistentTopic.getName()); String namespace = topicName.getNamespace(); String policyPath = AdminResource.path(POLICIES, namespace); BacklogQuota quota = getBacklogQuota(namespace, policyPath); log.info(&quot;Backlog quota exceeded for topic [&#123;&#125;]. Applying [&#123;&#125;] policy&quot;, persistentTopic.getName(), quota.getPolicy()); switch (quota.getPolicy()) &#123; case consumer_backlog_eviction: dropBacklog(persistentTopic, quota); break; case producer_exception: case producer_request_hold: disconnectProducers(persistentTopic); break; default: break; &#125; &#125; 下面介绍dropBacklog(persistentTopic, quota);和disconnectProducers(persistentTopic);两个函数。 dropBacklog(persistentTopic, quota) dropBacklog(persistentTopic, quota);函数负责在 Backlog 超限之后对 Backlog 中最早的消息进行丢弃，这里的丢弃实际是指向后移动未确认消息的起始标记（该 Topic 上最慢的 Consumer 的位置）。 123456789101112131415161718192021222324252627282930313233343536373839404142private void dropBacklog(PersistentTopic persistentTopic, BacklogQuota quota) &#123; // 设置丢弃比例为 0.9 ，即丢弃任务完成之后 Backlog 大小变为 Backlog 限额的 90% double reductionFactor = 0.9; double targetSize = reductionFactor * quota.getLimit(); // 获取 Backlog 大小的估计值，这里不直接使用 Ledger 的实际大小是因为 Ledger 不一定会被及时清理，实际大小会大于 Backlog 的大小 ManagedLedgerImpl mLedger = (ManagedLedgerImpl) persistentTopic.getManagedLedger(); long backlogSize = mLedger.getEstimatedBacklogSize(); //这个函数后面介绍 ManagedCursor previousSlowestConsumer = null; while (backlogSize &gt; targetSize) &#123; // 最慢的 Consumer ManagedCursor slowestConsumer = mLedger.getSlowestConsumer(); if (slowestConsumer == null) &#123; break; &#125; // 需要跳过的比例 double messageSkipFactor = ((backlogSize - targetSize) / backlogSize); // Cursor 没有移动，不需要执行清理 if (slowestConsumer == previousSlowestConsumer) &#123; break; &#125; // 计算需要移动的距离 long entriesInBacklog = slowestConsumer.getNumberOfEntriesInBacklog(); int messagesToSkip = (int) (messageSkipFactor * entriesInBacklog); try &#123; if (messagesToSkip == 0) &#123; break; &#125; // 移动 slowestConsumer 位置 slowestConsumer.skipEntries(messagesToSkip, IndividualDeletedEntries.Include); &#125; catch (Exception e) &#123; log.error(&quot;Error skipping [&#123;&#125;] messages from slowest consumer : [&#123;&#125;]&quot;, messagesToSkip, slowestConsumer.getName()); &#125; // 移动完成之后更新 backlogSize，再次执行上面的流程，确保移动之后 Backlog 没有再次超限 backlogSize = mLedger.getEstimatedBacklogSize(); previousSlowestConsumer = slowestConsumer; &#125; &#125; 这里用到了一个ManagedLedgerImpl类中的一个函数getEstimatedBacklogSize()，用来估计 Backlog的大小。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public long getEstimatedBacklogSize() &#123; // 未确认消息的起始标记 PositionImpl pos = getMarkDeletePositionOfSlowestConsumer(); while (true) &#123; if (pos == null) &#123; return 0; &#125; long size = 0; // Backlog 大小 final long slowestConsumerLedgerId = pos.getLedgerId(); synchronized (this) &#123; // 获取所有 Ledger 总大小 size = getTotalSize(); // 减去没有及时清理的 Ledger 的大小 size -= ledgers.values().stream().filter(li -&gt; li.getLedgerId() &lt; slowestConsumerLedgerId) .mapToLong(li -&gt; li.getSize()).sum(); &#125; LedgerInfo ledgerInfo = null; synchronized (this) &#123; ledgerInfo = ledgers.get(pos.getLedgerId()); &#125; if (ledgerInfo == null) &#123; // 如果 pos 指向的 Ledger 已经被删除，但是删除标记还没有更新（每次启动新的 manageLedger 时才会更新），就直接返回结果 if (pos.compareTo(getMarkDeletePositionOfSlowestConsumer()) == 0) &#123; return size; &#125; // 如果删除标记已经更新，说明当前 pos 指向的 Ledger 已经被完全清理，则需要更新 pos 进行重试 pos = getMarkDeletePositionOfSlowestConsumer(); continue; &#125; long numEntries = pos.getEntryId(); // consumedLedgerSize()第三个参数需要作为除数，不能为 0 if (ledgerInfo.getEntries() == 0) &#123; size -= consumedLedgerSize(currentLedgerSize, currentLedgerEntries, numEntries); return size; &#125; else &#123; size -= consumedLedgerSize(ledgerInfo.getSize(), ledgerInfo.getEntries(), numEntries); return size; &#125; &#125; &#125; 123456789private long consumedLedgerSize(long ledgerSize, long ledgerEntries, long consumedEntries) &#123; if (ledgerEntries &lt;= 0) &#123; return 0; &#125; // 计算平均 Entry 大小 long averageSize = ledgerSize / ledgerEntries; // Entry Id 的起始编号为 -1，所以这里需要 +1 return consumedEntries &gt;= 0 ? (consumedEntries + 1) * averageSize : 0; &#125; disconnectProducers(persistentTopic) disconnectProducers(persistentTopic);函数负责在producer_request_hold和producer_exception两种模式下 Backlog 超限时断开与 Producer 的链接。 12345678910111213141516private void disconnectProducers(PersistentTopic persistentTopic) &#123; List&lt;CompletableFuture&lt;Void&gt;&gt; futures = Lists.newArrayList(); ConcurrentOpenHashSet&lt;Producer&gt; producers = persistentTopic.getProducers(); producers.forEach(producer -&gt; &#123; futures.add(producer.disconnect()); &#125;); FutureUtil.waitForAll(futures).thenRun(() -&gt; &#123; log.info(&quot;All producers on topic [&#123;&#125;] are disconnected&quot;, persistentTopic.getName()); &#125;).exceptionally(exception -&gt; &#123; log.error(&quot;Error in disconnecting producers on topic [&#123;&#125;] [&#123;&#125;]&quot;, persistentTopic.getName(), exception); return null; &#125;); &#125; BacklogQuota 检查 BacklogQuota 有两种形式的检查，一种是周期性检查，另一种是创建 Producer 之前检查。 周期性检查 在BrokerService启动时，会启动startBacklogQuotaChecker();，startBacklogQuotaChecker();负责周期性执行monitorBacklogQuota() ，对于 Backlog 超限的情况，会通过BacklogQuotaManager进行处理。 1234567891011121314public void monitorBacklogQuota() &#123; forEachTopic(topic -&gt; &#123; if (topic instanceof PersistentTopic) &#123; PersistentTopic persistentTopic = (PersistentTopic) topic; if (isBacklogExceeded(persistentTopic)) &#123; getBacklogQuotaManager().handleExceededBacklogQuota(persistentTopic); &#125; else &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;quota not exceeded for [&#123;&#125;]&quot;, topic.getName()); &#125; &#125; &#125; &#125;); &#125; 创建 Producer 之前检查 在 Broker 与 Client 对接的服务端ServerCnx上，收到建立 Producer 的触发之后，在创建 Producer 之前，会进行 BacklogQuota 检查。 1234567891011121314151617if (topic.isBacklogQuotaExceeded(producerName)) &#123; IllegalStateException illegalStateException = new IllegalStateException( &quot;Cannot create producer on topic with backlog quota exceeded&quot;); BacklogQuota.RetentionPolicy retentionPolicy = topic.getBacklogQuota().getPolicy(); if (retentionPolicy == BacklogQuota.RetentionPolicy.producer_request_hold) &#123; // 返回 Error ctx.writeAndFlush( Commands.newError(requestId, ServerError.ProducerBlockedQuotaExceededError, illegalStateException.getMessage())); &#125; else if (retentionPolicy == BacklogQuota.RetentionPolicy.producer_exception) &#123; // 返回 Exception ctx.writeAndFlush(Commands.newError(requestId, ServerError.ProducerBlockedQuotaExceededException, illegalStateException.getMessage())); &#125; producerFuture.completeExceptionally(illegalStateException); producers.remove(producerId, producerFuture); return;&#125; 这里只进行producer_request_hold和producer_exception两种策略的处理，consumer_backlog_eviction只在周期性检查时进行处理。 对于producer_request_hold策略，返回 Error ，ClientCnx在收到 Error 之后，不会直接结束请求，会在 Future 任务超时或者调用get()时抛出ProducerBlockedQuotaExceededError异常。 12345678910111213141516protected void handleError(CommandError error) &#123; checkArgument(state == State.Ready); log.warn(&quot;&#123;&#125; Received error from server: &#123;&#125;&quot;, ctx.channel(), error.getMessage()); long requestId = error.getRequestId(); if (error.getError() == ServerError.ProducerBlockedQuotaExceededError) &#123; log.warn(&quot;&#123;&#125; Producer creation has been blocked because backlog quota exceeded for producer topic&quot;, ctx.channel()); &#125; CompletableFuture&lt;ProducerResponse&gt; requestFuture = pendingRequests.remove(requestId); if (requestFuture != null) &#123; requestFuture.completeExceptionally(getPulsarClientException(error.getError(), error.getMessage())); &#125; else &#123; log.warn(&quot;&#123;&#125; Received unknown request id from server: &#123;&#125;&quot;, ctx.channel(), error.getRequestId()); &#125; &#125; 对于producer_exception策略，直接返回ProducerBlockedQuotaExceededException异常。 以上就是对 Pulsar 代码中 BacklogQuota 机制的实现。","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://fxbing.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Pulsar","slug":"Pulsar","permalink":"http://fxbing.github.io/tags/Pulsar/"}]},{"title":"《深入理解Java虚拟机》笔记","slug":"2019-07-28-深入理解JAVA虚拟机笔记","date":"2019-07-27T16:00:00.000Z","updated":"2019-07-27T16:00:00.000Z","comments":true,"path":"2019/07/28/2019-07-28-深入理解JAVA虚拟机笔记/","link":"","permalink":"http://fxbing.github.io/2019/07/28/2019-07-28-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AC%94%E8%AE%B0/","excerpt":"阅读了《深入理解Java虚拟机》的部分章节，并做了一些简单的笔记，不是很详细，但是可以方便自己查阅。","text":"阅读了《深入理解Java虚拟机》的部分章节，并做了一些简单的笔记，不是很详细，但是可以方便自己查阅。 第三章 垃圾收集器与内存分配策略 1. 对象是否存活 引用计数法： 很难解决对象间的循环引用 可达性分析 可以作为GC Roots的对象： 虚拟机栈中引用的对象 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（Native方法）引用的对象 2. 引用分类（JDK1.2实现） 强引用：永远不回收 软引用SoftReference（有用但非必须）：内存溢出之前回收 弱引用WeakReference（非必须）：GC时回收 虚引用PhantomReference（幽灵引用/幻影引用）：目的是能在这个对象被收集器回收时收到一个系统通知 3. finalize()（不建议使用） 判断对象是否死亡会经历两次标记过程：①判断是否与GC Roots相连；②执行finalize()（对象没有覆盖finalize()或finalize()已经被调用过一次时，虚拟机认为没必要执行finalize()，不会进行第二次标记）。 被调用时会放在由虚拟机自动创建的、低优先级的队列F-Queue中 finalize()是对象唯一的自救机会，例如：在finalize()中将this赋值给某个类变量或者对象的成员变量 运行代价高昂，不确定性大、无法保证各个对象的调用顺序 finalize()能做的所有工作使用try-finally或者其他方式可以做得更好、更及时 4. 回收方法区 废弃常量 与Java堆的回收逻辑类似 无用的类 该类的所有实例已经被回收 加载该类的ClassLoader已经被回收 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 5. 垃圾收集算法 （1）标记清除算法 效率不高 会大量不连续内存碎片 （2）复制算法 内存缩小为原来的一半 HotSpot默认的Eden与Survivor的大小比例为8:1 没有办法保证每次回收都只有不多于10%的对象存活。当Survivor空间不够用时，需要依赖老年代进行分配担保。 分配担保：当Survivor空间不能放下上一次 YGC 之后存活的对象时，这些对象直接通过分配担保机制进入老年代。 （3）标记整理算法 （4）分代收集算法 新生代每次垃圾收集都会有大量对象死去，少量存活，所以采用复制算法。老年代对象存活率高、没有额外的空间对它进行担保，必须使用“标记-清理”或者“标记-整理”算法。 6. HotSpot算法实现 （1）枚举根节点 Java虚拟机使用准确式GC（必须确定一个变量是引用还是真正的数据） 虚拟机停顿之后不需要检查所有的执行上下文和全局的引用位置。 类加载完成时计算出什么偏移量上是什么类型的数据，JIT编译时在特定位置（安全点）记录OopMap数据结构（指明栈和寄存器哪些位置是引用） （2）安全点（SafePoint） 程序执行时并非在所有地方都能停顿下来开始GC，只有到达安全点时才能暂停。 安全点选定原则：是否具有让程序长时间执行的特征 长时间执行：指令序列复用（如：方法调用、循环跳转、异常跳转） 抢先式中断（已经被弃用）：所有线程中断，不在安全点的线程恢复执行。 主动式中断：在安全点设置中断标志，程序执行到安全点时主动轮询这个标志，判断是否需要进行中断。 （3）安全区域（Safe Region） 定义：一段代码中，引用关系不会发生变化。（线程处于Sleep或Blocked状态） 线程执行到Safe Region时，标识自己进入Safe Region状态；JVM GC时不管Safe Region状态的线程；当线程离开Safe Region状态时，检查系统是否完成了根节点枚举或整个GC过程；如果完成了，那线程继续执行，否则，必须等待收到可以安全离开Safe Region的信号为止。 7. 垃圾收集器 连线代表可以组合使用。 （1）Serial收集器（Client模式下新生代垃圾清理首选） 进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。 Serial/Serial Old收集器在新生代采用复制算法，老年代采用标记-整理算法。 （2）ParNew收集器（Server模式下新生代垃圾清理首选） 多线程版本的Serial收集器 第一款真正意义上的并发收集器 默认开启的收集线程数与CPU的数量相同 （3）Parallel Scavenge收集器 目标：达到一个可控制的吞吐量。（吞吐量 = 运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)） 适合在后台运算而不需要太多交互的任务 可以设置最大垃圾收集停段时间（-XX:MaxGCPauseMillis）和吞吐量大小（-XX:GCTimeRatio） 可以开启-XX:UseAdaptiveSizePolicy，之后虚拟机根据系统运行状况自动设置新生代大小、Eden与Survivor比例、晋升老年代对象大小等细节参数。（GC自适应的调节策略） （4）Serial Old收集器 （5）Parallel Old收集器 （6）CMS收集器 四个步骤：a: 初始标记（停顿）：记录与GC Roots直接相连的对象b: 并发标记：GC Roots Tracingc: 重新标记（停顿更长）：修正并发标记期间因用户程序继续运作而导致的标记产生变动的记录d: 并发清除 对 CPU 资源敏感 无法处理浮动垃圾（并发清除阶段用户程序产生的新的垃圾，需要等下次GC时再进行清理），可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。（不能等老年代被填满之后进行清理，需要为并发清除期间用户程序的执行预留空间） 空间碎片过多 （7）G1收集器（JDK1.7） 并行与并发 分代收集 空间整合：从整体上看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制“算法实现的。 可预测的停顿：使用者可以指定垃圾收集上消耗的时间不得超过 M 毫秒。 分配的对象会记录在 Remembered Set 中，内存回收时再GC根节点的枚举范围中加入 Remembered Set ，确保不对全堆扫描也不会有泄露。 不计算维护 Remembered Set 的过程，可以分为以下几个步骤：a: 初始标记b: 并发标记c: 最终标记：并发标记期间对象变化记录在线程 Remembered Set Logs 中，该阶段将 Remembered Set Logs 整合到 Remembered Set 中。d: 筛选回收：根据用户期望的 GC 停顿时间制定回收计划。 8. 内存分配与回收策略 对象优先在Eden分配 新生代 GC （Minor GC）：非常频繁，回收速度也比较块。老年代 GC （Major GC / Full GC）：伴随至少一次的 Minor GC ， 比 Minor GC 慢10倍以上。 大对象直接进入老年代 长期存活的对象将进入老年代（可以通过 -XX:MaxTenuringThreshold 参数进行设置，默认执行完15次 Minor GC） 动态对象年龄判断：如果在 Survivor 空间中相同年龄所有对象大小总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。 空间分配担保：在进行 Minor GC 之前会执行下面的流程，a: 检查老年代最大连续可用空间是否大于新生代所有对象总空间，如果是 Minor GC 可以确保安全，否则， 执行b；b: 查看 HandlePromotionFailure 设置的值是否允许担保失败，如果是，执行c，否则，执行 Full GC；c: 检查老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小，如果是，尝试一次 Minor GC （可能存在风险），否则，将 HandlePromotionFailure 设置为不允许冒险，改为进行一次 Full GC。 第七章 虚拟机类加载机制 1. 类的加载过程 按顺序按部就班的开始（不是结束，一个阶段中调用激活另一个阶段），解析阶段可以在初始化之后再开始（动态绑定） Java虚拟机规定的必须进行初始化的5种情况：（1） 遇到 new、getstatic、putstatic、invokestatic这4条字节码指令（对应使用 new 关键字实例化对象、读取或设置类的静态字段（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）以及调用一个类的静态方法几种情况）（2） 反射调用。（3） 初始化一个类时，如果父类没有进行过初始化，需要先触发父类初始化。（4） 虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的类），虚拟机会先初始化主类。（5） 但是用动态语言支持时，如果一个java.lang.invoke.MethodHandle实例后解析结果 REF_putStatic , REF_getStatic , REF_invokeStatic 的方法句柄时，当改方法句柄对应的类没有初始化时，需要初始化该类。 接口初始化时并不要求其父类接口全部都初始化完成，只有在真正使用到父类接口时才会初始化。 有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。 被动引用举例： 通过子类引用父类的静态字段，不会导致子类的初始化。 通过数组定义来引用类，不会触发此类的初始化。 常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。 1.1 加载 通过一个类的全限定名来获取定义此类的二进制字节流 获取途径：ZIP包（JAR、EAR、WAR）、网络（Applet）、运行时计算生成（动态代理）、其他文件（JSP应用）、数据库 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口 非数组类型使用引导类加载器或者用户自定义类加载器进行加载 数组的组件类型（去掉一个维度之后的类型）是引用类型，则按照普通类加载过程加载；不是引用类型，标记为与引导类加载器关联。 数组类可见性与组件类型可见性一致。如果组件类型不是引用类型，可见性默认为 public 。 1.2 验证（非常重要但不一定必要） 文件格式验证：保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个Java类型信息的要求。 经过此验证之后字节流才会进入内存方法区，后面3个验证阶段都是基于方法区中的存储结构 元数据验证（语义分析）：保证不存在不符合语言规范的元数据信息。 字节码验证（并不能完全保证安全）：对类的方法体进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。 符号引用验证：发生在虚拟机将符号引用转化为直接引用阶段，确保解析动作可以正常执行。 1.3 准备 为类变量（被 static 修饰的变量，不包括实例变量）分配内存并设置类变量初始值（一般是零值）。 通常情况下初始化零值，如果存在 ConstantValue 属性，则指定为 ConstantValue 属性的值。public static int value = 123;此代码 value 准备阶段之后的结果为0；public static final int value = 123;此代码 value 准备阶段之后的结果为123。 1.4 解析 将常量池中的符号引用替换为直接引用。 除invokeddynamic指令，其余需要进行解析的字节码指令都会对第一次解析结果进行缓存。解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符七类符号引用进行。 1.5 初始化 执行类构造器&lt;clinit&gt;()方法。 静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但不能访问。 &lt;clinit&gt;()不需要显示调用父类的&lt;clinit&gt;()，由虚拟机保证父类&lt;clinit&gt;()执行。第一个被执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object。 父类中定义的静态语句块优于子类变量的复制操作。 &lt;clinit&gt;()是非必需的（没有静态语句块和变量赋值操作） 接口不能使用静态语句块，但是可以对变量赋值。只有父接口中定义的变量使用时，父接口才会初始化。 虚拟机保证一个类的&lt;clinit&gt;()方法在多线程环境下被正确的加锁、同步。 2. 类加载器 2.1 判断两个类相等 使用相同类加载器 全限定名相同 2.2 双亲委派模型 双亲委派模型工作过程： 如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个类加载器都是如此，只有当父加载器在自己的搜索范围内找不到指定的类时（即ClassNotFoundException），子加载器才会尝试自己去加载。 类加载器之间的父子关系不会以继承实现，而是使用组合的方式。 双亲委派模型的三次破坏 第一次破坏是在jdk 1.2之前，用户自定义的类加载器都是重写Classloader中的loadClass方法,这样就导致每个自定义的类加载器其实是在使用自己的loadClass方法中的加载机制来进行加载,这种模式当然是不符合双亲委派机制的，也是无法保证同一个类在jvm中的唯一性的。为了向前兼容，java官方在Classloader中添加了findClass方法,用户只需要重新这个findClass方法，在loadClass方法的逻辑里，如果父类加载失败的时候，才会调用自己的findClass方法来完成类加载，这样就保证了写出的类加载器是符合双亲委派机制的。 第二次的破坏是由模型本身的缺陷导致的，根类加载器加载了基础代码，但是基础代码中有可能调用了用户的代码，但是对于根类加载器而言是不认识用户的代码的。 那么这时候java团队使用了一个不太优雅的设计：线程上下文类加载器。这个类加载器可以通过Thread类的setContextClassLoader方法进行设置,如果创建线程时还未设置，它就从父线程继承一个，如果在应用全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。 利用这个线程上下文类加载器傅，父类加载器请求子类加载器去加载某些自己识别不了的类。 java中基本所有涉及spi的加载动作基本上都采用了这种方式，例如jndi，jdbc等。 第三次的破坏是因为用户对于程序的动态性追求，诸如：代码热替换，模块热部署。目前业界Java模块化的标准是OSGI。而OSGI实现模块热部署的关键是他自己的类加载机制：每个程序模块(bundle)都有自己的类加载器，需要更换程序(bundle)的时候，连同类加载器一起替换，以实现代码的热部署。 第八章 虚拟机字节码执行引擎 1. 运行时栈帧结构 包含局部变量表、操作数栈、动态连接和方法返回地址等信息。 编译时确定栈帧中的局部变量表大小。 一个栈帧需要分配多少内存不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。 只有位于栈顶的栈帧（当前栈帧）才是有效的。 1.1 局部变量表 以容量槽（Slot）为最小单位 每个Slot都应该能够存放一个boolean、byte、char、short、int、float、reference或returnAddress类型数据。 如果一个局部变量定义了但是没有赋初始值是不能使用的 1.2 操作数栈 Java 虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈 1.3 动态连接 指向运行时常量池中该栈帧所属方法的引用。静态解析：符号引用在类加载阶段或第一次使用时转化为直接引用。动态连接：符号引用在每一次运行期间转化为直接引用。 1.4 方法返回地址 方法正常退出时，调用者的PC计数器的值可以作为返回地址，栈帧中很可能会保存这个计数器的值。方法异常退出时，返回地址通过异常处理器表来确定，栈帧中一般不会保存这部分信息。方法退出过程： 恢复上层方法的局部变量表和操作数栈 把返回值压入调用者栈帧的操作数栈 调整PC计数器的值以指向方法调用指令后面的一条指令 2. 方法调用 2.1 解析 只要能被 invokestatic 和 invokespecial 指令调用的方法都可以在解析阶段确定唯一的调用版本。 符合上述条件的的有静态方法、私有方法、实例构造器、父类方法 4 种。都称为非虚方法。其余方法为虚方法。 final 方法也是非虚方法。 2.2 分派（与多态特性有关） 静态分派 动态分派 编译阶段 运行阶段 重载 重写 多分派（关心静态类型与方法参数两个因素） 单分派（只关心方法接收者） （1）静态分派（重载） 所有通过静态类型来定位方法执行版本的分派动作称为静态分派。 方法重载是静态分派的典型应用 静态分派发生在编译阶段 Human man = new Man();Human为变量的静态类型，静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且最终的静态类型是在编译期可知的；Man为变量的实际类型，实际类型的变化结果在运行期才可以确定，编译期间不知道对象的实际类型。重载通过参数的静态类型而不是实际类型作为判定依据。 （2）动态分派（重写） 运行期根据实际类型确定方法执行版本的分派过程称为动态分派。 根据操作数栈中的信息确定接受者的实际类型 （3）单分派与多分派 方法的接收者与方法的参数统称为方法的宗量。单分派是根据一个宗量对目标方法进行选择，多分派则是根据多个宗量对目标方法进行选择。静态分派属于多分派，动态分派属于单分派。 （4）多分派的实现 为类在方法区中建立虚方法表，存放各个方法的实际入口地址。如果子类重写了父类函数，虚方法表中存放指向子类实现版本的入口地址；否则，与父类相同方法的入口地址一致。 第十二章 Java内存模型与线程 1. Java内存模型 工作内存 主内存 线程对变量读取、赋值等操作 线程间变量值的传递 虚拟机栈中的部分区域 Java堆中的对象实例数据部分 1.1 内存间的交互操作 **lock(锁定)**：作用于主内存的变量，把一个变量标记为一条线程独占状态 **unlock(解锁)**：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定 **read(读取)**：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用 **load(载入)**：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中 **use(使用)**：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎 **assign(赋值)**：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量 **store(存储)**：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作 **write(写入)**：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中 同步规则分析： 不允许read和load、store和write操作之一单独出现，以上两个操作必须按顺序执行，但没有保证必须连续执行，也就是说，read与load之间、store与write之间是可插入其他指令的。 不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步会主内存中 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或者assign）的变量。即就是对一个变量实施use和store操作之前，必须先自行assign和load操作。 一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现。 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量之前需要重新执行load或assign操作初始化变量的值。 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作） 2.3 volatile 1. 保证可见性，read与load、aggsin与store两两不分开。 2. 禁止指令重排序优化，内存屏障 2.4 long与double型变量的特殊规则 虚拟机不保证64位数据类型的load、store、read和write这四个操作的原子性。 目前的商用虚拟机保证了64位数据的类型读写操作的原子性 2.5 原子性、可见性与有序性 （1）原子性 基本数据类型具备原子性 sychronized 关键字保证更大范围内的原子性 （2）可见性 volatile、sychronized和final三个关键字实现可见性。 final关键字的可见性：被 final 修饰的字段在构造器中一旦初始化完成，并且构造器没有把this的引用传递出去，那在其他线程中就能看到 final 字段的值。 （3）有序性 volatile和sychronized两个关键字实现有序性。 如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。 2.6 先行发生原则（happens-before） （1）定义 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。 （2）具体规则 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。 join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。 程序中断规则：对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生。 对象finalize规则：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始。 Java与线程 在Java中，JDK1.2之前由用户线程实现，JDK1.2之后使用基于操作系统原生线程模型实现，win和linux都是用的一对一的线程模型（一条Java线程映射到一条轻量级进程中）。 1. 线程的实现 1.1 使用内核线程实现 不直接使用内核线程，而是使用内核线程的高级接口：轻量级进程。 轻量级进程与内核线程的数量比为 1 ：1。 轻量级进程消耗内核资源，一个系统支持的轻量级进程的数量是有限的。 1.2 使用用户线程实现（实现复杂，没有使用） 进程与用户线程之间是 1 ：N 的关系 1.3 使用用户线程加轻量级进程混合实现 用户线程与轻量级进程之间是 N:M 的关系。 2. 线程调度 协同式线程调度：实现简单，但线程执行时间不可控 抢占式线程调度：Java一共10个优先级，但windows系统只有7个 3. 状态转换","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://fxbing.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://fxbing.github.io/tags/Java/"}]},{"title":"Pulsar 源码阅读： Retention","slug":"2019-07-23-Pulsar-Retention","date":"2019-07-22T16:00:00.000Z","updated":"2019-07-22T16:00:00.000Z","comments":true,"path":"2019/07/23/2019-07-23-Pulsar-Retention/","link":"","permalink":"http://fxbing.github.io/2019/07/23/2019-07-23-Pulsar-Retention/","excerpt":"对于已经消费确认的消息，Pulsar 可以通过配置 Retention 策略决定保留的时间及大小。\n具体参见官方文档：Message retention and expiry\nPulsar 源码中有三个部分与 Retention 相关。","text":"对于已经消费确认的消息，Pulsar 可以通过配置 Retention 策略决定保留的时间及大小。 具体参见官方文档：Message retention and expiry Pulsar 源码中有三个部分与 Retention 相关。 1. PersistentTopic 在BrokerService启动之后，this.startInactivityMonitor();操作会对不活动任务进行定期清理，其中包括 GC 操作： 123public void checkGC(int gcIntervalInSeconds) &#123; forEachTopic(topic -&gt; topic.checkGC(gcIntervalInSeconds)); &#125; 该操作会对 Broker 中的每个 Topic 进行 GC 检查清理的操作。 其中checkGC()为PersistentTopic类中的实现，如下： 1234567891011if (isActive()) &#123; lastActive = System.nanoTime();&#125; else if (System.nanoTime() - lastActive &lt; TimeUnit.SECONDS.toNanos(gcIntervalInSeconds)) &#123; // Gc interval did not expire yet return;&#125; else if (shouldTopicBeRetained()) &#123; // Topic activity is still within the retention period return; &#125; else &#123; ...&#125; shouldTopicBeRetained()函数会对需要 retention 的数据进行检查。 1234567891011121314151617181920212223/** * Check whether the topic should be retained (based on time), even tough there are no producers/consumers and it&#x27;s * marked as inactive. */ private boolean shouldTopicBeRetained() &#123; TopicName name = TopicName.get(topic); try &#123; // 从配置缓存中读取配置信息 Optional&lt;Policies&gt; policies = brokerService.pulsar().getConfigurationCache().policiesCache() .get(AdminResource.path(POLICIES, name.getNamespace())); // 如果没有配置信息，默认该 Topic 不需要 Retention ，清理。 // 如果有配置信息，根据是否超过设定的 Retention 时间选择是否进行清理 return policies.map(p -&gt; p.retention_policies).map(rp -&gt; &#123; long retentionTime = TimeUnit.MINUTES.toNanos(rp.getRetentionTimeInMinutes()); return retentionTime &lt; 0 || (System.nanoTime() - lastActive) &lt; retentionTime; &#125;).orElse(false); &#125; catch (Exception e) &#123; if (log.isDebugEnabled()) &#123; log.debug(&quot;[&#123;&#125;] Error getting policies&quot;, topic); &#125; // Don&#x27;t delete in case we cannot get the policies return true; &#125; 上面对是否到达 Retention 时间的检查用到了 AbstractTopic 类中的lastActive字段： 12// Timestamp of when this topic was last seen active protected volatile long lastActive; 该字段在每次移除Producer、移除订阅和执行checkGC()的时候进行更新。这里根据我的理解对两个问题进行解释： 为什么只在移除的时候更新，而不再加入的时候更新？ lastActive指的是最后的存活时间，所以只有移除所有的producer、consumer之后才可能需要更新。 在每次移除Producer和consumer之后都进行更新，如果保证lastActive就代表了该Topic清空Producer和Consumer的时间？ shiyonglastActive并不能代表这个意思，首先lastActive只在判断是否需要进行GC和是否需要被保留的时候使用（后者是在前者之中调用的），在使用lastActive之前，会执行isActive()函数，该函数是对该Topic是否还有与其连接的Producer和Consumer，所有之后使用lastActive参数时已经保证了isActive()不成立，即：该Topic上已经不存在Producer和Consumer了。 以上是BrokerService中进行Topic清理时对**RetentionTime**的使用，这一部分是在清理 Topic 之前根据 Retention 策略决定该 Topic 是否应该被清理。 2. ManagedLedgerImpl Ledger 有关的 Retention 特性是在**ManagedLedgerImpl**类中实现的，下面介绍该部分。 在启动BrokerService的时候，会设置managedLedgerConfig: 12managedLedgerConfig.setRetentionTime(retentionPolicies.getRetentionTimeInMinutes(), TimeUnit.MINUTES);managedLedgerConfig.setRetentionSizeInMB(retentionPolicies.getRetentionSizeInMB()); 在ManagedLedgerImpl类中，下面的函数会对已经完全被消费（所有消息已经被所有 Consumer 消费和确认过）Ledger进行周期性检查清理， 1void internalTrimConsumedLedgers(CompletableFuture&lt;?&gt; promise) 在上面的函数执行过程中，会通过hasLedgerRetentionExpired函数判断该Ledger是否需要被Retention。 12345678private boolean hasLedgerRetentionExpired(long ledgerTimestamp) &#123; if (config.getRetentionTimeMillis() &lt; 0) &#123; // Negative retention time equates to infinite retention return false; &#125; long elapsedMs = clock.millis() - ledgerTimestamp; return elapsedMs &gt; config.getRetentionTimeMillis(); &#125; 其中ledgerTimestamp参数表示Ledger建立的时间。 3. NamespaceBase 还有一个用到Retention的地方是在NamespaceBase类中，可以对存储在Zookeeper中的Retention配置信息进行get和set，它通过Namespaces类中的Restful接口对外提供服务，client中的cmd/namepaces也是通过调用Restful接口实现的对Broker端的配置的修改。 Retention 属于 Namespace 级别的配置，Namespace 只是一个逻辑上的概念，具体消息的存储是通过 Ledger 进行的（Ledger 是 Pulsar 中增加删除持久化信息的最小单位），所以 Retention 这一特性也是有 Ledger 部分实现的。","raw":null,"content":null,"categories":[{"name":"技术","slug":"技术","permalink":"http://fxbing.github.io/categories/%E6%8A%80%E6%9C%AF/"}],"tags":[{"name":"Pulsar","slug":"Pulsar","permalink":"http://fxbing.github.io/tags/Pulsar/"}]},{"title":"Hello World, Hello Blog","slug":"2019-05-09-hello-2019","date":"2019-05-08T16:00:00.000Z","updated":"2019-05-08T16:00:00.000Z","comments":true,"path":"2019/05/09/2019-05-09-hello-2019/","link":"","permalink":"http://fxbing.github.io/2019/05/09/2019-05-09-hello-2019/","excerpt":"","text":"开门啦 万事开头难 我的博客终于开通了，之后会在这里写一些东西，可能是一些想法，可能是一些笔记，也可能是一些技术文章，总之，希望我的博客可以发展起来！！！","raw":null,"content":null,"categories":[{"name":"生活","slug":"生活","permalink":"http://fxbing.github.io/categories/%E7%94%9F%E6%B4%BB/"}],"tags":[{"name":"生活","slug":"生活","permalink":"http://fxbing.github.io/tags/%E7%94%9F%E6%B4%BB/"}]}]}