<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World, Hello Blog</title>
    <url>/2019/05/09/2019-05-09-hello-2019/</url>
    <content><![CDATA[
        <h1 id="开门啦"   >
          <a href="#开门啦" class="heading-link"><i class="fas fa-link"></i></a><a href="#开门啦" class="headerlink" title="开门啦"></a>开门啦</h1>
      <blockquote>
<p>万事开头难</p>
</blockquote>
<p>我的博客终于开通了，之后会在这里写一些东西，可能是一些想法，可能是一些笔记，也可能是一些技术文章，总之，希望我的博客可以发展起来！！！</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>Pulsar 源码阅读： Retention</title>
    <url>/2019/07/23/2019-07-23-Pulsar-Retention/</url>
    <content><![CDATA[<p>对于已经消费确认的消息，Pulsar 可以通过配置 Retention 策略决定保留的时间及大小。</p>
<p>具体参见官方文档：<span class="exturl"><a class="exturl__link"   href="https://pulsar.apache.org/docs/zh-CN/cookbooks-retention-expiry/#docsNav" >Message retention and expiry</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>Pulsar 源码中有三个部分与 Retention 相关。</p>
<span id="more"></span>



        <h2 id="1-PersistentTopic"   >
          <a href="#1-PersistentTopic" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-PersistentTopic" class="headerlink" title="1. PersistentTopic"></a>1. PersistentTopic</h2>
      <p>在<strong>BrokerService</strong>启动之后，<code>this.startInactivityMonitor();</code>操作会对不活动任务进行定期清理，其中包括 GC 操作：</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">checkGC</span><span class="params">(<span class="keyword">int</span> gcIntervalInSeconds)</span> </span>&#123;</span><br><span class="line">        forEachTopic(topic -&gt; topic.checkGC(gcIntervalInSeconds));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>该操作会对 Broker 中的每个 Topic 进行 GC 检查清理的操作。</p>
<p>其中<code>checkGC()</code>为<code>PersistentTopic</code>类中的实现，如下：</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (isActive()) &#123;</span><br><span class="line">            lastActive = System.nanoTime();</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (System.nanoTime() - lastActive &lt; TimeUnit.SECONDS.toNanos(gcIntervalInSeconds)) &#123;</span><br><span class="line">            <span class="comment">// Gc interval did not expire yet</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (shouldTopicBeRetained()) &#123;</span><br><span class="line">            <span class="comment">// Topic activity is still within the retention period</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line"> &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p><code>shouldTopicBeRetained()</code>函数会对需要 retention 的数据进行检查。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Check whether the topic should be retained (based on time), even tough there are no producers/consumers and it&#x27;s</span></span><br><span class="line"><span class="comment">     * marked as inactive.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">shouldTopicBeRetained</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        TopicName name = TopicName.get(topic);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 从配置缓存中读取配置信息</span></span><br><span class="line">            Optional&lt;Policies&gt; policies = brokerService.pulsar().getConfigurationCache().policiesCache()</span><br><span class="line">                    .get(AdminResource.path(POLICIES, name.getNamespace()));</span><br><span class="line">            <span class="comment">// 如果没有配置信息，默认该 Topic 不需要 Retention ，清理。</span></span><br><span class="line">            <span class="comment">// 如果有配置信息，根据是否超过设定的 Retention 时间选择是否进行清理</span></span><br><span class="line">            <span class="keyword">return</span> policies.map(p -&gt; p.retention_policies).map(rp -&gt; &#123;</span><br><span class="line">                <span class="keyword">long</span> retentionTime = TimeUnit.MINUTES.toNanos(rp.getRetentionTimeInMinutes());</span><br><span class="line">                <span class="keyword">return</span> retentionTime &lt; <span class="number">0</span> || (System.nanoTime() - lastActive) &lt; retentionTime;</span><br><span class="line">            &#125;).orElse(<span class="keyword">false</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">                log.debug(<span class="string">&quot;[&#123;&#125;] Error getting policies&quot;</span>, topic);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Don&#x27;t delete in case we cannot get the policies</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></div></figure>

<p>上面对是否到达 Retention 时间的检查用到了 <code>AbstractTopic</code> 类中的<code>lastActive</code>字段：</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Timestamp of when this topic was last seen active</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">long</span> lastActive;</span><br></pre></td></tr></table></div></figure>

<p>该字段在每次移除<code>Producer</code>、移除订阅和执行<code>checkGC()</code>的时候进行更新。这里根据我的理解对两个问题进行解释：</p>
<ol>
<li><p>为什么只在移除的时候更新，而不再加入的时候更新？</p>
<p>lastActive指的是最后的存活时间，所以只有移除所有的producer、consumer之后才可能需要更新。</p>
</li>
<li><p>在每次移除Producer和consumer之后都进行更新，如果保证lastActive就代表了该Topic清空Producer和Consumer的时间？</p>
<p>shiyonglastActive并不能代表这个意思，首先lastActive只在判断是否需要进行GC和是否需要被保留的时候使用（后者是在前者之中调用的），在使用lastActive之前，会执行<code>isActive()</code>函数，该函数是对该Topic是否还有与其连接的Producer和Consumer，所有之后使用lastActive参数时已经保证了<code>isActive()</code>不成立，即：<strong>该Topic上已经不存在Producer和Consumer</strong>了。</p>
</li>
</ol>
<p>以上是BrokerService中进行Topic清理时对**<code>RetentionTime</code>**的使用，这一部分是在清理 Topic 之前根据 Retention 策略决定该 Topic 是否应该被清理。</p>

        <h2 id="2-ManagedLedgerImpl"   >
          <a href="#2-ManagedLedgerImpl" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-ManagedLedgerImpl" class="headerlink" title="2. ManagedLedgerImpl"></a>2. ManagedLedgerImpl</h2>
      <p>Ledger 有关的 Retention 特性是在**<code>ManagedLedgerImpl</code>**类中实现的，下面介绍该部分。</p>
<p>在启动BrokerService的时候，会设置<code>managedLedgerConfig</code>:</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line">managedLedgerConfig.setRetentionTime(retentionPolicies.getRetentionTimeInMinutes(), TimeUnit.MINUTES);</span><br><span class="line">managedLedgerConfig.setRetentionSizeInMB(retentionPolicies.getRetentionSizeInMB());</span><br></pre></td></tr></table></div></figure>

<p>在<code>ManagedLedgerImpl</code>类中，下面的函数会对已经完全被消费（所有消息已经被所有 Consumer 消费和确认过）Ledger进行周期性检查清理，</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">internalTrimConsumedLedgers</span><span class="params">(CompletableFuture&lt;?&gt; promise)</span></span></span><br></pre></td></tr></table></div></figure>

<p>在上面的函数执行过程中，会通过<code>hasLedgerRetentionExpired</code>函数判断该Ledger是否需要被Retention。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">hasLedgerRetentionExpired</span><span class="params">(<span class="keyword">long</span> ledgerTimestamp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (config.getRetentionTimeMillis() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// Negative retention time equates to infinite retention</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> elapsedMs = clock.millis() - ledgerTimestamp;</span><br><span class="line">        <span class="keyword">return</span> elapsedMs &gt; config.getRetentionTimeMillis();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>其中<code>ledgerTimestamp</code>参数表示Ledger建立的时间。</p>

        <h2 id="3-NamespaceBase"   >
          <a href="#3-NamespaceBase" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-NamespaceBase" class="headerlink" title="3. NamespaceBase"></a>3. NamespaceBase</h2>
      <p>  还有一个用到<code>Retention</code>的地方是在<code>NamespaceBase</code>类中，可以对存储在Zookeeper中的<code>Retention</code>配置信息进行get和set，它通过<code>Namespaces</code>类中的Restful接口对外提供服务，client中的<code>cmd/namepaces</code>也是通过调用Restful接口实现的对Broker端的配置的修改。</p>
<p>  Retention 属于 Namespace 级别的配置，Namespace 只是一个逻辑上的概念，具体消息的存储是通过 Ledger 进行的（Ledger 是 Pulsar 中增加删除持久化信息的最小单位），所以 Retention 这一特性也是有 Ledger 部分实现的。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Pulsar</tag>
      </tags>
  </entry>
  <entry>
    <title>Pulsar 源码阅读： Backlog</title>
    <url>/2019/08/06/2019-08-06-Pulsar%20Backlog/</url>
    <content><![CDATA[<p>对于<del>已经消费但是</del>没有确认的消息，Pulsar 可以通过配置 BacklogQuota 决定保留大小及丢弃策略。</p>
<p>具体参见官方文档：<span class="exturl"><a class="exturl__link"   href="https://pulsar.apache.org/docs/zh-CN/cookbooks-retention-expiry/#docsNav" >Message retention and expiry</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>当 Backlog 大小未达到限额时，不需要处理，当 Backlog 大小超限时，根据丢弃策略进行处理。</p>
<p>BacklogQuota 的丢弃策略一共有三种：</p>
<ol>
<li><code>producer_request_hold</code>：① 断开所有的 Producer ② 在新建 Producer 时进行检查，如果超出 BacklogQuota，则拒绝新建请求并等待超时（异步返回结果调用<code>get()</code>时才抛出异常）</li>
<li><code>producer_exception</code>：① 断开所有的 Producer ② 在新建 Producer 时进行检查，如果超出 BacklogQuota，则拒绝新建请求并抛出异常</li>
<li><code>consumer_backlog_eviction</code>：丢弃最早的 Backlog</li>
</ol>
<span id="more"></span>



        <h2 id="BacklogQuotaManager"   >
          <a href="#BacklogQuotaManager" class="heading-link"><i class="fas fa-link"></i></a><a href="#BacklogQuotaManager" class="headerlink" title="BacklogQuotaManager"></a>BacklogQuotaManager</h2>
      <p>Pulsar 中有<code>BacklogQuotaManager</code>用来进行 Backlog 处理，有下面几个关键函数。</p>

        <h3 id="handleExceededBacklogQuota"   >
          <a href="#handleExceededBacklogQuota" class="heading-link"><i class="fas fa-link"></i></a><a href="#handleExceededBacklogQuota" class="headerlink" title="handleExceededBacklogQuota"></a><code>handleExceededBacklogQuota</code></h3>
      <p>该函数用来处理 Backlog 超限的情况，对于<code>consumer_backlog_eviction</code>策略，调用<code>dropBacklog(persistentTopic, quota);</code>；对于<code>producer_exception</code>和<code>producer_request_hold</code>两种策略，调用<code>disconnectProducers(persistentTopic);</code></p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleExceededBacklogQuota</span><span class="params">(PersistentTopic persistentTopic)</span> </span>&#123;</span><br><span class="line">        TopicName topicName = TopicName.get(persistentTopic.getName());</span><br><span class="line">        String namespace = topicName.getNamespace();</span><br><span class="line">        String policyPath = AdminResource.path(POLICIES, namespace);</span><br><span class="line"></span><br><span class="line">        BacklogQuota quota = getBacklogQuota(namespace, policyPath);</span><br><span class="line">        log.info(<span class="string">&quot;Backlog quota exceeded for topic [&#123;&#125;]. Applying [&#123;&#125;] policy&quot;</span>, persistentTopic.getName(),</span><br><span class="line">                quota.getPolicy());</span><br><span class="line">        <span class="keyword">switch</span> (quota.getPolicy()) &#123;</span><br><span class="line">        <span class="keyword">case</span> consumer_backlog_eviction:</span><br><span class="line">            dropBacklog(persistentTopic, quota);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> producer_exception:</span><br><span class="line">        <span class="keyword">case</span> producer_request_hold:</span><br><span class="line">            disconnectProducers(persistentTopic);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>下面介绍<code>dropBacklog(persistentTopic, quota);</code>和<code>disconnectProducers(persistentTopic);</code>两个函数。</p>

        <h3 id="dropBacklog-persistentTopic-quota"   >
          <a href="#dropBacklog-persistentTopic-quota" class="heading-link"><i class="fas fa-link"></i></a><a href="#dropBacklog-persistentTopic-quota" class="headerlink" title="dropBacklog(persistentTopic, quota)"></a><code>dropBacklog(persistentTopic, quota)</code></h3>
      <p><code>dropBacklog(persistentTopic, quota);</code>函数负责在 Backlog 超限之后对 Backlog 中最早的消息进行丢弃，这里的丢弃实际是指<strong>向后移动未确认消息的起始标记</strong>（该 Topic 上最慢的 Consumer 的位置）。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">dropBacklog</span><span class="params">(PersistentTopic persistentTopic, BacklogQuota quota)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 设置丢弃比例为 0.9 ，即丢弃任务完成之后 Backlog 大小变为 Backlog 限额的 90%</span></span><br><span class="line">        <span class="keyword">double</span> reductionFactor = <span class="number">0.9</span>;</span><br><span class="line">        <span class="keyword">double</span> targetSize = reductionFactor * quota.getLimit();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取 Backlog 大小的估计值，这里不直接使用 Ledger 的实际大小是因为 Ledger 不一定会被及时清理，实际大小会大于 Backlog 的大小</span></span><br><span class="line">        ManagedLedgerImpl mLedger = (ManagedLedgerImpl) persistentTopic.getManagedLedger();</span><br><span class="line">        <span class="keyword">long</span> backlogSize = mLedger.getEstimatedBacklogSize(); <span class="comment">//这个函数后面介绍</span></span><br><span class="line"></span><br><span class="line">        ManagedCursor previousSlowestConsumer = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span> (backlogSize &gt; targetSize) &#123;</span><br><span class="line">            <span class="comment">// 最慢的 Consumer</span></span><br><span class="line">            ManagedCursor slowestConsumer = mLedger.getSlowestConsumer();</span><br><span class="line">            <span class="keyword">if</span> (slowestConsumer == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 需要跳过的比例</span></span><br><span class="line">            <span class="keyword">double</span> messageSkipFactor = ((backlogSize - targetSize) / backlogSize);</span><br><span class="line">            <span class="comment">// Cursor 没有移动，不需要执行清理</span></span><br><span class="line">            <span class="keyword">if</span> (slowestConsumer == previousSlowestConsumer) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 计算需要移动的距离</span></span><br><span class="line">            <span class="keyword">long</span> entriesInBacklog = slowestConsumer.getNumberOfEntriesInBacklog();</span><br><span class="line">            <span class="keyword">int</span> messagesToSkip = (<span class="keyword">int</span>) (messageSkipFactor * entriesInBacklog);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (messagesToSkip == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 移动 slowestConsumer 位置</span></span><br><span class="line">                slowestConsumer.skipEntries(messagesToSkip, IndividualDeletedEntries.Include);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                log.error(<span class="string">&quot;Error skipping [&#123;&#125;] messages from slowest consumer : [&#123;&#125;]&quot;</span>, messagesToSkip,</span><br><span class="line">                        slowestConsumer.getName());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 移动完成之后更新 backlogSize，再次执行上面的流程，确保移动之后 Backlog 没有再次超限</span></span><br><span class="line">            backlogSize = mLedger.getEstimatedBacklogSize();</span><br><span class="line">            previousSlowestConsumer = slowestConsumer;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>这里用到了一个<code>ManagedLedgerImpl</code>类中的一个函数<code>getEstimatedBacklogSize()</code>，用来估计 Backlog的大小。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getEstimatedBacklogSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">// 未确认消息的起始标记</span></span><br><span class="line">        PositionImpl pos = getMarkDeletePositionOfSlowestConsumer();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (pos == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">long</span> size = <span class="number">0</span>; <span class="comment">// Backlog 大小</span></span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> slowestConsumerLedgerId = pos.getLedgerId();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">                <span class="comment">// 获取所有 Ledger 总大小</span></span><br><span class="line">                size = getTotalSize();</span><br><span class="line">                <span class="comment">// 减去没有及时清理的 Ledger 的大小</span></span><br><span class="line">                size -= ledgers.values().stream().filter(li -&gt; li.getLedgerId() &lt; slowestConsumerLedgerId)</span><br><span class="line">                        .mapToLong(li -&gt; li.getSize()).sum();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            LedgerInfo ledgerInfo = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">                ledgerInfo = ledgers.get(pos.getLedgerId());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (ledgerInfo == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 如果 pos 指向的 Ledger 已经被删除，但是删除标记还没有更新（每次启动新的 manageLedger 时才会更新），就直接返回结果</span></span><br><span class="line">                <span class="keyword">if</span> (pos.compareTo(getMarkDeletePositionOfSlowestConsumer()) == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">return</span> size;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 如果删除标记已经更新，说明当前 pos 指向的 Ledger 已经被完全清理，则需要更新 pos 进行重试</span></span><br><span class="line">                pos = getMarkDeletePositionOfSlowestConsumer();</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">long</span> numEntries = pos.getEntryId();</span><br><span class="line">            <span class="comment">// consumedLedgerSize()第三个参数需要作为除数，不能为 0</span></span><br><span class="line">            <span class="keyword">if</span> (ledgerInfo.getEntries() == <span class="number">0</span>) &#123;</span><br><span class="line">                size -= consumedLedgerSize(currentLedgerSize, currentLedgerEntries, numEntries);</span><br><span class="line">                <span class="keyword">return</span> size;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                size -= consumedLedgerSize(ledgerInfo.getSize(), ledgerInfo.getEntries(), numEntries);</span><br><span class="line">                <span class="keyword">return</span> size;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">consumedLedgerSize</span><span class="params">(<span class="keyword">long</span> ledgerSize, <span class="keyword">long</span> ledgerEntries, <span class="keyword">long</span> consumedEntries)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (ledgerEntries &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    	<span class="comment">// 计算平均 Entry 大小</span></span><br><span class="line">        <span class="keyword">long</span> averageSize = ledgerSize / ledgerEntries;</span><br><span class="line">    	<span class="comment">// Entry Id 的起始编号为 -1，所以这里需要 +1</span></span><br><span class="line">        <span class="keyword">return</span> consumedEntries &gt;= <span class="number">0</span> ? (consumedEntries + <span class="number">1</span>) * averageSize : <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="disconnectProducers-persistentTopic"   >
          <a href="#disconnectProducers-persistentTopic" class="heading-link"><i class="fas fa-link"></i></a><a href="#disconnectProducers-persistentTopic" class="headerlink" title="disconnectProducers(persistentTopic)"></a><code>disconnectProducers(persistentTopic)</code></h3>
      <p><code>disconnectProducers(persistentTopic);</code>函数负责在<code>producer_request_hold</code>和<code>producer_exception</code>两种模式下 Backlog 超限时断开与 Producer 的链接。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">disconnectProducers</span><span class="params">(PersistentTopic persistentTopic)</span> </span>&#123;</span><br><span class="line">        List&lt;CompletableFuture&lt;Void&gt;&gt; futures = Lists.newArrayList();</span><br><span class="line">        ConcurrentOpenHashSet&lt;Producer&gt; producers = persistentTopic.getProducers();</span><br><span class="line"></span><br><span class="line">        producers.forEach(producer -&gt; &#123;</span><br><span class="line">            futures.add(producer.disconnect());</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        FutureUtil.waitForAll(futures).thenRun(() -&gt; &#123;</span><br><span class="line">            log.info(<span class="string">&quot;All producers on topic [&#123;&#125;] are disconnected&quot;</span>, persistentTopic.getName());</span><br><span class="line">        &#125;).exceptionally(exception -&gt; &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Error in disconnecting producers on topic [&#123;&#125;] [&#123;&#125;]&quot;</span>, persistentTopic.getName(), exception);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>


        <h2 id="BacklogQuota-检查"   >
          <a href="#BacklogQuota-检查" class="heading-link"><i class="fas fa-link"></i></a><a href="#BacklogQuota-检查" class="headerlink" title="BacklogQuota 检查"></a>BacklogQuota 检查</h2>
      <p>BacklogQuota 有两种形式的检查，一种是<strong>周期性检查</strong>，另一种是<strong>创建 Producer 之前检查</strong>。</p>

        <h3 id="周期性检查"   >
          <a href="#周期性检查" class="heading-link"><i class="fas fa-link"></i></a><a href="#周期性检查" class="headerlink" title="周期性检查"></a>周期性检查</h3>
      <p>在<code>BrokerService</code>启动时，会启动<code>startBacklogQuotaChecker();</code>，<code>startBacklogQuotaChecker();</code>负责周期性执行<code>monitorBacklogQuota() </code>，对于 Backlog 超限的情况，会通过<code>BacklogQuotaManager</code>进行处理。</p>
 <figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">monitorBacklogQuota</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        forEachTopic(topic -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (topic <span class="keyword">instanceof</span> PersistentTopic) &#123;</span><br><span class="line">                PersistentTopic persistentTopic = (PersistentTopic) topic;</span><br><span class="line">                <span class="keyword">if</span> (isBacklogExceeded(persistentTopic)) &#123;</span><br><span class="line">                    getBacklogQuotaManager().handleExceededBacklogQuota(persistentTopic);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">                        log.debug(<span class="string">&quot;quota not exceeded for [&#123;&#125;]&quot;</span>, topic.getName());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="创建-Producer-之前检查"   >
          <a href="#创建-Producer-之前检查" class="heading-link"><i class="fas fa-link"></i></a><a href="#创建-Producer-之前检查" class="headerlink" title="创建 Producer 之前检查"></a>创建 Producer 之前检查</h3>
      <p>在 Broker 与 Client 对接的服务端<code>ServerCnx</code>上，收到建立 Producer 的触发之后，在创建 Producer 之前，会进行 BacklogQuota 检查。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (topic.isBacklogQuotaExceeded(producerName)) &#123;</span><br><span class="line">    IllegalStateException illegalStateException = <span class="keyword">new</span> IllegalStateException(</span><br><span class="line">            <span class="string">&quot;Cannot create producer on topic with backlog quota exceeded&quot;</span>);</span><br><span class="line">    BacklogQuota.RetentionPolicy retentionPolicy = topic.getBacklogQuota().getPolicy();</span><br><span class="line">    <span class="keyword">if</span> (retentionPolicy == BacklogQuota.RetentionPolicy.producer_request_hold) &#123;</span><br><span class="line">        <span class="comment">// 返回 Error</span></span><br><span class="line">        ctx.writeAndFlush( Commands.newError(requestId, ServerError.ProducerBlockedQuotaExceededError,</span><br><span class="line">                        illegalStateException.getMessage()));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (retentionPolicy == BacklogQuota.RetentionPolicy.producer_exception) &#123;</span><br><span class="line">        <span class="comment">// 返回 Exception</span></span><br><span class="line">        ctx.writeAndFlush(Commands.newError(requestId, ServerError.ProducerBlockedQuotaExceededException,</span><br><span class="line">                illegalStateException.getMessage()));</span><br><span class="line">    &#125;</span><br><span class="line">    producerFuture.completeExceptionally(illegalStateException);</span><br><span class="line">    producers.remove(producerId, producerFuture);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>这里只进行<code>producer_request_hold</code>和<code>producer_exception</code>两种策略的处理，<code>consumer_backlog_eviction</code>只在周期性检查时进行处理。</p>
<p>对于<code>producer_request_hold</code>策略，返回 Error ，<code>ClientCnx</code>在收到 Error 之后，不会直接结束请求，会在 Future 任务超时或者调用<code>get()</code>时抛出<code>ProducerBlockedQuotaExceededError</code>异常。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">handleError</span><span class="params">(CommandError error)</span> </span>&#123;</span><br><span class="line">        checkArgument(state == State.Ready);</span><br><span class="line"></span><br><span class="line">        log.warn(<span class="string">&quot;&#123;&#125; Received error from server: &#123;&#125;&quot;</span>, ctx.channel(), error.getMessage());</span><br><span class="line">        <span class="keyword">long</span> requestId = error.getRequestId();</span><br><span class="line">        <span class="keyword">if</span> (error.getError() == ServerError.ProducerBlockedQuotaExceededError) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;&#123;&#125; Producer creation has been blocked because backlog quota exceeded for producer topic&quot;</span>,</span><br><span class="line">                    ctx.channel());</span><br><span class="line">        &#125;</span><br><span class="line">        CompletableFuture&lt;ProducerResponse&gt; requestFuture = pendingRequests.remove(requestId);</span><br><span class="line">        <span class="keyword">if</span> (requestFuture != <span class="keyword">null</span>) &#123;</span><br><span class="line">            requestFuture.completeExceptionally(getPulsarClientException(error.getError(), error.getMessage()));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;&#123;&#125; Received unknown request id from server: &#123;&#125;&quot;</span>, ctx.channel(), error.getRequestId());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>对于<code>producer_exception</code>策略，直接返回<code>ProducerBlockedQuotaExceededException</code>异常。</p>
<p>以上就是对 Pulsar 代码中 BacklogQuota 机制的实现。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Pulsar</tag>
      </tags>
  </entry>
  <entry>
    <title>CompletableFuture 总结</title>
    <url>/2019/08/18/2019-08-18-CompletableFuture/</url>
    <content><![CDATA[<p><code>CompletableFuture</code> 是Java8 中新增的用来进行函数式异步编程的工具类。</p>
<p>最近学习源码的过程中看到有很多 <code>CompletableFuture</code> 的使用，感觉自己对这个类中的各个方法的使用场景和方法不是很熟悉，遂参考了下面几篇博客进行学习（本文大部分内容也都来自下面几篇博客）：</p>
<p><span class="exturl"><a class="exturl__link"   href="https://colobu.com/2016/02/29/Java-CompletableFuture/" >Java CompletableFuture 详解</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link"   href="https://juejin.im/post/59eae61b51882549fc512b34" >Java8新的异步编程方式 CompletableFuture(一)</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link"   href="https://juejin.im/post/59eae6e4f265da430e4e4cb5" >Java8新的异步编程方式 CompletableFuture(二)</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link"   href="https://juejin.im/post/59eae6e4f265da430e4e4cb5" >Java8新的异步编程方式 CompletableFuture(三)</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>上面的博客介绍的比较详细，为了自己查阅回看的方便，这里对这些方法进行一下总结（这里只总结不举例，具体使用需要看上面的博客）。</p>
<span id="more"></span>



        <h2 id="Future接口"   >
          <a href="#Future接口" class="heading-link"><i class="fas fa-link"></i></a><a href="#Future接口" class="headerlink" title="Future接口"></a>Future接口</h2>
      <p><code>Feture</code> 接口包含五个方法，介绍如下：</p>
<ul>
<li><p><code>boolean cancel (boolean mayInterruptIfRunning)</code> 取消任务的执行。参数指定是否立即中断任务执行，或者等等任务结束</p>
</li>
<li><p><code>boolean isCancelled ()</code> 任务是否已经取消，任务正常完成前将其取消，则返回 <code>true</code></p>
</li>
<li><p><code>boolean isDone ()</code> 任务是否已经完成。需要注意的是如果任务正常终止、异常或取消，都将返回<code>true</code></p>
</li>
<li><p><code>V get () throws InterruptedException, ExecutionException</code>  等待任务执行结束，然后获得V类型的结果。InterruptedException 线程被中断异常， ExecutionException任务执行异常，如果任务被取消，还会抛出CancellationException</p>
</li>
<li><p><code>V get (long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException </code>同上面的get功能一样，多了设置超时时间。参数timeout指定超时时间，uint指定时间的单位，在枚举类TimeUnit中有相关的定义。如果计 算超时，将抛出TimeoutException</p>
</li>
</ul>

        <h2 id="主动完成计算"   >
          <a href="#主动完成计算" class="heading-link"><i class="fas fa-link"></i></a><a href="#主动完成计算" class="headerlink" title="主动完成计算"></a>主动完成计算</h2>
      <p><code>CompletableFuture</code>实现了<code>CompletionStage</code>和<code>Future</code>两个接口。</p>

        <h4 id="通过阻塞或者轮询获得结果"   >
          <a href="#通过阻塞或者轮询获得结果" class="heading-link"><i class="fas fa-link"></i></a><a href="#通过阻塞或者轮询获得结果" class="headerlink" title="通过阻塞或者轮询获得结果"></a>通过阻塞或者轮询获得结果</h4>
      <div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>public T get()</code></td>
<td><code>Future</code>接口实现</td>
</tr>
<tr>
<td><code>public T get(long timeout, TimeUnit unit)</code></td>
<td><code>Future</code>接口实现</td>
</tr>
<tr>
<td><code>public T getNow(T valueIfAbsent)</code></td>
<td>如果结果已经计算完则返回结果或者抛出异常，否则返回给定的<code>valueIfAbsent</code>值。</td>
</tr>
<tr>
<td><code>public T join()</code></td>
<td>返回计算的结果或者抛出一个unchecked异常(CompletionException)</td>
</tr>
</tbody></table></div>
<blockquote>
<p><code>join()</code>和<code>get()</code>的区别是，<code>join()</code>只会抛出<strong>未检查异常</strong>（不需要使用<code>try...catch..</code>进行处理），而<code>get()</code>会抛出<strong>检查异常</strong>。</p>
</blockquote>

        <h4 id="异步获取结果"   >
          <a href="#异步获取结果" class="heading-link"><i class="fas fa-link"></i></a><a href="#异步获取结果" class="headerlink" title="异步获取结果"></a>异步获取结果</h4>
      <blockquote>
<ul>
<li><p>下面两个函数的调用会立即执行，并且只能执行一次。</p>
</li>
<li><p>如果该任务已经执行完成，那么下面两个调用会无效，只能获取执行完成的结果。其实就是使任务立即结束（返回指定结果或者指定抛出异常）。</p>
</li>
<li><p>比较适合需要返回<code>CompletableFuture</code>的方法，先创建一个空的<code>CompletableFuture</code>，之后通过下面两个函数指定前面创建的<code>CompletableFuture</code>的返回值。</p>
</li>
</ul>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>complete(T t)</code></td>
<td>完成异步执行，并返回future的结果</td>
</tr>
<tr>
<td><code>completeExceptionally(Throwable ex)</code></td>
<td>异步执行不正常的结束</td>
</tr>
</tbody></table></div>

        <h2 id="静态工厂方法"   >
          <a href="#静态工厂方法" class="heading-link"><i class="fas fa-link"></i></a><a href="#静态工厂方法" class="headerlink" title="静态工厂方法"></a>静态工厂方法</h2>
      <blockquote>
<p>run 和 supply 的主要区别是异步操作是否有返回值（下面列出的所有方法也基本都是按照<strong>是否有返回值</strong>分为两类）。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>runAsync(Runnable runnable)</code></td>
<td>使用ForkJoinPool.commonPool()作为它的线程池执行异步代码。</td>
</tr>
<tr>
<td><code>runAsync(Runnable runnable, Executor executor)</code></td>
<td>使用指定的thread pool执行异步代码。</td>
</tr>
<tr>
<td><code>supplyAsync(Supplier&lt;U&gt; supplier)</code></td>
<td>使用ForkJoinPool.commonPool()作为它的线程池执行异步代码，异步操作有返回值。</td>
</tr>
<tr>
<td><code>supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)</code></td>
<td>使用指定的thread pool执行异步代码，异步操作有返回值。</td>
</tr>
</tbody></table></div>
<blockquote>
<p>下面几乎所有的方法都是一式三份，三种方法的区别是</p>
<ul>
<li>直接在当前线程执行</li>
<li>换另一个线程（但是不指定线程）异步执行</li>
<li>指定线程执行</li>
</ul>
</blockquote>

        <h2 id="转换"   >
          <a href="#转换" class="heading-link"><i class="fas fa-link"></i></a><a href="#转换" class="headerlink" title="转换"></a>转换</h2>
      <blockquote>
<p>相当于 map 操作</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenApply(Function&lt;? super T,? extends U&gt; fn)</code></td>
<td>接受一个Function&lt;? super T,? extends U&gt;参数用来转换CompletableFuture</td>
</tr>
<tr>
<td><code>thenApplyAsync(Function&lt;? super T,? extends U&gt; fn)</code></td>
<td>接受一个Function&lt;? super T,? extends U&gt;参数用来转换CompletableFuture，使用ForkJoinPool</td>
</tr>
<tr>
<td><code>thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor)</code></td>
<td>接受一个Function&lt;? super T,? extends U&gt;参数用来转换CompletableFuture，使用指定的线程池</td>
</tr>
</tbody></table></div>
<blockquote>
<p>相当于 flatMap 操作</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn)</code></td>
<td>在异步操作完成的时候对异步操作的结果进行一些操作，并且仍然返回CompletableFuture类型。</td>
</tr>
<tr>
<td><code>thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn)</code></td>
<td>在异步操作完成的时候对异步操作的结果进行一些操作，并且仍然返回CompletableFuture类型。使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn,Executor executor)</code></td>
<td>在异步操作完成的时候对异步操作的结果进行一些操作，并且仍然返回CompletableFuture类型。使用指定的线程池。</td>
</tr>
</tbody></table></div>

        <h2 id="组合"   >
          <a href="#组合" class="heading-link"><i class="fas fa-link"></i></a><a href="#组合" class="headerlink" title="组合"></a>组合</h2>
      <div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的fn，用它来组合另外一个CompletableFuture的结果。</td>
</tr>
<tr>
<td><code>thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的fn，用它来组合另外一个CompletableFuture的结果。使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn, Executor executor)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的fn，用它来组合另外一个CompletableFuture的结果。使用指定的线程池。</td>
</tr>
</tbody></table></div>
<blockquote>
<p>thenAcceptBoth跟thenCombine类似，但是返回CompletableFuture类型。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenAcceptBoth(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; action)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的action，用它来组合另外一个CompletableFuture的结果。</td>
</tr>
<tr>
<td><code>thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; action)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的action，用它来组合另外一个CompletableFuture的结果。使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; action, Executor executor)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的action，用它来组合另外一个CompletableFuture的结果。使用指定的线程池。</td>
</tr>
</tbody></table></div>

        <h2 id="计算结果完成时的处理"   >
          <a href="#计算结果完成时的处理" class="heading-link"><i class="fas fa-link"></i></a><a href="#计算结果完成时的处理" class="headerlink" title="计算结果完成时的处理"></a>计算结果完成时的处理</h2>
      <blockquote>
<ul>
<li><code>Action</code>的类型是<code>BiConsumer&lt;? super T,? super Throwable&gt;</code>，它可以处理正常的计算结果，或者异常情况。</li>
<li>方法不以<code>Async</code>结尾，意味着<code>Action</code>使用相同的线程执行，而<code>Async</code>可能会使用其它的线程去执行(如果使用相同的线程池，也可能会被同一个线程选中执行</li>
</ul>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action)</code></td>
<td>当CompletableFuture完成计算结果时对结果进行处理，或者当CompletableFuture产生异常的时候对异常进行处理。</td>
</tr>
<tr>
<td><code>whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action)</code></td>
<td>当CompletableFuture完成计算结果时对结果进行处理，或者当CompletableFuture产生异常的时候对异常进行处理。使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)</code></td>
<td>当CompletableFuture完成计算结果时对结果进行处理，或者当CompletableFuture产生异常的时候对异常进行处理。使用指定的线程池。</td>
</tr>
</tbody></table></div>
<blockquote>
<p><code>handle()</code>相当于whenComplete()+转换。</p>
<p><code>handle()</code>也可以理解为和<code>thenApply()</code>的含义更为相似，但是比<code>thenApply()</code>增加异常处理的功能。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn)</code></td>
<td>当CompletableFuture完成计算结果或者抛出异常的时候，执行提供的fn</td>
</tr>
<tr>
<td><code>handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn)</code></td>
<td>当CompletableFuture完成计算结果或者抛出异常的时候，执行提供的fn，使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn, Executor executor)</code></td>
<td>当CompletableFuture完成计算结果或者抛出异常的时候，执行提供的fn，使用指定的线程池。</td>
</tr>
</tbody></table></div>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>exceptionally(Function fn)</code></td>
<td>只有当CompletableFuture抛出异常的时候，才会触发这个exceptionally的计算，调用function计算值。</td>
</tr>
</tbody></table></div>

        <h2 id="纯消费"   >
          <a href="#纯消费" class="heading-link"><i class="fas fa-link"></i></a><a href="#纯消费" class="headerlink" title="纯消费"></a>纯消费</h2>
      <div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenAccept(Consumer&lt;? super T&gt; action)</code></td>
<td>当CompletableFuture完成计算结果，只对结果执行Action，而不返回新的计算值</td>
</tr>
<tr>
<td><code>thenAcceptAsync(Consumer&lt;? super T&gt; action)</code></td>
<td>当CompletableFuture完成计算结果，只对结果执行Action，而不返回新的计算值，使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor)</code></td>
<td>当CompletableFuture完成计算结果，只对结果执行Action，而不返回新的计算值</td>
</tr>
</tbody></table></div>

        <h2 id="Either"   >
          <a href="#Either" class="heading-link"><i class="fas fa-link"></i></a><a href="#Either" class="headerlink" title="Either"></a>Either</h2>
      <blockquote>
<p>Either 表示的是两个CompletableFuture，当其中任意一个CompletableFuture计算完成的时候就会执行。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>acceptEither(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)</code></td>
<td>当任意一个CompletableFuture完成的时候，action这个消费者就会被执行。</td>
</tr>
<tr>
<td><code>acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)</code></td>
<td>当任意一个CompletableFuture完成的时候，action这个消费者就会被执行。使用ForkJoinPool</td>
</tr>
<tr>
<td><code>acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action, Executor executor)</code></td>
<td>当任意一个CompletableFuture完成的时候，action这个消费者就会被执行。使用指定的线程池</td>
</tr>
</tbody></table></div>
<blockquote>
<p><code>applyToEither()</code> 是<code>acceptEither()</code>的哥哥. 当两个future其中一个完成后，后者用于只是简单地调用一些代码，<code>applyToEither()</code>会返回一个新的future. 这个future是在前面两个future其中一个完成后进行执行完成。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>applyToEither(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn)</code></td>
<td>当任意一个CompletableFuture完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture<U>的计算结果。</td>
</tr>
<tr>
<td><code>applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn)</code></td>
<td>当任意一个CompletableFuture完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture<U>的计算结果。使用ForkJoinPool</td>
</tr>
<tr>
<td><code>applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn, Executor executor)</code></td>
<td>当任意一个CompletableFuture完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture<U>的计算结果。使用指定的线程池</td>
</tr>
</tbody></table></div>

        <h2 id="其他方法"   >
          <a href="#其他方法" class="heading-link"><i class="fas fa-link"></i></a><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h2>
      <div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>allOf(CompletableFuture&lt;?&gt;... cfs)</code></td>
<td>在所有Future对象完成后结束，并返回一个future。</td>
</tr>
<tr>
<td><code>anyOf(CompletableFuture&lt;?&gt;... cfs)</code></td>
<td>在任何一个Future对象结束后结束，并返回一个future。</td>
</tr>
</tbody></table></div>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次kafka宕机问题排查</title>
    <url>/2021/05/08/%E8%AE%B0%E4%B8%80%E6%AC%A1kafka%E5%AE%95%E6%9C%BA%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<p>kafka集群出现宕机报警，自动替换新broker一直无法成功。</p>
<span id="more"></span>


        <h2 id="排查过程"   >
          <a href="#排查过程" class="heading-link"><i class="fas fa-link"></i></a><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2>
      <ol>
<li><p>kafka集群有一个broker宕机，自动替换机器一直无法成功，手动重启时发现该broker对应的zookeeper上的/brokers/ids目录一直被删除导致。</p>
</li>
<li><p>定位zk目录一直被删除的原因：参照<span class="exturl"><a class="exturl__link"   href="https://www.cnblogs.com/cyl048/p/8984661.html" >Zookeeper日志文件&amp;事务日志&amp;数据快照</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>查看zk事务日志</p>
</li>
<li><p>首先查看zk事务日志所在的目录:</p>
<figure class="highlight shell"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> zookeeper/conf</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> grep dataLogDir *</span></span><br><span class="line">zoo.cfg:dataLogDir=/home/var/lib/zookeeper/</span><br></pre></td></tr></table></div></figure></li>
<li><p>通过<code>java -classpath .:lib/slf4j-api-1.6.1.jar:zookeeper-3.4.6.jar org.apache.zookeeper.server.LogFormatter /home/var/lib/zookeeper/version-2/log.10263212a| grep brokers/ids</code>查看事务日志，发现/brokers/ids/9984确实在刚刚创建时就被立刻删除了，并且可以找到zk的session id<img src="1.png"></p>
</li>
<li><p>任一找到一个删除该zk节点的session id，查找zk日志，确定删除操作的客户端<img src="2.png"></p>
<blockquote>
<ul>
<li>排查过程中发现，好多session id在zk日志中找不到，后面经同学提示才发现原因是zk有5个节点，事务日志在所有节点时相同的，但是普通日志只包含连接本节点的session id，所以需要在所有zk节点的普通日志中进行查找。</li>
<li>session closed时才会打印客户端ip</li>
</ul>
</blockquote>
</li>
<li><p>问题确定：原来是删除操作的broker与新启动的broker id相同，都为9884，但是由于执行删除操作的机器有问题，一直在重启，每次启动时前都会先删除/brokers/ids/9984这个zk节点</p>
</li>
</ol>

        <h2 id="经验总结"   >
          <a href="#经验总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#经验总结" class="headerlink" title="经验总结"></a>经验总结</h2>
      <ol>
<li>zk事务日志的查看方式：<span class="exturl"><a class="exturl__link"   href="https://www.cnblogs.com/cyl048/p/8984661.html" >Zookeeper日志文件&amp;事务日志&amp;数据快照</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li>zk所有节点的事务日志是相同的，但是普通日志中只有与当前节点连接的session信息</li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>zookeeper</tag>
        <tag>问题排查</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次线上服务Full GC问题排查</title>
    <url>/2021/05/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<p>有一个线上服务多个集群出现FGC，降低集群压力之后并没有改善。</p>
<span id="more"></span>


        <h2 id="背景"   >
          <a href="#背景" class="heading-link"><i class="fas fa-link"></i></a><a href="#背景" class="headerlink" title="背景"></a>背景</h2>
      <ul>
<li>这是一个kafka mirror服务，用来在多个kafka集群之间进行数据同步。</li>
<li>mirror服务是无状态的，因此一般情况下FGC不会对系统产生严重影响，但是仍然存在较大风险。</li>
</ul>

        <h2 id="排查过程"   >
          <a href="#排查过程" class="heading-link"><i class="fas fa-link"></i></a><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2>
      
        <h3 id="一-缩小范围"   >
          <a href="#一-缩小范围" class="heading-link"><i class="fas fa-link"></i></a><a href="#一-缩小范围" class="headerlink" title="一. 缩小范围"></a>一. 缩小范围</h3>
      <p>​    FGC是从五一长假期间开始发生的，并且在FGC发生之前，在两个FGC集群中增加过任务，因此推测可能与<strong>集群压力较大</strong>有关系，为了确定这一推测，在五一长假结束之后，将新增加的任务全部迁移至同一个mirror集群A，使另一个mirror集群B状态与出现FGC之前完全相同，但是，事与愿违，集群B的FGC没有恢复，仍然存在问题。</p>
<p>​    因此，基本可以确认本次FGC与五一长假期间集群压力增加没有关系，需要具体分析FGC的原因，确认是否存在<strong>内存泄漏</strong>的情况。</p>

        <h3 id="二-具体分析"   >
          <a href="#二-具体分析" class="heading-link"><i class="fas fa-link"></i></a><a href="#二-具体分析" class="headerlink" title="二. 具体分析"></a>二. 具体分析</h3>
      <ol>
<li><p>首先通过jmap查看内存的占用情况：</p>
<figure class="highlight shell"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> jmap -histo <span class="variable">$&#123;PID&#125;</span></span></span><br></pre></td></tr></table></div></figure>

<p><img src="1.png"></p>
<p>可以发现，<code>com.mysql.cj.jdbc.ByteArrayRow</code>这个对象占了4G多的内存（总内存32G），虽然代码中有查询mysql代码，但是查询结果都已经解析存放在了<code>Map</code>、<code>List</code>等对象中。</p>
</li>
<li><p>为了确认该mysql对象是不是查询的临时变量，会不会被FGC清理，主动找一台机器执行FGC，</p>
<figure class="highlight shell"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> jmap -histo:live  <span class="variable">$&#123;PID&#125;</span></span></span><br></pre></td></tr></table></div></figure>

<p>发现mysql对象占用的大小并未减少且仍在增加，推测这个mysql对象应该是引起FGC的原因。</p>
</li>
<li><p>查看代码发现，除了一处定期执行的SQL查询外，在任务不变的情况下，其他代码在系统启动后都不会进行SQL查询。并且，这条定期执行的SQL执行周期在这个版本中并没有发生变化，一直是2分钟一次。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line">kafkaScheduler.schedule(<span class="string">&quot;update-Maps-Task&quot;</span>, updateMapsTask, <span class="number">20000</span>, <span class="number">120000</span>, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateMapsTask</span></span>() &#123;</span><br><span class="line">    mysqlUtil.updateTopicMap(<span class="string">&quot;SELECT * FROM table2&quot;</span>)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure></li>
<li><p>验证<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象的内存占用是否与上述Scheduler有关：</p>
<ul>
<li>找一台机器每2分钟查询一次<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象大小，发现每两次查询到的对象大小之间的差值均相同，为395360</li>
<li>根据服务启动时间，按照每两分钟增长395360B的速度进行计算，得到<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象大小为4GB，该估算值与当前通过jmap看到的对象大小一致</li>
</ul>
<p>基本可以确认是这个定时查询导致的。</p>
</li>
<li><p>进一步验证：</p>
<ul>
<li>重启服务，发现<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象特别小；</li>
<li>将定时任务周期从2分钟改为3秒，发现<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象3分钟内增长了15MB，且与估算值一致。</li>
</ul>
</li>
<li><p>问题修复：</p>
<p>通过查看代码和Google发现，需要显式关闭mysql查询使用的<code>Statement</code>对象和<code>ResultSet</code>对象，</p>
<blockquote>
<p><span class="exturl"><a class="exturl__link"   href="https://stackoverflow.com/questions/4507440/must-jdbc-resultsets-and-statements-be-closed-separately-although-the-connection/15728512" >https://stackoverflow.com/questions/4507440/must-jdbc-resultsets-and-statements-be-closed-separately-although-the-connection/15728512</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
</blockquote>
</li>
<li><p>修复验证：</p>
<p>JVM内存设置为50MB，定时任务周期设置为3秒。</p>
<p>修复前，mysql内存不断增加，出现几次FGC，直到OOM 。</p>
<p><img src="2.png"></p>
<p>修复后，未出现FGC，有YGC，YGC之后mysql内存被回收 。</p>
<p><img src="3.png"></p>
</li>
</ol>

        <h2 id="总结"   >
          <a href="#总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#总结" class="headerlink" title="总结"></a>总结</h2>
      <ul>
<li>旧版本代码虽然也是2分钟执行一次查询，但是查询数据表不同，旧版本数据表中只有2条数据，新版本数据表中有7000+数据，内存积累很慢，所以旧版本一致没有发现问题。</li>
<li>查询mysql时需要及时关闭<code>Statement</code>对象和<code>ResultSet</code>对象，否则会因为对象一直被引用而无法自动进行垃圾回收。</li>
<li>分析FGC问题时需要主动使用jmap等工具，尽早发现问题。</li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>问题排查</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>《深入理解Java虚拟机》笔记</title>
    <url>/2019/07/28/2019-07-28-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>阅读了《深入理解Java虚拟机》的部分章节，并做了一些简单的笔记，不是很详细，但是可以方便自己查阅。</p>
<span id="more"></span>



        <h2 id="第三章-垃圾收集器与内存分配策略"   >
          <a href="#第三章-垃圾收集器与内存分配策略" class="heading-link"><i class="fas fa-link"></i></a><a href="#第三章-垃圾收集器与内存分配策略" class="headerlink" title="第三章 垃圾收集器与内存分配策略"></a>第三章 垃圾收集器与内存分配策略</h2>
      
        <h3 id="1-对象是否存活"   >
          <a href="#1-对象是否存活" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-对象是否存活" class="headerlink" title="1. 对象是否存活"></a>1. 对象是否存活</h3>
      
        <h4 id="引用计数法："   >
          <a href="#引用计数法：" class="heading-link"><i class="fas fa-link"></i></a><a href="#引用计数法：" class="headerlink" title="引用计数法："></a>引用计数法：</h4>
      <p>很难解决对象间的循环引用</p>

        <h4 id="可达性分析"   >
          <a href="#可达性分析" class="heading-link"><i class="fas fa-link"></i></a><a href="#可达性分析" class="headerlink" title="可达性分析"></a>可达性分析</h4>
      
        <h5 id="可以作为GC-Roots的对象："   >
          <a href="#可以作为GC-Roots的对象：" class="heading-link"><i class="fas fa-link"></i></a><a href="#可以作为GC-Roots的对象：" class="headerlink" title="可以作为GC Roots的对象："></a>可以作为GC Roots的对象：</h5>
      <ul>
<li>虚拟机栈中引用的对象</li>
<li>方法区中类静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
<li>本地方法栈中JNI（Native方法）引用的对象</li>
</ul>

        <h3 id="2-引用分类（JDK1-2实现）"   >
          <a href="#2-引用分类（JDK1-2实现）" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-引用分类（JDK1-2实现）" class="headerlink" title="2. 引用分类（JDK1.2实现）"></a>2. 引用分类（JDK1.2实现）</h3>
      <ul>
<li><strong>强引用</strong>：永远不回收</li>
<li><strong>软引用SoftReference</strong>（有用但非必须）：内存溢出之前回收</li>
<li><strong>弱引用WeakReference</strong>（非必须）：GC时回收</li>
<li><strong>虚引用PhantomReference</strong>（幽灵引用/幻影引用）：目的是能在这个对象被收集器回收时收到一个系统通知</li>
</ul>

        <h3 id="3-finalize-（不建议使用）"   >
          <a href="#3-finalize-（不建议使用）" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-finalize-（不建议使用）" class="headerlink" title="3. finalize()（不建议使用）"></a>3. finalize()（不建议使用）</h3>
      <blockquote>
<p>判断对象是否死亡会经历<strong>两次标记</strong>过程：<br>①判断是否与GC Roots相连；<br>②执行finalize()（对象没有覆盖finalize()或finalize()已经被调用过一次时，虚拟机认为没必要执行finalize()，不会进行第二次标记）。</p>
</blockquote>
<ul>
<li>被调用时会放在由虚拟机自动创建的、低优先级的队列<strong>F-Queue</strong>中</li>
<li>finalize()是对象唯一的自救机会，例如：在finalize()中将this赋值给某个类变量或者对象的成员变量</li>
<li>运行代价高昂，不确定性大、无法保证各个对象的调用顺序</li>
<li>finalize()能做的所有工作使用try-finally或者其他方式可以做得更好、更及时</li>
</ul>

        <h3 id="4-回收方法区"   >
          <a href="#4-回收方法区" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-回收方法区" class="headerlink" title="4. 回收方法区"></a>4. 回收方法区</h3>
      
        <h5 id="废弃常量"   >
          <a href="#废弃常量" class="heading-link"><i class="fas fa-link"></i></a><a href="#废弃常量" class="headerlink" title="废弃常量"></a>废弃常量</h5>
      <p>与Java堆的回收逻辑类似</p>

        <h5 id="无用的类"   >
          <a href="#无用的类" class="heading-link"><i class="fas fa-link"></i></a><a href="#无用的类" class="headerlink" title="无用的类"></a>无用的类</h5>
      <ul>
<li>该类的所有实例已经被回收</li>
<li>加载该类的ClassLoader已经被回收</li>
<li>该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li>
</ul>

        <h3 id="5-垃圾收集算法"   >
          <a href="#5-垃圾收集算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-垃圾收集算法" class="headerlink" title="5. 垃圾收集算法"></a>5. 垃圾收集算法</h3>
      
        <h4 id="（1）标记清除算法"   >
          <a href="#（1）标记清除算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）标记清除算法" class="headerlink" title="（1）标记清除算法"></a>（1）标记清除算法</h4>
      <ul>
<li>效率不高</li>
<li>会大量不连续内存碎片</li>
</ul>

        <h4 id="（2）复制算法"   >
          <a href="#（2）复制算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）复制算法" class="headerlink" title="（2）复制算法"></a>（2）复制算法</h4>
      <ul>
<li>内存缩小为原来的一半</li>
<li>HotSpot默认的Eden与Survivor的大小比例为8:1</li>
<li>没有办法保证每次回收都只有不多于10%的对象存活。当Survivor空间不够用时，需要依赖老年代进行<strong>分配担保</strong>。<blockquote>
<p>分配担保：当Survivor空间不能放下上一次 YGC 之后存活的对象时，这些对象直接通过分配担保机制进入老年代。</p>
</blockquote>
</li>
</ul>

        <h4 id="（3）标记整理算法"   >
          <a href="#（3）标记整理算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）标记整理算法" class="headerlink" title="（3）标记整理算法"></a>（3）标记整理算法</h4>
      
        <h4 id="（4）分代收集算法"   >
          <a href="#（4）分代收集算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#（4）分代收集算法" class="headerlink" title="（4）分代收集算法"></a>（4）分代收集算法</h4>
      <p>新生代每次垃圾收集都会有大量对象死去，少量存活，所以采用复制算法。<br>老年代对象存活率高、没有额外的空间对它进行担保，必须使用“标记-清理”或者“标记-整理”算法。</p>

        <h3 id="6-HotSpot算法实现"   >
          <a href="#6-HotSpot算法实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-HotSpot算法实现" class="headerlink" title="6. HotSpot算法实现"></a>6. HotSpot算法实现</h3>
      
        <h4 id="（1）枚举根节点"   >
          <a href="#（1）枚举根节点" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）枚举根节点" class="headerlink" title="（1）枚举根节点"></a>（1）枚举根节点</h4>
      <ul>
<li>Java虚拟机使用准确式GC（必须确定一个变量是引用还是真正的数据）</li>
<li>虚拟机停顿之后不需要检查所有的执行上下文和全局的引用位置。</li>
<li>类加载完成时计算出什么偏移量上是什么类型的数据，JIT编译时在特定位置（<strong>安全点</strong>）记录<strong>OopMap</strong>数据结构（指明栈和寄存器哪些位置是引用）</li>
</ul>

        <h4 id="（2）安全点（SafePoint）"   >
          <a href="#（2）安全点（SafePoint）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）安全点（SafePoint）" class="headerlink" title="（2）安全点（SafePoint）"></a>（2）安全点（SafePoint）</h4>
      <ul>
<li>程序执行时并非在所有地方都能停顿下来开始GC，只有到达安全点时才能暂停。</li>
<li><strong>安全点选定原则</strong>：是否具有让程序<strong>长时间执行</strong>的特征</li>
<li><strong>长时间执行</strong>：指令序列复用（如：方法调用、循环跳转、异常跳转）</li>
<li><strong>抢先式中断（已经被弃用）</strong>：所有线程中断，不在安全点的线程恢复执行。  </li>
</ul>
<p><strong>主动式中断</strong>：在安全点设置中断标志，程序执行到安全点时主动轮询这个标志，判断是否需要进行中断。</p>

        <h4 id="（3）安全区域（Safe-Region）"   >
          <a href="#（3）安全区域（Safe-Region）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）安全区域（Safe-Region）" class="headerlink" title="（3）安全区域（Safe Region）"></a>（3）安全区域（Safe Region）</h4>
      <ul>
<li>定义：一段代码中，引用关系不会发生变化。（线程处于Sleep或Blocked状态）</li>
<li>线程执行到Safe Region时，标识自己进入Safe Region状态；<br>JVM GC时不管Safe Region状态的线程；<br>当线程离开Safe Region状态时，检查系统是否完成了根节点枚举或整个GC过程；<br>如果完成了，那线程继续执行，否则，必须等待收到可以安全离开Safe Region的信号为止。</li>
</ul>

        <h3 id="7-垃圾收集器"   >
          <a href="#7-垃圾收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#7-垃圾收集器" class="headerlink" title="7. 垃圾收集器"></a>7. 垃圾收集器</h3>
      <p>连线代表可以组合使用。<br><img src="https://i.bmp.ovh/imgs/2019/05/8e139eb7578dd5fc.jpg"></p>

        <h4 id="（1）Serial收集器（Client模式下新生代垃圾清理首选）"   >
          <a href="#（1）Serial收集器（Client模式下新生代垃圾清理首选）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）Serial收集器（Client模式下新生代垃圾清理首选）" class="headerlink" title="（1）Serial收集器（Client模式下新生代垃圾清理首选）"></a>（1）Serial收集器（Client模式下新生代垃圾清理首选）</h4>
      <ul>
<li>进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。</li>
<li>Serial/Serial Old收集器在新生代采用<strong>复制算法</strong>，老年代采用<strong>标记-整理算法</strong>。</li>
</ul>

        <h4 id="（2）ParNew收集器（Server模式下新生代垃圾清理首选）"   >
          <a href="#（2）ParNew收集器（Server模式下新生代垃圾清理首选）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）ParNew收集器（Server模式下新生代垃圾清理首选）" class="headerlink" title="（2）ParNew收集器（Server模式下新生代垃圾清理首选）"></a>（2）ParNew收集器（Server模式下新生代垃圾清理首选）</h4>
      <ul>
<li>多线程版本的Serial收集器</li>
<li>第一款真正意义上的<strong>并发</strong>收集器</li>
<li>默认开启的收集线程数与CPU的数量相同</li>
</ul>

        <h4 id="（3）Parallel-Scavenge收集器"   >
          <a href="#（3）Parallel-Scavenge收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）Parallel-Scavenge收集器" class="headerlink" title="（3）Parallel Scavenge收集器"></a>（3）Parallel Scavenge收集器</h4>
      <ul>
<li>目标：达到一个可控制的吞吐量。（吞吐量 = 运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)）</li>
<li>适合在后台运算而不需要太多交互的任务</li>
<li>可以设置最大垃圾收集停段时间（-XX:MaxGCPauseMillis）和吞吐量大小（-XX:GCTimeRatio）</li>
<li>可以开启-XX:UseAdaptiveSizePolicy，之后虚拟机根据系统运行状况自动设置新生代大小、Eden与Survivor比例、晋升老年代对象大小等细节参数。（<strong>GC自适应的调节策略</strong>）</li>
</ul>

        <h4 id="（4）Serial-Old收集器"   >
          <a href="#（4）Serial-Old收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#（4）Serial-Old收集器" class="headerlink" title="（4）Serial Old收集器"></a>（4）Serial Old收集器</h4>
      
        <h4 id="（5）Parallel-Old收集器"   >
          <a href="#（5）Parallel-Old收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#（5）Parallel-Old收集器" class="headerlink" title="（5）Parallel Old收集器"></a>（5）Parallel Old收集器</h4>
      
        <h4 id="（6）CMS收集器"   >
          <a href="#（6）CMS收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#（6）CMS收集器" class="headerlink" title="（6）CMS收集器"></a>（6）CMS收集器</h4>
      <ul>
<li>四个步骤：<br>a: 初始标记（停顿）：记录与GC Roots直接相连的对象<br>b: 并发标记：GC Roots Tracing<br>c: 重新标记（停顿更长）：修正并发标记期间因用户程序继续运作而导致的标记产生变动的记录<br>d: 并发清除</li>
<li>对 CPU 资源敏感</li>
<li>无法处理<strong>浮动垃圾</strong>（并发清除阶段用户程序产生的新的垃圾，需要等下次GC时再进行清理），可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。（不能等老年代被填满之后进行清理，需要为并发清除期间用户程序的执行预留空间）</li>
<li>空间碎片过多</li>
</ul>

        <h4 id="（7）G1收集器（JDK1-7）"   >
          <a href="#（7）G1收集器（JDK1-7）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（7）G1收集器（JDK1-7）" class="headerlink" title="（7）G1收集器（JDK1.7）"></a>（7）G1收集器（JDK1.7）</h4>
      <ul>
<li>并行与并发</li>
<li>分代收集</li>
<li><strong>空间整合</strong>：从整体上看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制“算法实现的。</li>
<li><strong>可预测的停顿</strong>：使用者可以指定垃圾收集上消耗的时间不得超过 M 毫秒。</li>
<li>分配的对象会记录在 Remembered Set 中，内存回收时再GC根节点的枚举范围中加入 Remembered Set ，确保不对全堆扫描也不会有泄露。</li>
<li>不计算维护 Remembered Set 的过程，可以分为以下几个步骤：<br>a: 初始标记<br>b: 并发标记<br>c: 最终标记：并发标记期间对象变化记录在线程 Remembered Set Logs 中，该阶段将 Remembered Set Logs 整合到 Remembered Set 中。<br>d: 筛选回收：根据用户期望的 GC 停顿时间制定回收计划。</li>
</ul>

        <h3 id="8-内存分配与回收策略"   >
          <a href="#8-内存分配与回收策略" class="heading-link"><i class="fas fa-link"></i></a><a href="#8-内存分配与回收策略" class="headerlink" title="8. 内存分配与回收策略"></a>8. 内存分配与回收策略</h3>
      <ul>
<li><strong>对象优先在Eden分配</strong><blockquote>
<p>新生代 GC （Minor GC）：非常频繁，回收速度也比较块。<br>老年代 GC （Major GC / Full GC）：伴随至少一次的 Minor GC ， 比 Minor GC 慢10倍以上。</p>
</blockquote>
</li>
<li><strong>大对象直接进入老年代</strong></li>
<li><strong>长期存活的对象将进入老年代</strong>（可以通过 -XX:MaxTenuringThreshold 参数进行设置，默认执行完<strong>15</strong>次 Minor GC）</li>
<li><strong>动态对象年龄判断</strong>：如果在 Survivor 空间中相同年龄所有对象大小总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。</li>
<li><strong>空间分配担保</strong>：在进行 Minor GC 之前会执行下面的流程，<br>a: 检查<strong>老年代最大连续可用空间是否大于新生代所有对象总空间</strong>，如果是 Minor GC 可以确保安全，否则， 执行b；<br>b: 查看 HandlePromotionFailure 设置的值是否允许担保失败，如果是，执行c，否则，执行 Full GC；<br>c: 检查<strong>老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小</strong>，如果是，尝试一次 Minor GC （可能存在风险），否则，将 HandlePromotionFailure 设置为不允许冒险，改为进行一次 Full GC。</li>
</ul>

        <h2 id="第七章-虚拟机类加载机制"   >
          <a href="#第七章-虚拟机类加载机制" class="heading-link"><i class="fas fa-link"></i></a><a href="#第七章-虚拟机类加载机制" class="headerlink" title="第七章 虚拟机类加载机制"></a>第七章 虚拟机类加载机制</h2>
      
        <h3 id="1-类的加载过程"   >
          <a href="#1-类的加载过程" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-类的加载过程" class="headerlink" title="1. 类的加载过程"></a>1. 类的加载过程</h3>
      <p><img src="https://i.bmp.ovh/imgs/2019/05/ab251c96094d3f7d.png">  </p>
<ul>
<li>按顺序按部就班的开始（不是结束，一个阶段中调用激活另一个阶段），解析阶段可以在初始化之后再开始（动态绑定）</li>
<li>Java虚拟机规定的必须进行<strong>初始化</strong>的5种情况：<br>（1） 遇到 new、getstatic、putstatic、invokestatic这4条字节码指令（对应使用 <strong>new 关键字实例化对象</strong>、<strong>读取或设置类的静态字段</strong>（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）以及<strong>调用一个类的静态方法</strong>几种情况）<br>（2） 反射调用。<br>（3） 初始化一个类时，如果父类没有进行过初始化，需要先触发父类初始化。<br>（4） 虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的类），虚拟机会先初始化主类。<br>（5） 但是用动态语言支持时，如果一个java.lang.invoke.MethodHandle实例后解析结果 REF_putStatic , REF_getStatic , REF_invokeStatic 的方法句柄时，当改方法句柄对应的类没有初始化时，需要初始化该类。<blockquote>
<p>接口初始化时并不要求其父类接口全部都初始化完成，只有在真正使用到父类接口时才会初始化。</p>
</blockquote>
</li>
</ul>
<blockquote>

        <h5 id="有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。"   >
          <a href="#有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。" class="heading-link"><i class="fas fa-link"></i></a><a href="#有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。" class="headerlink" title="有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。"></a>有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。</h5>
      <p>被动引用举例：  </p>
<ul>
<li>通过子类引用父类的静态字段，不会导致子类的初始化。</li>
<li>通过数组定义来引用类，不会触发此类的初始化。</li>
<li>常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。</li>
</ul>
</blockquote>

        <h4 id="1-1-加载"   >
          <a href="#1-1-加载" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-加载" class="headerlink" title="1.1 加载"></a>1.1 加载</h4>
      <ol>
<li>通过一个类的全限定名来获取定义此类的二进制字节流<blockquote>
<p>获取途径：ZIP包（JAR、EAR、WAR）、网络（Applet）、运行时计算生成（动态代理）、其他文件（JSP应用）、数据库</p>
</blockquote>
</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构</li>
<li>在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口<blockquote>
<ul>
<li>非数组类型使用引导类加载器或者用户自定义类加载器进行加载</li>
<li>数组的组件类型（去掉一个维度之后的类型）是引用类型，则按照普通类加载过程加载；不是引用类型，标记为与引导类加载器关联。</li>
<li>数组类可见性与组件类型可见性一致。如果组件类型不是引用类型，可见性默认为 public 。</li>
</ul>
</blockquote>
</li>
</ol>

        <h4 id="1-2-验证（非常重要但不一定必要）"   >
          <a href="#1-2-验证（非常重要但不一定必要）" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-验证（非常重要但不一定必要）" class="headerlink" title="1.2 验证（非常重要但不一定必要）"></a>1.2 验证（非常重要但不一定必要）</h4>
      <ol>
<li>文件格式验证：保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个Java类型信息的要求。<blockquote>
<p>经过此验证之后字节流才会进入内存方法区，后面3个验证阶段都是基于方法区中的存储结构</p>
</blockquote>
</li>
<li>元数据验证（语义分析）：保证不存在不符合语言规范的元数据信息。</li>
<li>字节码验证（并不能完全保证安全）：对类的方法体进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。</li>
<li>符号引用验证：发生在虚拟机将符号引用转化为直接引用阶段，确保解析动作可以正常执行。</li>
</ol>

        <h4 id="1-3-准备"   >
          <a href="#1-3-准备" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-3-准备" class="headerlink" title="1.3 准备"></a>1.3 准备</h4>
      <p>为类变量（被 static 修饰的变量，不包括实例变量）分配内存并设置类变量初始值（一般是零值）。</p>
<blockquote>
<p>通常情况下初始化零值，如果存在 ConstantValue 属性，则指定为 ConstantValue 属性的值。<br><code>public static int value = 123;</code>此代码 value 准备阶段之后的结果为0；<br><code>public static final int value = 123;</code>此代码 value 准备阶段之后的结果为123。</p>
</blockquote>

        <h4 id="1-4-解析"   >
          <a href="#1-4-解析" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-4-解析" class="headerlink" title="1.4 解析"></a>1.4 解析</h4>
      <p>将常量池中的符号引用替换为直接引用。</p>
<blockquote>
<p>除invokeddynamic指令，其余需要进行解析的字节码指令都会对第一次解析结果进行缓存。<br>解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符七类符号引用进行。</p>
</blockquote>

        <h4 id="1-5-初始化"   >
          <a href="#1-5-初始化" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-5-初始化" class="headerlink" title="1.5 初始化"></a>1.5 初始化</h4>
      <p>执行类构造器<code>&lt;clinit&gt;()</code>方法。</p>
<ul>
<li>静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但不能访问。</li>
<li><code>&lt;clinit&gt;()</code>不需要显示调用父类的<code>&lt;clinit&gt;()</code>，由虚拟机保证父类<code>&lt;clinit&gt;()</code>执行。<br>第一个被执行的<code>&lt;clinit&gt;()</code>方法的类肯定是<code>java.lang.Object</code>。</li>
<li>父类中定义的静态语句块优于子类变量的复制操作。</li>
<li><code>&lt;clinit&gt;()</code>是非必需的（没有静态语句块和变量赋值操作）</li>
<li>接口不能使用静态语句块，但是可以对变量赋值。<br>只有父接口中定义的变量使用时，父接口才会初始化。</li>
<li>虚拟机保证一个类的<code>&lt;clinit&gt;()</code>方法在多线程环境下被正确的加锁、同步。</li>
</ul>

        <h3 id="2-类加载器"   >
          <a href="#2-类加载器" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-类加载器" class="headerlink" title="2. 类加载器"></a>2. 类加载器</h3>
      
        <h4 id="2-1-判断两个类相等"   >
          <a href="#2-1-判断两个类相等" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-判断两个类相等" class="headerlink" title="2.1 判断两个类相等"></a>2.1 判断两个类相等</h4>
      <ol>
<li>使用相同类加载器</li>
<li>全限定名相同</li>
</ol>

        <h4 id="2-2-双亲委派模型"   >
          <a href="#2-2-双亲委派模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-双亲委派模型" class="headerlink" title="2.2 双亲委派模型"></a>2.2 双亲委派模型</h4>
      <p><img src="https://images2018.cnblogs.com/blog/1256203/201807/1256203-20180714171531925-1737231049.png" alt="image"></p>

        <h5 id="双亲委派模型工作过程："   >
          <a href="#双亲委派模型工作过程：" class="heading-link"><i class="fas fa-link"></i></a><a href="#双亲委派模型工作过程：" class="headerlink" title="双亲委派模型工作过程："></a>双亲委派模型工作过程：</h5>
      <p>如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个类加载器都是如此，只有当父加载器在自己的搜索范围内找不到指定的类时（即ClassNotFoundException），子加载器才会尝试自己去加载。</p>
<blockquote>
<p>类加载器之间的父子关系不会以继承实现，而是使用组合的方式。</p>
</blockquote>

        <h5 id="双亲委派模型的三次破坏"   >
          <a href="#双亲委派模型的三次破坏" class="heading-link"><i class="fas fa-link"></i></a><a href="#双亲委派模型的三次破坏" class="headerlink" title="双亲委派模型的三次破坏"></a>双亲委派模型的三次破坏</h5>
      <ul>
<li>第一次破坏是<strong>在jdk 1.2之前，用户自定义的类加载器都是重写Classloader中的loadClass方法</strong>,这样就导致每个自定义的类加载器其实是在使用自己的loadClass方法中的加载机制来进行加载,这种模式当然是不符合双亲委派机制的，也是无法保证同一个类在jvm中的唯一性的。为了向前兼容，java官方<strong>在Classloader中添加了findClass方法</strong>,用户只需要重新这个findClass方法，在loadClass方法的逻辑里，如果父类加载失败的时候，才会调用自己的findClass方法来完成类加载，这样就保证了写出的类加载器是符合双亲委派机制的。</li>
<li>第二次的破坏是由模型本身的缺陷导致的，<strong>根类加载器加载了基础代码，但是基础代码中有可能调用了用户的代码</strong>，但是对于根类加载器而言是不认识用户的代码的。<blockquote>
<p>那么这时候java团队使用了一个不太优雅的设计：线程上下文类加载器。这个类加载器可以通过Thread类的setContextClassLoader方法进行设置,如果创建线程时还未设置，它就从父线程继承一个，如果在应用全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。  </p>
</blockquote>
</li>
</ul>
<blockquote>
<p>利用这个线程上下文类加载器傅，父类加载器请求子类加载器去加载某些自己识别不了的类。</p>
</blockquote>
<blockquote>
<p>java中基本所有涉及spi的加载动作基本上都采用了这种方式，例如jndi，jdbc等。</p>
</blockquote>
<ul>
<li>第三次的破坏是因为<strong>用户对于程序的动态性追求，诸如：代码热替换，模块热部署</strong>。<br>目前业界Java模块化的标准是OSGI。而OSGI实现模块热部署的关键是他自己的类加载机制：每个程序模块(bundle)都有自己的类加载器，需要更换程序(bundle)的时候，连同类加载器一起替换，以实现代码的热部署。</li>
</ul>

        <h2 id="第八章-虚拟机字节码执行引擎"   >
          <a href="#第八章-虚拟机字节码执行引擎" class="heading-link"><i class="fas fa-link"></i></a><a href="#第八章-虚拟机字节码执行引擎" class="headerlink" title="第八章 虚拟机字节码执行引擎"></a>第八章 虚拟机字节码执行引擎</h2>
      
        <h3 id="1-运行时栈帧结构"   >
          <a href="#1-运行时栈帧结构" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-运行时栈帧结构" class="headerlink" title="1. 运行时栈帧结构"></a>1. 运行时栈帧结构</h3>
      <ul>
<li>包含<strong>局部变量表、操作数栈、动态连接和方法返回地址</strong>等信息。</li>
<li>编译时确定栈帧中的局部变量表大小。</li>
<li>一个栈帧需要分配多少内存不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。</li>
<li>只有位于栈顶的栈帧（当前栈帧）才是有效的。</li>
</ul>

        <h4 id="1-1-局部变量表"   >
          <a href="#1-1-局部变量表" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-局部变量表" class="headerlink" title="1.1 局部变量表"></a>1.1 局部变量表</h4>
      <ul>
<li>以容量槽（Slot）为最小单位</li>
<li>每个Slot都应该能够存放一个boolean、byte、char、short、int、float、reference或returnAddress类型数据。</li>
<li>如果一个局部变量定义了但是没有赋初始值是不能使用的</li>
</ul>

        <h4 id="1-2-操作数栈"   >
          <a href="#1-2-操作数栈" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-操作数栈" class="headerlink" title="1.2 操作数栈"></a>1.2 操作数栈</h4>
      <ul>
<li>Java 虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈</li>
</ul>

        <h4 id="1-3-动态连接"   >
          <a href="#1-3-动态连接" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-3-动态连接" class="headerlink" title="1.3 动态连接"></a>1.3 动态连接</h4>
      <p>指向运行时常量池中该栈帧所属方法的引用。<br><strong>静态解析</strong>：符号引用在类加载阶段或第一次使用时转化为直接引用。<br><strong>动态连接</strong>：符号引用在每一次运行期间转化为直接引用。</p>

        <h4 id="1-4-方法返回地址"   >
          <a href="#1-4-方法返回地址" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-4-方法返回地址" class="headerlink" title="1.4 方法返回地址"></a>1.4 方法返回地址</h4>
      <p>方法正常退出时，调用者的<strong>PC计数器</strong>的值可以作为返回地址，栈帧中很可能会保存这个计数器的值。<br>方法异常退出时，返回地址通过<strong>异常处理器</strong>表来确定，栈帧中一般不会保存这部分信息。<br><strong>方法退出过程：</strong></p>
<ol>
<li>恢复上层方法的局部变量表和操作数栈</li>
<li>把返回值压入调用者栈帧的操作数栈</li>
<li>调整PC计数器的值以指向方法调用指令后面的一条指令</li>
</ol>

        <h3 id="2-方法调用"   >
          <a href="#2-方法调用" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-方法调用" class="headerlink" title="2. 方法调用"></a>2. 方法调用</h3>
      
        <h4 id="2-1-解析"   >
          <a href="#2-1-解析" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-解析" class="headerlink" title="2.1 解析"></a>2.1 解析</h4>
      <ul>
<li>只要能被 invokestatic 和 invokespecial 指令调用的方法都可以在解析阶段确定唯一的调用版本。</li>
<li>符合上述条件的的有<strong>静态方法、私有方法、实例构造器、父类方法</strong> 4 种。都称为<strong>非虚方法</strong>。其余方法为<strong>虚方法</strong>。<blockquote>
<p>final 方法也是非虚方法。</p>
</blockquote>
</li>
</ul>

        <h4 id="2-2-分派（与多态特性有关）"   >
          <a href="#2-2-分派（与多态特性有关）" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-分派（与多态特性有关）" class="headerlink" title="2.2 分派（与多态特性有关）"></a>2.2 分派（与多态特性有关）</h4>
      <div class="table-container"><table>
<thead>
<tr>
<th>静态分派</th>
<th>动态分派</th>
</tr>
</thead>
<tbody><tr>
<td>编译阶段</td>
<td>运行阶段</td>
</tr>
<tr>
<td>重载</td>
<td>重写</td>
</tr>
<tr>
<td>多分派（关心静态类型与方法参数两个因素）</td>
<td>单分派（只关心方法接收者）</td>
</tr>
</tbody></table></div>

        <h5 id="（1）静态分派（重载）"   >
          <a href="#（1）静态分派（重载）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）静态分派（重载）" class="headerlink" title="（1）静态分派（重载）"></a>（1）静态分派（重载）</h5>
      <p>所有通过静态类型来定位方法执行版本的分派动作称为静态分派。</p>
<blockquote>
<ul>
<li>方法重载是静态分派的典型应用  </li>
<li>静态分派发生在编译阶段</li>
</ul>
</blockquote>
<p><code>Human man = new Man();</code><br><code>Human</code>为变量的<strong>静态类型</strong>，静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且最终的静态类型是在编译期可知的；<br><code>Man</code>为变量的<strong>实际类型</strong>，实际类型的变化结果在运行期才可以确定，编译期间不知道对象的实际类型。<br><strong>重载</strong>通过参数的<strong>静态类型而不是实际类型</strong>作为判定依据。</p>

        <h5 id="（2）动态分派（重写）"   >
          <a href="#（2）动态分派（重写）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）动态分派（重写）" class="headerlink" title="（2）动态分派（重写）"></a>（2）动态分派（重写）</h5>
      <p>运行期根据实际类型确定方法执行版本的分派过程称为动态分派。</p>
<blockquote>
<p>根据操作数栈中的信息确定接受者的实际类型</p>
</blockquote>

        <h5 id="（3）单分派与多分派"   >
          <a href="#（3）单分派与多分派" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）单分派与多分派" class="headerlink" title="（3）单分派与多分派"></a>（3）单分派与多分派</h5>
      <p>方法的接收者与方法的参数统称为方法的<strong>宗量</strong>。<br><strong>单分派</strong>是根据一个宗量对目标方法进行选择，<strong>多分派</strong>则是根据多个宗量对目标方法进行选择。<br><strong>静态分派</strong>属于<strong>多分派</strong>，<strong>动态分派</strong>属于<strong>单分派</strong>。</p>

        <h5 id="（4）多分派的实现"   >
          <a href="#（4）多分派的实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#（4）多分派的实现" class="headerlink" title="（4）多分派的实现"></a>（4）多分派的实现</h5>
      <p>为类在方法区中建立<strong>虚方法表</strong>，存放各个方法的实际入口地址。<br>如果子类重写了父类函数，虚方法表中存放指向子类实现版本的入口地址；否则，与父类相同方法的入口地址一致。</p>

        <h2 id="第十二章-Java内存模型与线程"   >
          <a href="#第十二章-Java内存模型与线程" class="heading-link"><i class="fas fa-link"></i></a><a href="#第十二章-Java内存模型与线程" class="headerlink" title="第十二章 Java内存模型与线程"></a>第十二章 Java内存模型与线程</h2>
      
        <h3 id="1-Java内存模型"   >
          <a href="#1-Java内存模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-Java内存模型" class="headerlink" title="1. Java内存模型"></a>1. Java内存模型</h3>
      <div class="table-container"><table>
<thead>
<tr>
<th align="center">工作内存</th>
<th align="center">主内存</th>
</tr>
</thead>
<tbody><tr>
<td align="center">线程对变量读取、赋值等操作</td>
<td align="center">线程间变量值的传递</td>
</tr>
<tr>
<td align="center">虚拟机栈中的部分区域</td>
<td align="center">Java堆中的对象实例数据部分</td>
</tr>
</tbody></table></div>

        <h4 id="1-1-内存间的交互操作"   >
          <a href="#1-1-内存间的交互操作" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-内存间的交互操作" class="headerlink" title="1.1 内存间的交互操作"></a>1.1 内存间的交互操作</h4>
      <p><img src="https://img-blog.csdn.net/20180522220730109" alt="image"></p>
<ol>
<li>**lock(锁定)**：作用于主内存的变量，把一个变量标记为一条线程独占状态</li>
<li>**unlock(解锁)**：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定</li>
<li>**read(读取)**：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用</li>
<li>**load(载入)**：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中</li>
<li>**use(使用)**：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎</li>
<li>**assign(赋值)**：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量</li>
<li>**store(存储)**：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作</li>
<li>**write(写入)**：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中</li>
</ol>

        <h5 id="同步规则分析："   >
          <a href="#同步规则分析：" class="heading-link"><i class="fas fa-link"></i></a><a href="#同步规则分析：" class="headerlink" title="同步规则分析："></a>同步规则分析：</h5>
      <ol>
<li>不允许read和load、store和write操作之一单独出现，以上两个操作必须按顺序执行，但没有保证必须连续执行，也就是说，read与load之间、store与write之间是可插入其他指令的。</li>
<li>不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。</li>
<li>不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步会主内存中</li>
<li>一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或者assign）的变量。即就是对一个变量实施use和store操作之前，必须先自行assign和load操作。</li>
<li>一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现。</li>
<li>如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量之前需要重新执行load或assign操作初始化变量的值。</li>
<li>如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。</li>
<li>对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）</li>
</ol>

        <h4 id="2-3-volatile"   >
          <a href="#2-3-volatile" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-3-volatile" class="headerlink" title="2.3 volatile"></a>2.3 volatile</h4>
      
        <h5 id="1-保证可见性，read与load、aggsin与store两两不分开。"   >
          <a href="#1-保证可见性，read与load、aggsin与store两两不分开。" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-保证可见性，read与load、aggsin与store两两不分开。" class="headerlink" title="1. 保证可见性，read与load、aggsin与store两两不分开。"></a>1. 保证可见性，read与load、aggsin与store两两不分开。</h5>
      
        <h5 id="2-禁止指令重排序优化，内存屏障"   >
          <a href="#2-禁止指令重排序优化，内存屏障" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-禁止指令重排序优化，内存屏障" class="headerlink" title="2. 禁止指令重排序优化，内存屏障"></a>2. 禁止指令重排序优化，内存屏障</h5>
      
        <h4 id="2-4-long与double型变量的特殊规则"   >
          <a href="#2-4-long与double型变量的特殊规则" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-4-long与double型变量的特殊规则" class="headerlink" title="2.4 long与double型变量的特殊规则"></a>2.4 long与double型变量的特殊规则</h4>
      <p>虚拟机不保证64位数据类型的load、store、read和write这四个操作的原子性。</p>
<blockquote>
<p>目前的商用虚拟机保证了64位数据的类型读写操作的原子性</p>
</blockquote>

        <h4 id="2-5-原子性、可见性与有序性"   >
          <a href="#2-5-原子性、可见性与有序性" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-5-原子性、可见性与有序性" class="headerlink" title="2.5 原子性、可见性与有序性"></a>2.5 原子性、可见性与有序性</h4>
      
        <h5 id="（1）原子性"   >
          <a href="#（1）原子性" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）原子性" class="headerlink" title="（1）原子性"></a>（1）原子性</h5>
      <ul>
<li>基本数据类型具备原子性</li>
<li><code>sychronized</code> 关键字保证更大范围内的原子性</li>
</ul>

        <h5 id="（2）可见性"   >
          <a href="#（2）可见性" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）可见性" class="headerlink" title="（2）可见性"></a>（2）可见性</h5>
      <ul>
<li><code>volatile</code>、<code>sychronized</code>和<code>final</code>三个关键字实现可见性。</li>
<li><code>final</code>关键字的可见性：<br>被 final 修饰的字段在构造器中一旦初始化完成，并且构造器没有把<code>this</code>的引用传递出去，那在其他线程中就能看到 final 字段的值。</li>
</ul>

        <h5 id="（3）有序性"   >
          <a href="#（3）有序性" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）有序性" class="headerlink" title="（3）有序性"></a>（3）有序性</h5>
      <ul>
<li><code>volatile</code>和<code>sychronized</code>两个关键字实现有序性。</li>
<li>如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。</li>
</ul>

        <h4 id="2-6-先行发生原则（happens-before）"   >
          <a href="#2-6-先行发生原则（happens-before）" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-6-先行发生原则（happens-before）" class="headerlink" title="2.6 先行发生原则（happens-before）"></a>2.6 先行发生原则（happens-before）</h4>
      
        <h5 id="（1）定义"   >
          <a href="#（1）定义" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）定义" class="headerlink" title="（1）定义"></a>（1）定义</h5>
      <ol>
<li>如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</li>
<li>两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。</li>
</ol>

        <h5 id="（2）具体规则"   >
          <a href="#（2）具体规则" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）具体规则" class="headerlink" title="（2）具体规则"></a>（2）具体规则</h5>
      <ol>
<li><strong>程序顺序规则</strong>：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</li>
<li><strong>监视器锁规则</strong>：对一个锁的解锁，happens-before于随后对这个锁的加锁。</li>
<li><strong>volatile变量规则</strong>：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。</li>
<li><strong>传递性</strong>：如果A happens-before B，且B happens-before C，那么A happens-before C。</li>
<li><strong>start()规则</strong>：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。</li>
<li><strong>join()规则</strong>：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。</li>
<li><strong>程序中断规则</strong>：对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生。</li>
<li><strong>对象finalize规则</strong>：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始。</li>
</ol>

        <h3 id="Java与线程"   >
          <a href="#Java与线程" class="heading-link"><i class="fas fa-link"></i></a><a href="#Java与线程" class="headerlink" title="Java与线程"></a>Java与线程</h3>
      <blockquote>
<p>在Java中，JDK1.2之前由用户线程实现，JDK1.2之后使用基于操作系统原生线程模型实现，win和linux都是用的一对一的线程模型（一条Java线程映射到一条轻量级进程中）。</p>
</blockquote>

        <h4 id="1-线程的实现"   >
          <a href="#1-线程的实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-线程的实现" class="headerlink" title="1. 线程的实现"></a>1. 线程的实现</h4>
      
        <h5 id="1-1-使用内核线程实现"   >
          <a href="#1-1-使用内核线程实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-使用内核线程实现" class="headerlink" title="1.1 使用内核线程实现"></a>1.1 使用内核线程实现</h5>
      <ul>
<li>不直接使用内核线程，而是使用内核线程的高级接口：轻量级进程。</li>
<li>轻量级进程与内核线程的数量比为 1 ：1。</li>
<li>轻量级进程消耗内核资源，一个系统支持的轻量级进程的数量是有限的。</li>
</ul>

        <h5 id="1-2-使用用户线程实现（实现复杂，没有使用）"   >
          <a href="#1-2-使用用户线程实现（实现复杂，没有使用）" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-使用用户线程实现（实现复杂，没有使用）" class="headerlink" title="1.2 使用用户线程实现（实现复杂，没有使用）"></a>1.2 使用用户线程实现（实现复杂，没有使用）</h5>
      <ul>
<li>进程与用户线程之间是 1 ：N 的关系</li>
</ul>

        <h5 id="1-3-使用用户线程加轻量级进程混合实现"   >
          <a href="#1-3-使用用户线程加轻量级进程混合实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-3-使用用户线程加轻量级进程混合实现" class="headerlink" title="1.3 使用用户线程加轻量级进程混合实现"></a>1.3 使用用户线程加轻量级进程混合实现</h5>
      <ul>
<li>用户线程与轻量级进程之间是 N:M 的关系。</li>
</ul>

        <h4 id="2-线程调度"   >
          <a href="#2-线程调度" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-线程调度" class="headerlink" title="2. 线程调度"></a>2. 线程调度</h4>
      <ul>
<li>协同式线程调度：实现简单，但线程执行时间不可控</li>
<li>抢占式线程调度：Java一共10个优先级，但windows系统只有7个</li>
</ul>

        <h4 id="3-状态转换"   >
          <a href="#3-状态转换" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-状态转换" class="headerlink" title="3. 状态转换"></a>3. 状态转换</h4>
      <p><img src="https://pic2.zhimg.com/80/v2-326a2be9b86b1446d75b6f52f54c98fb_hd.jpg" alt="线程状态转移图"></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka源码学习：KafkaApis-LEADER_AND_ISR</title>
    <url>/2021/06/05/kafka%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9AKafkaApis-LEADER-AND-ISR/</url>
    <content><![CDATA[<blockquote>
<p>本文源码基于kafka 0.10.2版本</p>
</blockquote>
<p>​    每当controller发生状态变更时，都会通过调用<code>sendRequestsToBrokers</code>方法发送<code>leaderAndIsrRequest</code>请求，本文主要介绍kafka服务端处理该请求的逻辑和过程。</p>
<span id="more"></span>


        <h1 id="LEADER-AND-ISR"   >
          <a href="#LEADER-AND-ISR" class="heading-link"><i class="fas fa-link"></i></a><a href="#LEADER-AND-ISR" class="headerlink" title="LEADER_AND_ISR"></a>LEADER_AND_ISR</h1>
      
        <h2 id="整体逻辑流程"   >
          <a href="#整体逻辑流程" class="heading-link"><i class="fas fa-link"></i></a><a href="#整体逻辑流程" class="headerlink" title="整体逻辑流程"></a>整体逻辑流程</h2>
      <figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEADER_AND_ISR</span> =&gt; handleLeaderAndIsrRequest(request)</span><br></pre></td></tr></table></div></figure>

<p>在server端收到LEADER_AND_ISR请求后，会调用<code>handleLeaderAndIsrRequest</code>方法进行处理，该方法的处理流程如图所示：</p>
<p><img src="%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="流程图"></p>

        <h2 id="源码"   >
          <a href="#源码" class="heading-link"><i class="fas fa-link"></i></a><a href="#源码" class="headerlink" title="源码"></a>源码</h2>
      
        <h3 id="handleLeaderAndIsrRequest"   >
          <a href="#handleLeaderAndIsrRequest" class="heading-link"><i class="fas fa-link"></i></a><a href="#handleLeaderAndIsrRequest" class="headerlink" title="handleLeaderAndIsrRequest"></a>handleLeaderAndIsrRequest</h3>
      <p><code>handleLeaderAndIsrRequest</code>函数的逻辑结果主要分为以下几个部分：</p>
<ol>
<li>构造callback函数<code>onLeadershipChange</code>,用来回调coordinator处理新增的leader或者follower节点</li>
<li>校验请求权限，如果校验成功调用<code>replicaManager.becomeLeaderOrFollower(correlationId, leaderAndIsrRequest, metadataCache, onLeadershipChange)</code>进行后续处理【此处该函数的主流程】，否则，直接返回错误码<code>Errors.CLUSTER_AUTHORIZATION_FAILED.code</code></li>
</ol>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleLeaderAndIsrRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">    <span class="comment">// ensureTopicExists is only for client facing requests</span></span><br><span class="line">    <span class="comment">// We can&#x27;t have the ensureTopicExists check here since the controller sends it as an advisory to all brokers so they</span></span><br><span class="line">    <span class="comment">// stop serving data to clients for the topic being deleted</span></span><br><span class="line">    <span class="keyword">val</span> correlationId = request.header.correlationId</span><br><span class="line">    <span class="keyword">val</span> leaderAndIsrRequest = request.body.asInstanceOf[<span class="type">LeaderAndIsrRequest</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">onLeadershipChange</span></span>(updatedLeaders: <span class="type">Iterable</span>[<span class="type">Partition</span>], updatedFollowers: <span class="type">Iterable</span>[<span class="type">Partition</span>]) &#123;</span><br><span class="line">        <span class="comment">// for each new leader or follower, call coordinator to handle consumer group migration.</span></span><br><span class="line">        <span class="comment">// this callback is invoked under the replica state change lock to ensure proper order of</span></span><br><span class="line">        <span class="comment">// leadership changes</span></span><br><span class="line">        updatedLeaders.foreach &#123; partition =&gt;</span><br><span class="line">          <span class="keyword">if</span> (partition.topic == <span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>)</span><br><span class="line">            coordinator.handleGroupImmigration(partition.partitionId)</span><br><span class="line">        &#125;</span><br><span class="line">        updatedFollowers.foreach &#123; partition =&gt;</span><br><span class="line">          <span class="keyword">if</span> (partition.topic == <span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>)</span><br><span class="line">            coordinator.handleGroupEmigration(partition.partitionId)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> leaderAndIsrResponse =</span><br><span class="line">        <span class="keyword">if</span> (authorize(request.session, <span class="type">ClusterAction</span>, <span class="type">Resource</span>.<span class="type">ClusterResource</span>)) &#123;</span><br><span class="line">          <span class="keyword">val</span> result = replicaManager.becomeLeaderOrFollower(correlationId, leaderAndIsrRequest, metadataCache, onLeadershipChange)</span><br><span class="line">          <span class="keyword">new</span> <span class="type">LeaderAndIsrResponse</span>(result.errorCode, result.responseMap.mapValues(<span class="keyword">new</span> <span class="type">JShort</span>(_)).asJava)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">val</span> result = leaderAndIsrRequest.partitionStates.asScala.keys.map((_, <span class="keyword">new</span> <span class="type">JShort</span>(<span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.code))).toMap</span><br><span class="line">          <span class="keyword">new</span> <span class="type">LeaderAndIsrResponse</span>(<span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.code, result.asJava)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">Response</span>(request, leaderAndIsrResponse))</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">KafkaStorageException</span> =&gt;</span><br><span class="line">        fatal(<span class="string">&quot;Disk error during leadership change.&quot;</span>, e)</span><br><span class="line">        <span class="type">Runtime</span>.getRuntime.halt(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="becomeLeaderOrFollower"   >
          <a href="#becomeLeaderOrFollower" class="heading-link"><i class="fas fa-link"></i></a><a href="#becomeLeaderOrFollower" class="headerlink" title="becomeLeaderOrFollower"></a>becomeLeaderOrFollower</h3>
      <p><code>ReplicaManager</code>的主要工作有以下几个部分，具体代码位置见中文注释：</p>
<ol>
<li>校验controller epoch是否合规，只处理比自己epoch大且本地有副本的tp的请求</li>
<li>调用<code>makeLeaders</code>和<code>makeFollowers</code>方法构造新增的leader partition和follower partition【此处为主要逻辑，后面小结详细介绍】</li>
<li>如果是第一次收到请求，启动定时更新hw的线程</li>
<li>停掉空的Fetcher线程</li>
<li>调用回调函数，coordinator处理新增的leader partition和follower partition</li>
</ol>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">becomeLeaderOrFollower</span></span>(correlationId: <span class="type">Int</span>,leaderAndISRRequest: <span class="type">LeaderAndIsrRequest</span>,</span><br><span class="line">                           metadataCache: <span class="type">MetadataCache</span>,</span><br><span class="line">                           onLeadershipChange: (<span class="type">Iterable</span>[<span class="type">Partition</span>], <span class="type">Iterable</span>[<span class="type">Partition</span>]) =&gt; <span class="type">Unit</span>): <span class="type">BecomeLeaderOrFollowerResult</span> = &#123;</span><br><span class="line">    leaderAndISRRequest.partitionStates.asScala.foreach &#123; <span class="keyword">case</span> (topicPartition, stateInfo) =&gt;</span><br><span class="line">        stateChangeLogger.trace(<span class="string">&quot;Broker %d received LeaderAndIsr request %s correlation id %d from controller %d epoch %d for partition [%s,%d]&quot;</span></span><br><span class="line">                                .format(localBrokerId, stateInfo, correlationId,</span><br><span class="line">                                        leaderAndISRRequest.controllerId, leaderAndISRRequest.controllerEpoch, topicPartition.topic, topicPartition.partition))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//主要代码，构造返回结果</span></span><br><span class="line">    replicaStateChangeLock synchronized &#123;</span><br><span class="line">        <span class="keyword">val</span> responseMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>]</span><br><span class="line">        <span class="comment">//如果controller epoch不正确，直接返回Errors.STALE_CONTROLLER_EPOCH.code错误码</span></span><br><span class="line">        <span class="keyword">if</span> (leaderAndISRRequest.controllerEpoch &lt; controllerEpoch) &#123;</span><br><span class="line">            stateChangeLogger.warn((<span class="string">&quot;Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d since &quot;</span> +</span><br><span class="line">                                    <span class="string">&quot;its controller epoch %d is old. Latest known controller epoch is %d&quot;</span>).format(localBrokerId, leaderAndISRRequest.controllerId,</span><br><span class="line">                                                                                                                  correlationId, leaderAndISRRequest.controllerEpoch, controllerEpoch))</span><br><span class="line">            <span class="type">BecomeLeaderOrFollowerResult</span>(responseMap, <span class="type">Errors</span>.<span class="type">STALE_CONTROLLER_EPOCH</span>.code)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">val</span> controllerId = leaderAndISRRequest.controllerId</span><br><span class="line">            controllerEpoch = leaderAndISRRequest.controllerEpoch</span><br><span class="line"></span><br><span class="line">            <span class="comment">// First check partition&#x27;s leader epoch</span></span><br><span class="line">            <span class="comment">//校验所有的partition信息，分为以下3种情况：</span></span><br><span class="line">            <span class="comment">//1. 本地不包含该partition，返回Errors.UNKNOWN_TOPIC_OR_PARTITION.code</span></span><br><span class="line">            <span class="comment">//2. 本地包含该partition，controller epoch比本地epoch大，信息正确</span></span><br><span class="line">            <span class="comment">//3. controller epoch比本地epoch小，返回Errors.STALE_CONTROLLER_EPOCH.code</span></span><br><span class="line">            <span class="keyword">val</span> partitionState = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>]()</span><br><span class="line">            leaderAndISRRequest.partitionStates.asScala.foreach &#123; <span class="keyword">case</span> (topicPartition, stateInfo) =&gt;</span><br><span class="line">                <span class="keyword">val</span> partition = getOrCreatePartition(topicPartition)</span><br><span class="line">                <span class="keyword">val</span> partitionLeaderEpoch = partition.getLeaderEpoch</span><br><span class="line">                <span class="comment">// If the leader epoch is valid record the epoch of the controller that made the leadership decision.</span></span><br><span class="line">                <span class="comment">// This is useful while updating the isr to maintain the decision maker controller&#x27;s epoch in the zookeeper path</span></span><br><span class="line">                <span class="keyword">if</span> (partitionLeaderEpoch &lt; stateInfo.leaderEpoch) &#123;</span><br><span class="line">                    <span class="keyword">if</span>(stateInfo.replicas.contains(localBrokerId))</span><br><span class="line">                    partitionState.put(partition, stateInfo)</span><br><span class="line">                    <span class="keyword">else</span> &#123;</span><br><span class="line">                        stateChangeLogger.warn((<span class="string">&quot;Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d &quot;</span> +</span><br><span class="line">                                                <span class="string">&quot;epoch %d for partition [%s,%d] as itself is not in assigned replica list %s&quot;</span>)</span><br><span class="line">                                               .format(localBrokerId, controllerId, correlationId, leaderAndISRRequest.controllerEpoch,</span><br><span class="line">                                                       topicPartition.topic, topicPartition.partition, stateInfo.replicas.asScala.mkString(<span class="string">&quot;,&quot;</span>)))</span><br><span class="line">                        responseMap.put(topicPartition, <span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span>.code)</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// Otherwise record the error code in response</span></span><br><span class="line">                    stateChangeLogger.warn((<span class="string">&quot;Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d &quot;</span> +</span><br><span class="line">                                            <span class="string">&quot;epoch %d for partition [%s,%d] since its associated leader epoch %d is not higher than the current leader epoch %d&quot;</span>)</span><br><span class="line">                                           .format(localBrokerId, controllerId, correlationId, leaderAndISRRequest.controllerEpoch,</span><br><span class="line">                                                   topicPartition.topic, topicPartition.partition, stateInfo.leaderEpoch, partitionLeaderEpoch))</span><br><span class="line">                    responseMap.put(topicPartition, <span class="type">Errors</span>.<span class="type">STALE_CONTROLLER_EPOCH</span>.code)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//处理leader&amp;follower副本，构造partitionsBecomeLeader和partitionsBecomeFollower供callback处理（coordinator处理）</span></span><br><span class="line">            <span class="keyword">val</span> partitionsTobeLeader = partitionState.filter &#123; <span class="keyword">case</span> (_, stateInfo) =&gt;</span><br><span class="line">                stateInfo.leader == localBrokerId</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">val</span> partitionsToBeFollower = partitionState -- partitionsTobeLeader.keys</span><br><span class="line"></span><br><span class="line">            <span class="keyword">val</span> partitionsBecomeLeader = <span class="keyword">if</span> (partitionsTobeLeader.nonEmpty)</span><br><span class="line">            <span class="comment">// 主要调用</span></span><br><span class="line">            makeLeaders(controllerId, controllerEpoch, partitionsTobeLeader, correlationId, responseMap)</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            <span class="type">Set</span>.empty[<span class="type">Partition</span>]</span><br><span class="line">            <span class="keyword">val</span> partitionsBecomeFollower = <span class="keyword">if</span> (partitionsToBeFollower.nonEmpty)</span><br><span class="line">            <span class="comment">// 主要调用</span></span><br><span class="line">            makeFollowers(controllerId, controllerEpoch, partitionsToBeFollower, correlationId, responseMap, metadataCache)</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            <span class="type">Set</span>.empty[<span class="type">Partition</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment">// we initialize highwatermark thread after the first leaderisrrequest. This ensures that all the partitions</span></span><br><span class="line">            <span class="comment">// have been completely populated before starting the checkpointing there by avoiding weird race conditions</span></span><br><span class="line">            <span class="comment">// 在第一次收到收到请求后，就会启动Scheduler，定时更新hw checkpoint</span></span><br><span class="line">            <span class="keyword">if</span> (!hwThreadInitialized) &#123;</span><br><span class="line">                startHighWaterMarksCheckPointThread()</span><br><span class="line">                hwThreadInitialized = <span class="literal">true</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 因为上面更新了元信息，此处检查停掉不必要的Fetcher线程</span></span><br><span class="line">            replicaFetcherManager.shutdownIdleFetcherThreads()</span><br><span class="line">            <span class="comment">// 回调</span></span><br><span class="line">            onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)</span><br><span class="line">            <span class="type">BecomeLeaderOrFollowerResult</span>(responseMap, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="makeLeaders"   >
          <a href="#makeLeaders" class="heading-link"><i class="fas fa-link"></i></a><a href="#makeLeaders" class="headerlink" title="makeLeaders"></a>makeLeaders</h3>
      <p>处理新增的leader partition</p>
<ol>
<li>停止这些partition的follower线程</li>
<li>更新这些partition的metadata cache</li>
<li>构造新增leader集合</li>
</ol>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeLeaders</span></span>(controllerId: <span class="type">Int</span>,</span><br><span class="line">                          epoch: <span class="type">Int</span>,</span><br><span class="line">                          partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</span><br><span class="line">                          correlationId: <span class="type">Int</span>,</span><br><span class="line">                          responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>]): <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</span><br><span class="line">    <span class="comment">// 构造becomeLeaderOrFollower需要的返回结果</span></span><br><span class="line">    <span class="keyword">for</span> (partition &lt;- partitionState.keys)</span><br><span class="line">      responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> partitionsToMakeLeaders: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// First stop fetchers for all the partitions</span></span><br><span class="line">      <span class="comment">// 停止Fetcher线程 </span></span><br><span class="line">        replicaFetcherManager.removeFetcherForPartitions(partitionState.keySet.map(_.topicPartition))</span><br><span class="line">      <span class="comment">// Update the partition information to be the leader</span></span><br><span class="line">      <span class="comment">// 构造新增leader partition集合</span></span><br><span class="line">      partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (partition.makeLeader(controllerId, partitionStateInfo, correlationId))</span><br><span class="line">          partitionsToMakeLeaders += partition</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">          stateChangeLogger.info((<span class="string">&quot;Broker %d skipped the become-leader state change after marking its partition as leader with correlation id %d from &quot;</span> +</span><br><span class="line">            <span class="string">&quot;controller %d epoch %d for partition %s since it is already the leader for the partition.&quot;</span>)</span><br><span class="line">            .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</span><br><span class="line">      &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        partitionState.keys.foreach &#123; partition =&gt;</span><br><span class="line">          <span class="keyword">val</span> errorMsg = (<span class="string">&quot;Error on broker %d while processing LeaderAndIsr request correlationId %d received from controller %d&quot;</span> +</span><br><span class="line">            <span class="string">&quot; epoch %d for partition %s&quot;</span>).format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition)</span><br><span class="line">          stateChangeLogger.error(errorMsg, e)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></span><br><span class="line">        <span class="keyword">throw</span> e</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    partitionsToMakeLeaders</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure>

<p><code>partition.makeLeader(controllerId, partitionStateInfo, correlationId)</code>会进行元信息的处理，并更新hw，此方法会调用<code>maybeIncrementLeaderHW</code>函数，该函数会尝试追赶hw：<strong>如果其他副本落后leader不太远，并且比之前的hw大，会延缓hw增长速度，尽可能让其他副本进队。</strong></p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeLeader</span></span>(controllerId: <span class="type">Int</span>, partitionStateInfo: <span class="type">PartitionState</span>, correlationId: <span class="type">Int</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> (leaderHWIncremented, isNewLeader) = inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">      <span class="keyword">val</span> allReplicas = partitionStateInfo.replicas.asScala.map(_.toInt)</span><br><span class="line">      <span class="comment">// record the epoch of the controller that made the leadership decision. This is useful while updating the isr</span></span><br><span class="line">      <span class="comment">// to maintain the decision maker controller&#x27;s epoch in the zookeeper path</span></span><br><span class="line">      controllerEpoch = partitionStateInfo.controllerEpoch</span><br><span class="line">      <span class="comment">// add replicas that are new</span></span><br><span class="line">      <span class="comment">// 构造新ISR</span></span><br><span class="line">      allReplicas.foreach(replica =&gt; getOrCreateReplica(replica))</span><br><span class="line">      <span class="keyword">val</span> newInSyncReplicas = partitionStateInfo.isr.asScala.map(r =&gt; getOrCreateReplica(r)).toSet</span><br><span class="line">      <span class="comment">// remove assigned replicas that have been removed by the controller</span></span><br><span class="line">      <span class="comment">// 移除所有不在新ISR中的副本</span></span><br><span class="line">      (assignedReplicas.map(_.brokerId) -- allReplicas).foreach(removeReplica)</span><br><span class="line">      inSyncReplicas = newInSyncReplicas</span><br><span class="line">      leaderEpoch = partitionStateInfo.leaderEpoch</span><br><span class="line">      zkVersion = partitionStateInfo.zkVersion</span><br><span class="line">      <span class="comment">//是否第一次成为该partition的leader</span></span><br><span class="line">      <span class="keyword">val</span> isNewLeader =</span><br><span class="line">        <span class="keyword">if</span> (leaderReplicaIdOpt.isDefined &amp;&amp; leaderReplicaIdOpt.get == localBrokerId) &#123;</span><br><span class="line">          <span class="literal">false</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          leaderReplicaIdOpt = <span class="type">Some</span>(localBrokerId)</span><br><span class="line">          <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      <span class="keyword">val</span> leaderReplica = getReplica().get</span><br><span class="line">      <span class="keyword">val</span> curLeaderLogEndOffset = leaderReplica.logEndOffset.messageOffset</span><br><span class="line">      <span class="keyword">val</span> curTimeMs = time.milliseconds</span><br><span class="line">      <span class="comment">// initialize lastCaughtUpTime of replicas as well as their lastFetchTimeMs and lastFetchLeaderLogEndOffset.</span></span><br><span class="line">      <span class="comment">//新leader初始化</span></span><br><span class="line">      (assignedReplicas - leaderReplica).foreach &#123; replica =&gt;</span><br><span class="line">        <span class="keyword">val</span> lastCaughtUpTimeMs = <span class="keyword">if</span> (inSyncReplicas.contains(replica)) curTimeMs <span class="keyword">else</span> <span class="number">0</span>L</span><br><span class="line">        replica.resetLastCaughtUpTime(curLeaderLogEndOffset, curTimeMs, lastCaughtUpTimeMs)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// we may need to increment high watermark since ISR could be down to 1</span></span><br><span class="line">      <span class="keyword">if</span> (isNewLeader) &#123;</span><br><span class="line">        <span class="comment">// construct the high watermark metadata for the new leader replica</span></span><br><span class="line">        leaderReplica.convertHWToLocalOffsetMetadata()</span><br><span class="line">        <span class="comment">// reset log end offset for remote replicas</span></span><br><span class="line">        assignedReplicas.filter(_.brokerId != localBrokerId).foreach(_.updateLogReadResult(<span class="type">LogReadResult</span>.<span class="type">UnknownLogReadResult</span>))</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//  尝试追赶hw,如果其他副本落后leader不太远，并且比之前的hw大，会延缓hw增长速度，尽可能让其他副本进队</span></span><br><span class="line">      (maybeIncrementLeaderHW(leaderReplica), isNewLeader)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// some delayed operations may be unblocked after HW changed</span></span><br><span class="line">    <span class="comment">//  hw更新后会处理一些request</span></span><br><span class="line">    <span class="keyword">if</span> (leaderHWIncremented)</span><br><span class="line">      tryCompleteDelayedRequests()</span><br><span class="line">    isNewLeader</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="makeFollowers"   >
          <a href="#makeFollowers" class="heading-link"><i class="fas fa-link"></i></a><a href="#makeFollowers" class="headerlink" title="makeFollowers"></a>makeFollowers</h3>
      <p>处理新增的follower partition</p>
<ol>
<li>从leaderpartition集合中移除这些partition</li>
<li>标记为follower，阻止producer请求</li>
<li>移除Fetcher线程</li>
<li>根据hw truncate这些partition的本地日志</li>
<li>清理producer和fetch请求</li>
<li>如果没有宕机，从新的leader fetch数据</li>
</ol>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeFollowers</span></span>(controllerId: <span class="type">Int</span>,</span><br><span class="line">                          epoch: <span class="type">Int</span>,</span><br><span class="line">                          partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</span><br><span class="line">                          correlationId: <span class="type">Int</span>,</span><br><span class="line">                          responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>],</span><br><span class="line">                          metadataCache: <span class="type">MetadataCache</span>) : <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</span><br><span class="line">    partitionState.keys.foreach &#123; partition =&gt;</span><br><span class="line">        stateChangeLogger.trace((<span class="string">&quot;Broker %d handling LeaderAndIsr request correlationId %d from controller %d epoch %d &quot;</span> +</span><br><span class="line">                                 <span class="string">&quot;starting the become-follower transition for partition %s&quot;</span>)</span><br><span class="line">                                .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 构造becomeLeaderOrFollower需要的返回结果</span></span><br><span class="line">    <span class="keyword">for</span> (partition &lt;- partitionState.keys)</span><br><span class="line">    responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> partitionsToMakeFollower: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// <span class="doctag">TODO:</span> Delete leaders from LeaderAndIsrRequest</span></span><br><span class="line">        partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</span><br><span class="line">            <span class="keyword">val</span> newLeaderBrokerId = partitionStateInfo.leader</span><br><span class="line">            metadataCache.getAliveBrokers.find(_.id == newLeaderBrokerId) <span class="keyword">match</span> &#123;</span><br><span class="line">                <span class="comment">// Only change partition state when the leader is available</span></span><br><span class="line">                <span class="keyword">case</span> <span class="type">Some</span>(_) =&gt;</span><br><span class="line">                <span class="comment">// 构造返回结果</span></span><br><span class="line">                <span class="keyword">if</span> (partition.makeFollower(controllerId, partitionStateInfo, correlationId))</span><br><span class="line">                partitionsToMakeFollower += partition</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                stateChangeLogger.info((<span class="string">&quot;Broker %d skipped the become-follower state change after marking its partition as follower with correlation id %d from &quot;</span> +</span><br><span class="line">                                        <span class="string">&quot;controller %d epoch %d for partition %s since the new leader %d is the same as the old leader&quot;</span>)</span><br><span class="line">                                       .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</span><br><span class="line">                                               partition.topicPartition, newLeaderBrokerId))</span><br><span class="line">                <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">                <span class="comment">// The leader broker should always be present in the metadata cache.</span></span><br><span class="line">                <span class="comment">// If not, we should record the error message and abort the transition process for this partition</span></span><br><span class="line">                stateChangeLogger.error((<span class="string">&quot;Broker %d received LeaderAndIsrRequest with correlation id %d from controller&quot;</span> +</span><br><span class="line">                                         <span class="string">&quot; %d epoch %d for partition %s but cannot become follower since the new leader %d is unavailable.&quot;</span>)</span><br><span class="line">                                        .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</span><br><span class="line">                                                partition.topicPartition, newLeaderBrokerId))</span><br><span class="line">                <span class="comment">// Create the local replica even if the leader is unavailable. This is required to ensure that we include</span></span><br><span class="line">                <span class="comment">// the partition&#x27;s high watermark in the checkpoint file (see KAFKA-1647)</span></span><br><span class="line">                partition.getOrCreateReplica()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">//移除Fetcher线程</span></span><br><span class="line">        replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))</span><br><span class="line">        <span class="comment">//根据新hw进行truncate</span></span><br><span class="line">        logManager.truncateTo(partitionsToMakeFollower.map &#123; partition =&gt;</span><br><span class="line">            (partition.topicPartition, partition.getOrCreateReplica().highWatermark.messageOffset)</span><br><span class="line">        &#125;.toMap)</span><br><span class="line">        <span class="comment">//hw更新，尝试处理请求</span></span><br><span class="line">        partitionsToMakeFollower.foreach &#123; partition =&gt;</span><br><span class="line">            <span class="keyword">val</span> topicPartitionOperationKey = <span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(partition.topicPartition)</span><br><span class="line">            tryCompleteDelayedProduce(topicPartitionOperationKey)</span><br><span class="line">            tryCompleteDelayedFetch(topicPartitionOperationKey)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (isShuttingDown.get()) &#123;</span><br><span class="line">            partitionsToMakeFollower.foreach &#123; partition =&gt;</span><br><span class="line">                stateChangeLogger.trace((<span class="string">&quot;Broker %d skipped the adding-fetcher step of the become-follower state change with correlation id %d from &quot;</span> +</span><br><span class="line">                                         <span class="string">&quot;controller %d epoch %d for partition %s since it is shutting down&quot;</span>).format(localBrokerId, correlationId,</span><br><span class="line">                                                                                                                     controllerId, epoch, partition.topicPartition))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// we do not need to check if the leader exists again since this has been done at the beginning of this process</span></span><br><span class="line">            <span class="comment">// 重置fetch位置，加入Fetcher</span></span><br><span class="line">            <span class="keyword">val</span> partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map(partition =&gt;</span><br><span class="line">                                                                                           partition.topicPartition -&gt; <span class="type">BrokerAndInitialOffset</span>(</span><br><span class="line">                                                                                               metadataCache.getAliveBrokers.find(_.id == partition.leaderReplicaIdOpt.get).get.getBrokerEndPoint(config.interBrokerListenerName),</span><br><span class="line">                                                                                               partition.getReplica().get.logEndOffset.messageOffset)).toMap</span><br><span class="line">            replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        <span class="keyword">val</span> errorMsg = (<span class="string">&quot;Error on broker %d while processing LeaderAndIsr request with correlationId %d received from controller %d &quot;</span> +</span><br><span class="line">                        <span class="string">&quot;epoch %d&quot;</span>).format(localBrokerId, correlationId, controllerId, epoch)</span><br><span class="line">        stateChangeLogger.error(errorMsg, e)</span><br><span class="line">        <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></span><br><span class="line">        <span class="keyword">throw</span> e</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    partitionsToMakeFollower</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>二零二一年七月书单</title>
    <url>/2021/08/15/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E4%B8%83%E6%9C%88%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<p>​    这是我的第一次书单总结，希望以后每个月都能有一次书单总结将自己读过的书记录下来。</p>
<span id="more"></span>

<blockquote>
<p>📚以下书籍出现的顺序代表我对这些书的评分排序。</p>
</blockquote>

        <h3 id="《朝闻道》"   >
          <a href="#《朝闻道》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《朝闻道》" class="headerlink" title="《朝闻道》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/27191786/" >《朝闻道》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      
        <h4 id="相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长"   >
          <a href="#相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长" class="heading-link"><i class="fas fa-link"></i></a><a href="#相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长" class="headerlink" title="相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长"></a>相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长</h4>
      <p>​    宇宙排险者的职责是负责排除宇宙中存在的知识的巨大发展，因为当人们获取到更多的宇宙奥秘时，对宇宙也更加危险。人类第一次触发排险者报警是因为原始人类第一次<strong>仰望星空</strong>，因为，<strong>“当生命意识到宇宙奥秘的存在时，距它最终解开这个奥秘只有一步之遥。”</strong></p>

        <h4 id="“朝闻道夕死可矣”"   >
          <a href="#“朝闻道夕死可矣”" class="heading-link"><i class="fas fa-link"></i></a><a href="#“朝闻道夕死可矣”" class="headerlink" title="“朝闻道夕死可矣”"></a>“朝闻道夕死可矣”</h4>
      <p>​    这是一句论语中的话，老刘从科幻的角度进行了解释。宇宙排险者的工作是阻止人们获取宇宙的奥秘，防止宇宙被破坏。宇宙排险者知道宇宙的奥秘，却不能告诉人类。丁仪想到了可以既能得到宇宙的终极奥秘，又不违反宇宙排险者的职责的方法：“把宇宙的终极奥秘告诉我，然后再毁灭我。”之后便有大量的顶级学者前赴后继地选择得到宇宙的奥秘然后死去。</p>
<p>​        在我看来，普通人不会参与、选择“朝闻道夕死”，是因为越是有知识的人，才会知道自己不知道什么，人们的学习过程，不是一个从“不知道”到“知道”的过程，而是一个“不知道自己不知道”到“知道自己不知道”的过程，普通人“知道自己不知道”的东西，还远到不了需要宇宙排险者来解答的程度。</p>
<p>​    但是，如果成为了顶级学者，是否又真的能选择“朝闻道夕死可矣”？</p>

        <h3 id="《你当像鸟飞往你的山》"   >
          <a href="#《你当像鸟飞往你的山》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《你当像鸟飞往你的山》" class="headerlink" title="《你当像鸟飞往你的山》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/33440205//" >《你当像鸟飞往你的山》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书讲述了一个女孩关于原生家庭的自述，在她的家里有暴力狂的哥哥、不让孩子受教育的父亲、只会听从父亲话的母亲，十七岁前从未上过学，现在却成为了剑桥大学的博士。虽然主要是作者自身经历的描写，但是作者心路历程的变化清晰可见。从作者心路历程的变化中也可以看到许多关于原生家庭的道理，这些道理在原生家庭与现实世界的冲突没有那么严重时是不容易触及的。</p>

        <h4 id="原生家庭的影响很难改变"   >
          <a href="#原生家庭的影响很难改变" class="heading-link"><i class="fas fa-link"></i></a><a href="#原生家庭的影响很难改变" class="headerlink" title="原生家庭的影响很难改变"></a>原生家庭的影响很难改变</h4>
      <p>​    作者的成长过程中，即便读书使她见到了更加广阔的世界，认识到父亲那些顽固的观点（读书不好，政府不好，医院里的医生都是恶魔等）不是正确的，但是依旧会对当下的生活持有怀疑，怀疑现在的世界是否真的如父亲所讲。</p>

        <h4 id="一个人从不好的原生家庭中走出后总是会想着帮助家人改变"   >
          <a href="#一个人从不好的原生家庭中走出后总是会想着帮助家人改变" class="heading-link"><i class="fas fa-link"></i></a><a href="#一个人从不好的原生家庭中走出后总是会想着帮助家人改变" class="headerlink" title="一个人从不好的原生家庭中走出后总是会想着帮助家人改变"></a>一个人从不好的原生家庭中走出后总是会想着帮助家人改变</h4>
      <p>​    当作者离开原生家庭，外出读书，知道了生病就应该去医院，知道到了指定年龄就应该去读书。虽然对原生家庭怀有恨意，但是仍然很想帮助他们，让他们知道什么是对的，什么是不对的，想让妹妹去上学，想让母亲不迷恋草药去相信医院。</p>

        <h4 id="相比于外界的认可，自我认可才更为重要"   >
          <a href="#相比于外界的认可，自我认可才更为重要" class="heading-link"><i class="fas fa-link"></i></a><a href="#相比于外界的认可，自我认可才更为重要" class="headerlink" title="相比于外界的认可，自我认可才更为重要"></a>相比于外界的认可，自我认可才更为重要</h4>
      <p>​    逃离原生家庭的过程中面临着种种困难，来到外面的世界后，作者会有各种不适应，自卑，格格不入的感觉，认为别人听到她的人生经历会不理解，看不起她。其实不然，真正的困难从来不是来自于外界，而是自己，自己都无法认可自己时怎么能到到外界的认可，反之，当自己可以认可自己时，外界的认可也便不再那么重要。</p>

        <h3 id="《非暴力沟通》"   >
          <a href="#《非暴力沟通》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《非暴力沟通》" class="headerlink" title="《非暴力沟通》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/26728136/" >《非暴力沟通》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书介绍了一种沟通模式，不论是表达自己还是倾听他人，都要遵循以下四个步骤：观察、感受、需要、请求。需要在平时的沟通中提醒自己，按照下面的模式进行。</p>

        <h4 id="诚实地表达自己，而不批评、指责"   >
          <a href="#诚实地表达自己，而不批评、指责" class="heading-link"><i class="fas fa-link"></i></a><a href="#诚实地表达自己，而不批评、指责" class="headerlink" title="诚实地表达自己，而不批评、指责"></a>诚实地表达自己，而不批评、指责</h4>
      <ol>
<li><p>观察我所观察（看、听、回忆、想）到的有助于（或无助于）我的福祉的具体行为：“当我（看、听、想到我看到的/听到的）……”</p>
</li>
<li><p>感受对于这些行为，我有什么样的感受（情感而非思想）：“我感到……”</p>
</li>
<li><p>需要什么样的需要或价值（而非偏好或某种具体的行为）导致我那样的感受：“因为我需要/看重……”</p>
</li>
<li><p>请求清楚地请求（而非命令）那些能丰富我生命的具体行为，“你是否愿意……？”</p>
</li>
</ol>

        <h4 id="关切地倾听他人，而不解读为批评或指责"   >
          <a href="#关切地倾听他人，而不解读为批评或指责" class="heading-link"><i class="fas fa-link"></i></a><a href="#关切地倾听他人，而不解读为批评或指责" class="headerlink" title="关切地倾听他人，而不解读为批评或指责"></a>关切地倾听他人，而不解读为批评或指责</h4>
      <ol>
<li>观察你所观察（看、听、回忆、想）到的有助于（或无助于）你的福祉的具体行为：“当你（看、听、想到你看到的/听到的）……”</li>
<li>感受对于这些行为，你有什么样的感受（是情感而非思想）：“你感到……吗？”</li>
<li>需要什么样的需要或价值（而非偏好或某种具体的行为）导致你那样的感受：“因为你需要/看重……”</li>
<li>请求关切地倾听那些能丰富你生命的具体请求，而不解读为命令：“所以，你想……”</li>
</ol>

        <h3 id="《代码整洁之道》"   >
          <a href="#《代码整洁之道》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《代码整洁之道》" class="headerlink" title="《代码整洁之道》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/34986245/" >《代码整洁之道》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    从命名规范、注释、代码规范等各个方面介绍了如果写出一份好的代码，其中有许多内容其实在实际编码过程中已经遵守，只不过自己没有意识到，没有系统化的梳理，但是也存在需要自己没有意识到的事情，比如：尽量避免在函数参数中使用布尔型变量来区分不同功能，而是要写成两个名称不同的函数。代码不只是写给自己的，除了功能正确外，可读性强也是好代码的标准，按照书上的总结进行执行，让自己的代码更好。</p>

        <h3 id="《指数基金投资指南》"   >
          <a href="#《指数基金投资指南》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《指数基金投资指南》" class="headerlink" title="《指数基金投资指南》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/27204860/" >《指数基金投资指南》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书可以算一个指数基金的科普手册，通过这本书可以了解大部分主要的指数基金类型的基本知识，并且给出一些投资方面的建议。指数基金的投资，关键还是要稳定投资，长期持有。</p>

        <h3 id="《我的第一本人生规划手册》"   >
          <a href="#《我的第一本人生规划手册》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《我的第一本人生规划手册》" class="headerlink" title="《我的第一本人生规划手册》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/35334790/" >《我的第一本人生规划手册》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书更像是一个公众号文章的合集，它会告诉你要赚钱，要规划，会告诉你什么样的目标在每个阶段应该赚得多少钱，但是并没有什么实质性的建议，每个人的实际情况并不相同，每个人需要考虑、选择、努力的事情也并不相同，重要还是自己认真的思考，然后脚踏实地好好努力。</p>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>2021书单</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka日志清理引发的core dump问题</title>
    <url>/2021/08/15/kafka%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86%E5%BC%95%E5%8F%91%E7%9A%84core-dump%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>​    团队开发了kafka on hdfs的功能，用以将kafka数据存储在hdfs上，但是在使用的过程中发现，有机器出现core dump现象。</p>
<span id="more"></span>

<blockquote>
<p>本文基于kafka版本0.10.2</p>
</blockquote>

        <h2 id="排查过程"   >
          <a href="#排查过程" class="heading-link"><i class="fas fa-link"></i></a><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2>
      
        <h3 id="一、排查core-dump文件"   >
          <a href="#一、排查core-dump文件" class="heading-link"><i class="fas fa-link"></i></a><a href="#一、排查core-dump文件" class="headerlink" title="一、排查core dump文件"></a>一、排查core dump文件</h3>
      <p>由于出现了多次core dump问题，所以首先需要从core dump文件中进行分析。从core dump文件可以看出，以下几个问题：</p>
<ol>
<li>挂掉的线程名称都是hdfs相关的，所以推测与hdfs相关功能有关</li>
<li>挂掉的代码位置都与index读取逻辑有关，所以推测和index清理逻辑有关</li>
</ol>
<p><img src="case1.png" alt="case1"></p>
<p><img src="case2.png" alt="case2"></p>

        <h3 id="二、分析代码"   >
          <a href="#二、分析代码" class="heading-link"><i class="fas fa-link"></i></a><a href="#二、分析代码" class="headerlink" title="二、分析代码"></a>二、分析代码</h3>
      <p>​    分析kafka本地日志删除的代码发现，本地日志删除通过<code>asyncDeleteSegment</code>进行，<code>asyncDeleteSegment</code>进行删除时首先会rename本地日志文件和索引文件，然后延迟一定时间进行删除。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** a file that is scheduled to be deleted */</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">DeletedFileSuffix</span> = <span class="string">&quot;.deleted&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Perform an asynchronous delete on the given file if it exists (otherwise do nothing)</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @throws KafkaStorageException if the file can&#x27;t be renamed and still exists</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">asyncDeleteSegment</span></span>(segment: <span class="type">LogSegment</span>) &#123;</span><br><span class="line">    segment.changeFileSuffixes(<span class="string">&quot;&quot;</span>, <span class="type">Log</span>.<span class="type">DeletedFileSuffix</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteSeg</span></span>() &#123;</span><br><span class="line">      info(<span class="string">&quot;Deleting segment %d from log %s.&quot;</span>.format(segment.baseOffset, name))</span><br><span class="line">      segment.delete()</span><br><span class="line">    &#125;</span><br><span class="line">    scheduler.schedule(<span class="string">&quot;delete-file&quot;</span>, deleteSeg, delay = config.fileDeleteDelayMs)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Change the suffix for the index and log file for this log segment</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">changeFileSuffixes</span></span>(oldSuffix: <span class="type">String</span>, newSuffix: <span class="type">String</span>) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">kafkaStorageException</span></span>(fileType: <span class="type">String</span>, e: <span class="type">IOException</span>) =</span><br><span class="line">      <span class="keyword">new</span> <span class="type">KafkaStorageException</span>(<span class="string">s&quot;Failed to change the <span class="subst">$fileType</span> file suffix from <span class="subst">$oldSuffix</span> to <span class="subst">$newSuffix</span> for log segment <span class="subst">$baseOffset</span>&quot;</span>, e)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> log.renameTo(<span class="keyword">new</span> <span class="type">File</span>(<span class="type">CoreUtils</span>.replaceSuffix(log.file.getPath, oldSuffix, newSuffix)))</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; <span class="keyword">throw</span> kafkaStorageException(<span class="string">&quot;log&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> index.renameTo(<span class="keyword">new</span> <span class="type">File</span>(<span class="type">CoreUtils</span>.replaceSuffix(index.file.getPath, oldSuffix, newSuffix)))</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; <span class="keyword">throw</span> kafkaStorageException(<span class="string">&quot;index&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> timeIndex.renameTo(<span class="keyword">new</span> <span class="type">File</span>(<span class="type">CoreUtils</span>.replaceSuffix(timeIndex.file.getPath, oldSuffix, newSuffix)))</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; <span class="keyword">throw</span> kafkaStorageException(<span class="string">&quot;timeindex&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure>

<p>​    但是在hdfs相关的清理功能中，直接进行的日志清理而没有rename和delay操作，所以推测清理日志和索引时，如果文件仍被读取，强行删除会导致core dump。</p>

        <h3 id="三、测试结论"   >
          <a href="#三、测试结论" class="heading-link"><i class="fas fa-link"></i></a><a href="#三、测试结论" class="headerlink" title="三、测试结论"></a>三、测试结论</h3>
      <p>编写单测，本地索引lookup过程中强行删除索引文件，确实出现了core dump现象。</p>

        <h2 id="解决方案"   >
          <a href="#解决方案" class="heading-link"><i class="fas fa-link"></i></a><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2>
      <p>仿照本地日志的清理策略，在hdfs相关的逻辑中，不直接删除文件，而是先rename文件，然后再延迟一定时间进行删除。</p>

        <h2 id="总结"   >
          <a href="#总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#总结" class="headerlink" title="总结"></a>总结</h2>
      <ol>
<li>本次问题的出现属于偶发现象，只有在kafka consumer消费lag，读取即将被删除的日志时才有可能会发生。</li>
<li>core dump问题分析的过程中需要通过多个case的相似点来分析问题。</li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>问题排查</tag>
      </tags>
  </entry>
  <entry>
    <title>二零二一年八月书单</title>
    <url>/2021/08/28/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E5%85%AB%E6%9C%88%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<p>第二篇书单如期而至。</p>
<span id="more"></span>

<blockquote>
<p>📚以下书籍出现的顺序代表我对这些书的评分排序。</p>
</blockquote>

        <h3 id="《蛤蟆先生去看心理医生》"   >
          <a href="#《蛤蟆先生去看心理医生》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《蛤蟆先生去看心理医生》" class="headerlink" title="《蛤蟆先生去看心理医生》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/35143790/" >《蛤蟆先生去看心理医生》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    一本以寓言故事的形式讲心理学的书，这个寓言故事并不是讲给孩子的，而是讲给大人的。书中提到了一组很有意思的概念：</p>
<ol>
<li>儿童自我状态：“孩子是成年人的父亲”，其实人们成年后的很多思维方式和行为方式都是孩子时的写照。</li>
<li>父母自我状态：成年后的思维方式和行为方式以模仿自己的父母进行。</li>
<li>成人自我状态：指我们用理性而不是情绪化的方式行事。</li>
</ol>
<p>​    反思自己和周围的人，会发现确实会有处于儿童状态，或者父母状态的情况，毕竟一方面无法抛弃自己的过往，另一方面父母又是孩子的老师。之所以处于这两种状态，是因为儿童和父母状态是不需要思考的，自己的思维或者行为就像是表演，表演自己所熟悉的东西。但同时，这两种状态又是最差的，因为没有思考就不会学习。只有处于成人状态下，我们才能够进行学习，才能应对此时正在发生的现实状况。</p>
<p>​    我们生活的样子就是我们自己想成为的样子，而不是别人造就了我们的生活。要想更幸福，就需要有足够的情商。情商真正的意思是：了解你内心的情感世界并且还能掌控它。</p>

        <h3 id="《牧羊少年的奇幻之旅》"   >
          <a href="#《牧羊少年的奇幻之旅》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《牧羊少年的奇幻之旅》" class="headerlink" title="《牧羊少年的奇幻之旅》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/3608208/" >《牧羊少年的奇幻之旅》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    一本奇幻的书，此处借用豆瓣网友Big Ben的短评：“《小王子》教你放下执念，而《牧羊少年奇幻之旅》是教你寻找执念；两种不同的方法，确有着相同的目的。重点不是你在这个世界上寻找什么，而是在过程中明白什么是不可丢弃的，那将是你生命的意义所在，超越一切，一旦了白于心，就将于永恒同在。”</p>
<p>​    不要放弃自己的“执念”，需要向其前进。现在的生活中，在一无所有时，可能会怀着有钱之后周游世界的梦想，但是在足够富有之后，因为会渴望更加富有，或者因为害怕风险，只选择相比周游世界更加平稳的享受当下的幸福。前进的过程中，可能会有很多的收获，甚至到达大众所谓的成功，但是这本书要说的不是前进过程中的收获，而是收获到这些附加东西之后，仍然不要忘记自己的“执念”，为了不让自己在看似优渥的生活中留下遗憾，也为了“执念”实现之后意义。</p>
<p>​    用书中不断重复的一个阿拉伯语来总结和思考：<strong>“马克图布”</strong>，可以理解为：命中注定。</p>

        <h3 id="《心流》"   >
          <a href="#《心流》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《心流》" class="headerlink" title="《心流》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/27186106/" >《心流》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书的序言确实挺长的，不到400页的书，序言就有50多页🐶。“心流”是积极心理学中的重要概念，是指我们在做某些事情时，那种全神贯注、投入忘我的状态——这种状态下，你甚至感觉不到时间的存在，在这件事情完成之后我们会有一种充满能量并且非常满足的感受。在我们的正常生活中，每个人都会有心流体验，只是多与少的区别，比如：中学上电脑课玩游戏时🐶、没有杂事干扰只有自己一个人专心写代码时🐶。这本书讲的是如何让自己尽可能多得体验心流，下面是一些书中观点的笔记：</p>
<ul>
<li>大部分人的心流体验来自于工作而非休息。</li>
<li>享乐与乐趣不同，享乐不需要消耗精神能量，而乐趣需要。</li>
<li>竞争只有在它以使个人技巧臻于完美为目标时，才有乐趣；当它本身成为目的时，就不再有乐趣了。</li>
<li>记忆的重要性：记忆足够充足的人，可以不需要外界刺激而保持心流。</li>
<li>未来不仅属于受过教育的人，更属于那些懂得善用闲暇的人。</li>
<li>培养自得其乐的性格：确立目标、全神贯注、避免过于自我、从当前体验中寻找乐趣。</li>
</ul>

        <h3 id="《政治是什么？》"   >
          <a href="#《政治是什么？》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《政治是什么？》" class="headerlink" title="《政治是什么？》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/26644832/" >《政治是什么？》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这是一本台湾人写的政治普及书籍。这本书对政治中的各种概念进行介绍，并且从作者的角度，结合各种观点进行了客观的分析。作者的表达中不会带着对哪种政治制度的偏见，读这本书的过程确实可以引发自己一些关于政治知识的思考，但是却感觉缺乏主线。下面只列举一些我在读书过程中思考记录的想法：</p>
<ul>
<li>政治是可以在违背他人意愿的情况下实现自己目的的可能性，分为“强制性权力”（例如：武力）和“象征性权力”（例如：信仰），相比强制性权力，象征性权力更会让人们潜意识服从，更不容易反抗推翻。</li>
<li>意识形态可以决定人们是否接受你成为领袖，而能否真正满足人们的需求才是决定你是否可以一直成为领袖的因素。因此，稳固的政治不仅需要一个好的意识形态（借口），还需要让人们感受到自己需求得到满足。</li>
<li>国家并不能称为实体，甚至是一个模糊的概念，比如古代各个国家之间并没有绝对明确的地理划分，也不需要签证。之所以现在这一切变得复杂，是因为各个国家之间的交流过于紧密，如果没有明确的边界感，就会产生争端，为了明确边界感，一个国家需要拥有被其他国家承认的“主权”，如：一个国家的居民必须要有户口等。为什么人不需要说我承认你是人，你才是人？而国家必须要拥有被其他国家承认的主权才是国家？因为人本来就是一个实体，有明确的边界感，而国家本身并非实体，而是一种概念，必须有各种条条框框才能被理解为实体。</li>
</ul>

        <h3 id="《什么是民粹主义？》"   >
          <a href="#《什么是民粹主义？》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《什么是民粹主义？》" class="headerlink" title="《什么是民粹主义？》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/34879976/" >《什么是民粹主义？》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书感觉像是一本表达作者本人政治观点的书籍，可能由于我政治知识不够，并没有兴趣读完整本书，只能依照自己的感觉描述一下对这本书的理解。</p>
<p>​    根据维基百科的解释，民粹主义通常是精英主义的反义词。在古希腊城邦发明民主制度之后，对于应由精英、贵族还是一般大众来掌握政治，出现了争论。支持民粹主义者则诉求直接民主与基层民主，认为政治精英（当下或未来）只追求自身利益，腐化且不可相信，希望由人民直接决定政治事务。</p>
<p>​    这本书作者认为，民粹主义者的本质不是反精英、反多元化、反建制等等，而是对“人民”的定义，民粹主义者们一方面认为只有他们才能代表人民的利益，另一方面又认为只有支持他们的人才算做“人民”，可谓是假民主、真偏见。</p>
<hr>
<p>​    从《你当像鸟飞往你的山》、《蛤蟆先生去看心理医生》和《心流》三本书中都可以看到掌握自己的重要性。了解自己，接纳他人，可以控制自己的情感和思维不被外界干扰，同时又可以完全平和地接纳他人的观点，这是一种很强大的能力，感觉自己现在远远不及，也是自己心理上努力的方向。</p>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>2021书单</tag>
      </tags>
  </entry>
  <entry>
    <title>二零二一年九月书单</title>
    <url>/2021/10/03/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E4%B9%9D%E6%9C%88%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<p>国庆假期补上了第三篇书单。</p>
<span id="more"></span>

<blockquote>
<p>📚以下书籍出现的顺序代表我对这些书的评分排序。</p>
</blockquote>

        <h3 id="《乡土中国》"   >
          <a href="#《乡土中国》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《乡土中国》" class="headerlink" title="《乡土中国》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/1795079/" >《乡土中国》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    费孝通经典作品。一本社会学的书，对我来说，更重要的引发辩证的思考：乡土文化并不是封建守旧，而是在安土重迁的思想下下产生的社会文化，乡土文化在不变的社会中是没有问题的，但是在现代社会，已经不同于原来的社会模式，所以也要适当的思考乡土文化中的哪些内容应当予以改变或摒弃。</p>

        <h3 id="《江村经济》"   >
          <a href="#《江村经济》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《江村经济》" class="headerlink" title="《江村经济》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/20395460/" >《江村经济》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本也是费老的书，费老用两个月的时间调查开弦弓村，完成了这篇著作。介绍上说对中国社会学的发展具有重要意义，也只能从门外汉自己的角度说一说感受：</p>
<ol>
<li><p>虽然调查只有两个月，但是从描述上可以看出，调查相当翔实，并且文笔上没有冗余的文字，虽然描述不多，但是可以清楚地感受到费老想要展现的内容。</p>
</li>
<li><p>这本书详细描述的一个乡村文化、经济、政治等各个方面内容，是一种十分详细的封建农村生活的真实写照，比小说之类看得更为有画面。</p>
<p> 读完上面两本书的感受是，不论是封建传统的思想还是前卫现代的思想，都有其产生的根源，不能单纯的说哪一个更为正确，而是要客观地认识其产生的原因，以及这种文化在当前情况下适合或者不再适合的原因。</p>
</li>
</ol>

        <h3 id="《人生海海》"   >
          <a href="#《人生海海》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《人生海海》" class="headerlink" title="《人生海海》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/30475767/" >《人生海海》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    麦家作品，前后封皮的描述足以概括这本小说的内容。</p>
<ul>
<li><p>人生海海，潮落之后是潮起，你说那是消磨、笑柄、罪过，到那就是我的英雄主义。</p>
</li>
<li><p>他是全村最出奇古怪的人，古怪的名目要扳着指头个个数</p>
<p>第一，他当过国民党军队的上校，是革命群众要争的对象。但大家一边斗争他，一边又巴结讨好他，家里出什么事都去我他拿主意。</p>
<p>第二，说他是太监，可我们小孩子经常偷看他那个地方好像还是满当当的，有模有样的。</p>
<p>第三，他向来不出工，不干农活，天天空在家里看报纸瓜子可日子过得比谁家都舒坦。还像养孩子一样养着一对猫，宝贝得不得了，简直神经病！</p>
<p>《人生海海》讲述了一个人在时代中穿行缠斗的一生，离奇的故事里藏着让人叹息的人生况味，既有日常滋生的残酷，也有时间带来的仁慈。</p>
</li>
</ul>

        <h3 id="《活出生命的意义》"   >
          <a href="#《活出生命的意义》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《活出生命的意义》" class="headerlink" title="《活出生命的意义》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/5330333/" >《活出生命的意义》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书分为两个部分，第一部分是作者在奥斯维辛集中营中经历的描写，以及一些感悟，第二部分则是纯心理学方面的讲述。</p>
<p>​    “由于生命中每一种情况对人来说都是一种挑战，都会提出需要你去解决的问题，所以生命之意义的问题实际上被颠倒了。人不应该问他的生命之意义是什么，而必须承认是生命向他提出了间题。简单地说，生命对每个人都提出了问题，他必须通过对自己生命的理解来回答生命的提问。对待生命，他只能担当起自己的责任。”负责任，就是自己生命的意义。</p>

        <h3 id="《自私的基因》"   >
          <a href="#《自私的基因》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《自私的基因》" class="headerlink" title="《自私的基因》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/11445548/" >《自私的基因》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>本以为是一本心理学的书，实际上更像是一本生物学的科普书籍，并不是很感兴趣。作者将基因定义为进化的基本单位，结合博弈论，从各个方面讲述了基因是如何保证物种稳定的。</p>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>2021书单</tag>
      </tags>
  </entry>
  <entry>
    <title>二零二一年十月书单</title>
    <url>/2021/10/31/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E5%8D%81%E6%9C%88%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<p>十一长假加休假的一个月，读书量变少了🐶。</p>
<span id="more"></span>

<blockquote>
<p>📚以下书籍出现的顺序代表我对这些书的评分排序。</p>
</blockquote>

        <h3 id="《被讨厌的勇气》：厘清自己的课题并做好它"   >
          <a href="#《被讨厌的勇气》：厘清自己的课题并做好它" class="heading-link"><i class="fas fa-link"></i></a><a href="#《被讨厌的勇气》：厘清自己的课题并做好它" class="headerlink" title="《被讨厌的勇气》：厘清自己的课题并做好它"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/26176538/" >《被讨厌的勇气》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：厘清自己的课题并做好它</h3>
      <p>​    这本书通过长者与青年对话的形式，对<strong>阿德勒心理学</strong>进行了通俗并深刻的解释，总结起来，主要包含以下几个方面：</p>
<ol>
<li>人生目标：人生不是与他人比赛，不要有和他人的竞争意识，只需要与理想的自己比较就可以了。健全的自卑感也不是来自于和他人的比较，而是来自于理想的自己的比较。竞争意识不仅会让我们拘泥于胜负而无法做出正确的选择，而且还会让我们增加很多不正常的自卑或者自大的感觉。</li>
<li>人际关系：基本上，一切人际关系矛盾都起因于对别人的课题妄加干涉或者自己的课题被别人妄加干涉。处理人际关系的第一步，要考虑“这是谁的课题”，如果是自己的，不要因为别人的看法来影响自己的决断，如果是别人的，不要对别人的课题过度干涉。依赖或者干涉别人都是没有将彼此放在同一水平的表现，是在潜意识中认为别人比自己高一等或者自己比较别人高一等。但其实人与人之间是平等的，可能有社会层面的长幼尊卑，而作为人，是不存在等级差别的。这个道理不仅限于朋友之间，也包括家人之间甚至父母和子女之间，比如：父母可以在子女需要时提供帮助，但是不能够干涉子女的选择，并且不论是夸奖还是批评，都是一种心理上比子女高一等表现。</li>
<li>自我定位：自己永远是一个独立的个体，不应该依附于任何人，也不比任何人更高级，要让自己在自立的前提下与社会和谐相处。与别人比较、按照别人的看法生活确实会比明确自己的目标更为简单，但这种懒惰是一种不正常的心理。另外，拼命寻求认可也是以自己为中心的不正确表现，与自大一样，都是想要过度强调自己在集体中的地位。</li>
<li>人生意义：“我”是自己人生的主人公，同时也是共同体的一员，是整体的一部分。这里的“共同体”，不是一个家庭、一个学校、一个公司这样的小团体，而是全人类、整个宇宙甚至包含一草一木。当把自己作为自己人生的主人公时，就不会因为别人对自己的评价和看法对自己的心理和决策产生干扰。当把自己作为共同体中普通的一员时，自己才不会因为自己的经里而自卑或自大，才不会去过度干涉别人的课题。要记住，人生只取决于当下，无论之前发生过什么（成功或苦难），都对今后的人生如何度过没有影响。</li>
</ol>

        <h3 id="《一句顶一万句》：平凡琐碎生活中有深刻的感悟"   >
          <a href="#《一句顶一万句》：平凡琐碎生活中有深刻的感悟" class="heading-link"><i class="fas fa-link"></i></a><a href="#《一句顶一万句》：平凡琐碎生活中有深刻的感悟" class="headerlink" title="《一句顶一万句》：平凡琐碎生活中有深刻的感悟"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/26877012/" >《一句顶一万句》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：平凡琐碎生活中有深刻的感悟</h3>
      <p>​    这本刘震云的小说，被称为“中国版的《百年孤独》”，就像是邻居唠家常，讲述谁家谁谁谁怎么怎么样了，但是简单的生活中却又包含着许多的感悟。这本中最核心的观点，就是人与人之间是不是可以“说到一起去”，朋友之间能不能“说到一起去”可以决定能不能一直成为朋友，夫妻之间能不能“说到一起去”可以决定生活会不会幸福。可能一路走来，会发现能够一直“说到一起去”的人少之又少，但是“日子过的是往后，不是从前。”</p>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>2021书单</tag>
      </tags>
  </entry>
  <entry>
    <title>二零二一年十一月书单</title>
    <url>/2021/12/04/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E5%8D%81%E4%B8%80%E6%9C%88%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<p>有点迟到，冲冲冲！</p>
<span id="more"></span>

<blockquote>
<p>📚以下书籍出现的顺序代表我对这些书的评分排序。</p>
</blockquote>

        <h3 id="《沉默的大多数》：相当有意思吐槽"   >
          <a href="#《沉默的大多数》：相当有意思吐槽" class="heading-link"><i class="fas fa-link"></i></a><a href="#《沉默的大多数》：相当有意思吐槽" class="headerlink" title="《沉默的大多数》：相当有意思吐槽"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/1054685/" >《沉默的大多数》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：相当有意思吐槽</h3>
      <p>​    正如这本书的名字所言，多数人对于各种事情会有不满，但是会选择沉默，王小波就像是为这些“沉默的大多数”代言，说出了一些我深有同感却想不起来要说、也没这么会说的想法（ps：<em>看到他强推《乡村经济》时还是很开心的</em>）。王小波的表达太有意思了，像一个“愤青”、像一个“吐槽怪”，读起来很是舒服。虽然没有对这本书具体内容的总结，但是不影响我对这本书的评价。</p>

        <h3 id="《幸福之路》：从各个角度论述如何更幸福"   >
          <a href="#《幸福之路》：从各个角度论述如何更幸福" class="heading-link"><i class="fas fa-link"></i></a><a href="#《幸福之路》：从各个角度论述如何更幸福" class="headerlink" title="《幸福之路》：从各个角度论述如何更幸福"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/1033248/" >《幸福之路》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：从各个角度论述如何更幸福</h3>
      <p>​    罗素的幸福观，从各个角度讲述如何让自己变得更幸福，下面是一些读书笔记，总结了我的理解：</p>
<ul>
<li>论竞争:竞争让人们忘记了事情的本质，忘记了享受生活，只知道去和别人比较。</li>
<li>论烦闷与兴奋:兴奋就像镇静剂，过少会让生活过于平淡，导致烦闷，但是过多就成了毒品。真正的快乐应该来自于远大稳定的目标这种长久的东西，而不是吸毒这种短暂的东西，因为短暂的兴奋过后，会是更大的烦闷与失落，而长久的目标，才能让我们快乐永驻。用罗素的话说，长久平静的快乐与短暂的兴奋相比，就像是有爱情的性生活与没有爱情的性生活。幸福的生活在很大程度上一定是一种平静的生活，因为真正的快乐只能常驻在平静的环境里。</li>
<li>论疲劳:现代的疲劳大多是精神上的疲劳而不是肌肉上的。一方面是因为恐惧何种最坏的情况，另一方面是因为喜欢兴奋，兴奋消耗了大量的精力。</li>
<li>论嫉妒：不会从自己拥有的东西寻找快乐，而会从其他人拥有的东西寻找痛苦。现代人的嫉妒变多了，因为他们从以前只了解嫉妒自己的邻居，变成了可以了解更多的东西。“<strong>希望从绝望中找到正确道路的文明人一定要像拓展自己的思维那样旷达自己的心胸，一定要学会超越自我，从而获得宇宙般无限的自由心灵</strong>”。</li>
<li>论犯罪感：犯罪感大多来自于我们从小被灌输的不一定正确的道德观，当感觉到犯罪感时，需要用理性去评估是否真的错误，要以理性的判断为准。</li>
<li>论被虐狂：第一，要记住，你的动机并不总像你想的那样无私；第二，不要过高估计你的价值；第三，不要指望别人也像你一样那么看重你；第四，不要幻想着大多数人总是在想着怎么害你。</li>
<li>论舆论压力：不要过度在意别人的看法，因为大部分人的看法都是偏见，如果有可能，去一个自己喜欢的环境，在这里别人对你的看法就又是另一种。但是，要听取行业专家的意见。</li>
<li>还可以快乐吗：幸福的秘诀在于：兴趣要尽可能的广，尽可能善意的而不是敌意的对待你感兴趣的人和物。</li>
<li>论情趣：情趣是幸福、安康的秘诀，但是必须要让它们与健康、与我们所爱的人的情感、与我们生活着的社会所尊重的东西协调一致。不要过度放纵寻求遗忘，也不要过于受文明社会的约束而处处不敢。</li>
<li>论爱：最好的是可以互惠的爱，各自可以愉快地接受爱，自然地给予爱，每一方都会因为这种互惠的快乐的存在而觉得这个世界更有意思了。</li>
<li>论家庭：父母与孩子之间的感情比任何情感都更加牢固，但是不能对孩子有过多的占有欲，或者强迫孩子必须按照自己的意志成长，教育也可以交给更专业的人做，并且会做得更好。</li>
<li>论工作：明智地度过闲暇时光的能力是文明的终极产物；有意思的工作主要具备两个要素：可以运用技能；具有建设性。</li>
<li>论闲情逸致：我们只是宇宙中很小的一部分，我们遭遇的痛苦、悲伤也是微不足道的，因此，不要沉浸于痛苦不能自拔，应该积极的通过转移目标方式让自己摆脱痛苦。</li>
<li>论努力与放弃：不要让无所谓的小事影响了自己。尽人事，听天命，不要感情用事。</li>
</ul>

        <h3 id="《论人类不平等的起源和基础》：社会产生之后不平等就开始了"   >
          <a href="#《论人类不平等的起源和基础》：社会产生之后不平等就开始了" class="heading-link"><i class="fas fa-link"></i></a><a href="#《论人类不平等的起源和基础》：社会产生之后不平等就开始了" class="headerlink" title="《论人类不平等的起源和基础》：社会产生之后不平等就开始了"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/1099275/" >《论人类不平等的起源和基础》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：社会产生之后不平等就开始了</h3>
      <p>​    读书摘抄：</p>
<ul>
<li>如果我们从这些不同的变革中去寻找不平等发展的足迹，我们会发现法律和私有财产权的形成是不平等形成的第一阶段；法官的设立是第二阶段；而第三个也是最后一个阶段，则是合法权利向专制权力的转变。因此，第一个阶段催生的是贫富的差距，第二个阶段造就的是强弱的悬殊，而第三个阶段诞生的则是主人与奴隶的对立。主人与奴隶的对立正是不平等的最后阶段，是所有其他不平等终将抵达的彼岸。这一阶段将一直持续，直到新的革命将政府彻底瓦解或者使其向合法制度靠拢为止。</li>
<li>如果所有未经堕落与变质的政府都能做到不忘初心，严格按照成立之初的目的行事，那么，这个政府的成立通常就不是必需的；在一个国家里，如果没有任何人规避法律、滥用司法，那么这个国家是既不需要法官也不需要法律的。</li>
<li>社会的产生是人类之间互相联系的增加，联系更加紧密之后就避免不了对比与竞争对手有对比和竞争就会有不公平。相反，原始人反而是孤独而平等的。</li>
<li>富人为了让穷人从奴隶身份解放出来，创建了政府，但其实，富人只是为了防止奴隶因为不平等而反抗，所以所谓民主政府的建立并非平等。</li>
</ul>

        <h3 id="《后物欲时代的来临》：人们是如何掉进消费主义陷阱的"   >
          <a href="#《后物欲时代的来临》：人们是如何掉进消费主义陷阱的" class="heading-link"><i class="fas fa-link"></i></a><a href="#《后物欲时代的来临》：人们是如何掉进消费主义陷阱的" class="headerlink" title="《后物欲时代的来临》：人们是如何掉进消费主义陷阱的"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/2025385/" >《后物欲时代的来临》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：人们是如何掉进消费主义陷阱的</h3>
      <p>在我看来，这本书主要是对“消费主义陷阱”的诠释。我是在看费孝通大佬的《江村经济》时，在书序中发现的这本书，感觉让我眼前一亮的干货没有很多，唯一记住的一段有意思的观点是：“鲍曼：这一社会的精神特质宣告:假如你心情低落，那就吃。这里发生了一个悖论：因为温饱的解决，发生了空虚和无聊的问题;我们却在解决温饱上面加大砝码，来应对空虚和无聊的问题。”</p>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>2021书单</tag>
      </tags>
  </entry>
  <entry>
    <title>二零二一年十二月书单</title>
    <url>/2021/12/25/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E5%8D%81%E4%BA%8C%E6%9C%88%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<p>一年即将过去，从七月份记录以来，读了 28 本书，按照这个速度，明年的最低目标得是 50 本，加油加油！💪🏻💪🏻💪🏻</p>
<span id="more"></span>

<blockquote>
<p>📚以下书籍出现的顺序代表我对这些书的评分排序。 </p>
</blockquote>

        <h3 id="《深入理解Kafka：核心设计与实践原理》：深入讲解-Kafka-原理但没有简单罗列源码"   >
          <a href="#《深入理解Kafka：核心设计与实践原理》：深入讲解-Kafka-原理但没有简单罗列源码" class="heading-link"><i class="fas fa-link"></i></a><a href="#《深入理解Kafka：核心设计与实践原理》：深入讲解-Kafka-原理但没有简单罗列源码" class="headerlink" title="《深入理解Kafka：核心设计与实践原理》：深入讲解 Kafka 原理但没有简单罗列源码"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/30437872/" >《深入理解Kafka：核心设计与实践原理》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：深入讲解 Kafka 原理但没有简单罗列源码</h3>
      <p>​    作者朱小厮写的这本原理解析的书确实不错，相比与其他介绍组件的书籍，既没有冗长的基本操作的罗列，也没有详细到每一段代码的源码解析。对于基础部分，作者介绍了 Kafka 生产者和消费者的基本使用方式，以及如何灵活地使用拦截器、如何做到不丢失数据不重复消费等，对于高级部分，从原理层面介绍了 Kafka 中几个主要的逻辑，没有源码解析，但是包含了不少作者自己的思考，值得学习。</p>

        <h3 id="《黑箱》：现实中的被性侵者比电影故事中的更受人同情"   >
          <a href="#《黑箱》：现实中的被性侵者比电影故事中的更受人同情" class="heading-link"><i class="fas fa-link"></i></a><a href="#《黑箱》：现实中的被性侵者比电影故事中的更受人同情" class="headerlink" title="《黑箱》：现实中的被性侵者比电影故事中的更受人同情"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/30484795/" >《黑箱》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：现实中的被性侵者比电影故事中的更受人同情</h3>
      <p>​    这是一本遭遇性侵女孩的自述，这个日本女孩讲述了自己是如何遭遇性侵的、警察是如何不负责任的以及她最终通过杂志和发布会讲出这件事的原因。在日本这个男权社会中，受性侵者维护自己的权利十分困难，因为警察都认为这是一件正常的事，警察都会倾向让受害人私了。并且在作者就医以及接受警察问询的过程中，真切感受到了什么叫做“二次性侵”，让受害者不断揭开自己的伤疤甚至比第一次遭遇伤害还要残忍。作者是勇敢的，她的表达带动更多的人加入到了#MeToo运动中，也让我们可以更深地了解到这类事件的真相。</p>

        <h3 id="《抱住棒棒的自己》：短小却有意义的心理案例合集"   >
          <a href="#《抱住棒棒的自己》：短小却有意义的心理案例合集" class="heading-link"><i class="fas fa-link"></i></a><a href="#《抱住棒棒的自己》：短小却有意义的心理案例合集" class="headerlink" title="《抱住棒棒的自己》：短小却有意义的心理案例合集"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/35641411/" >《抱住棒棒的自己》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：短小却有意义的心理案例合集</h3>
      <p>​    这本书看名字有点无营养畅销书的感觉，实际读起来则不然。这本书出自徐慢慢公众号，通过一个虚拟人物，以漫画的形式刻画了许多我们在生活中会遇到的场景，通过浅显的方式讲出了许多道理：</p>
<ul>
<li>关于接纳自己：当一个人不被逼迫、不被设限，而是被无条件地接纳时，他自然能感知到接纳背后的爱和期待。</li>
<li>关于自我批判：我们有意识地压抑消极情绪、自我批判，只会让情绪更加强化。自我批判的人其实更容易认输放弃。</li>
<li>关于帮助别人：比一切帮助更为基本的帮助，是让人们意识到，他们总比自己以为的更有办法。</li>
<li>关于自我要求：总想正确地活着，其实是一种虚弱。不要凡事都去想对错。</li>
</ul>

        <h3 id="《公正：该如何是好？》：如何辩证地看待公正这个问题"   >
          <a href="#《公正：该如何是好？》：如何辩证地看待公正这个问题" class="heading-link"><i class="fas fa-link"></i></a><a href="#《公正：该如何是好？》：如何辩证地看待公正这个问题" class="headerlink" title="《公正：该如何是好？》：如何辩证地看待公正这个问题"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/20366368/" >《公正：该如何是好？》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：如何辩证地看待公正这个问题</h3>
      <p>​    最有名的哈佛公开课，作者通过一个个有关公正的故事，引入了卢梭、边沁、康德等人的学说，解释了他们的观点，又推翻了他们的观点。这本书重要的不是告诉我们到底什么才是公正，而是教会我们辩证地思考公正这件事情，凡事无绝对，辩证思考才能跳出思想束缚。</p>

        <h3 id="《房价的逻辑》：通过数据解释了为什么那些关于房价的流言不正确"   >
          <a href="#《房价的逻辑》：通过数据解释了为什么那些关于房价的流言不正确" class="heading-link"><i class="fas fa-link"></i></a><a href="#《房价的逻辑》：通过数据解释了为什么那些关于房价的流言不正确" class="headerlink" title="《房价的逻辑》：通过数据解释了为什么那些关于房价的流言不正确"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/35616923/" >《房价的逻辑》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：通过数据解释了为什么那些关于房价的流言不正确</h3>
      <p>​    为什么房价不会跌？为什么说房地产不是泡沫？作者通过与全球范围内的大城市（东京、纽约、伦敦等）对比，用数据对关于买房的种种流言进行反驳。总结起来就是：不论是生育率下降还是政府的严格管控，都不会改变大城市房价上涨的趋势，因为优秀的人才永远都会向好的地方流动，好的地方都是房子供给不足。说明供求关系的最简单逻辑就是：“假设房子降价，你会不会上车？”</p>

        <h3 id="《沸腾新十年》：一本互联网科技史"   >
          <a href="#《沸腾新十年》：一本互联网科技史" class="heading-link"><i class="fas fa-link"></i></a><a href="#《沸腾新十年》：一本互联网科技史" class="headerlink" title="《沸腾新十年》：一本互联网科技史"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/35567300/" >《沸腾新十年》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>：一本互联网科技史</h3>
      <p>​    这本书上下两册，60 多万字，介绍了从 2010 年到 2020 年十年间互联网中重要的历史，内容相当全面，可以看到互联网中每个小领域的变化，也可以看到各个大厂的起起伏伏。但是涉及到的人物确实有点多，看完只能知道大概的事件，却记不得有哪些人。主要还是一些客观事实的描述，主观的解读还是要靠自己的思考。</p>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>2021书单</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka 源码学习：日志加载与恢复</title>
    <url>/2022/02/20/Kafka-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E6%97%A5%E5%BF%97%E5%8A%A0%E8%BD%BD%E4%B8%8E%E6%81%A2%E5%A4%8D/</url>
    <content><![CDATA[<p>本文梳理主要梳理 Kafka 日志加载与恢复的源码。（Kafka 版本：2.8）</p>
<span id="more"></span>


        <h2 id="日志管理：LogManager"   >
          <a href="#日志管理：LogManager" class="heading-link"><i class="fas fa-link"></i></a><a href="#日志管理：LogManager" class="headerlink" title="日志管理：LogManager"></a>日志管理：LogManager</h2>
      <blockquote>
<p>LogManager 是 kafka 日志管理子系统的入口点。负责日志的创建、检索和清理。所有读取和写入操作都委托给各个日志实例。LogManager 在一个或多个目录中维护日志。在日志最少的数据目录中创建新日志。事后不会尝试移动分区或根据大小或 I/O 速率进行平衡。后台线程通过定期截断多余的日志段来处理日志保留。</p>
</blockquote>
<p>LogManger 的启动主要包括三个部分：</p>
<ol>
<li>日志加载与恢复，即：loadLogs</li>
<li>各个定时任务启动，主要包括：<br>a. cleanupLogs：根据保留时间和保留大小进行历史 segment 的清理<br>b. flushDirtyLogs：定时刷新还没有写到磁盘上日志<br>c. checkpointLogRecoveryOffsets：定时将所有数据目录所有日志的检查点写到检查点文件中<br>d. checkpointLogStartOffsets：将所有日志的当前日志开始偏移量写到日志目录中的文本文件中，以避免暴露已被 DeleteRecordsRequest 删除的数据<br>e. deleteLogs：定时删除标记为 delete 的日志文件</li>
<li>启动 LogCleaner，负责进行日志 compaction</li>
</ol>
<p>本文主要对第一部分日志加载与恢复进行梳理。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="comment">// visible for testing</span></span><br><span class="line"><span class="keyword">private</span>[log] <span class="function"><span class="keyword">def</span> <span class="title">startupWithConfigOverrides</span></span>(topicConfigOverrides: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">LogConfig</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  loadLogs(topicConfigOverrides) <span class="comment">// this could take a while if shutdown was not clean</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">/* Schedule the cleanup task to delete old logs */</span></span><br><span class="line">  <span class="keyword">if</span> (scheduler != <span class="literal">null</span>) &#123;</span><br><span class="line">    info(<span class="string">&quot;Starting log cleanup with a period of %d ms.&quot;</span>.format(retentionCheckMs))</span><br><span class="line">    scheduler.schedule(<span class="string">&quot;kafka-log-retention&quot;</span>,</span><br><span class="line">                       cleanupLogs _,</span><br><span class="line">                       delay = <span class="type">InitialTaskDelayMs</span>,</span><br><span class="line">                       period = retentionCheckMs,</span><br><span class="line">                       <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">    info(<span class="string">&quot;Starting log flusher with a default period of %d ms.&quot;</span>.format(flushCheckMs))</span><br><span class="line">    scheduler.schedule(<span class="string">&quot;kafka-log-flusher&quot;</span>,</span><br><span class="line">                       flushDirtyLogs _,</span><br><span class="line">                       delay = <span class="type">InitialTaskDelayMs</span>,</span><br><span class="line">                       period = flushCheckMs,</span><br><span class="line">                       <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">    scheduler.schedule(<span class="string">&quot;kafka-recovery-point-checkpoint&quot;</span>,</span><br><span class="line">                       checkpointLogRecoveryOffsets _,</span><br><span class="line">                       delay = <span class="type">InitialTaskDelayMs</span>,</span><br><span class="line">                       period = flushRecoveryOffsetCheckpointMs,</span><br><span class="line">                       <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">    scheduler.schedule(<span class="string">&quot;kafka-log-start-offset-checkpoint&quot;</span>,</span><br><span class="line">                       checkpointLogStartOffsets _,</span><br><span class="line">                       delay = <span class="type">InitialTaskDelayMs</span>,</span><br><span class="line">                       period = flushStartOffsetCheckpointMs,</span><br><span class="line">                       <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">    scheduler.schedule(<span class="string">&quot;kafka-delete-logs&quot;</span>, <span class="comment">// will be rescheduled after each delete logs with a dynamic period</span></span><br><span class="line">                       deleteLogs _,</span><br><span class="line">                       delay = <span class="type">InitialTaskDelayMs</span>,</span><br><span class="line">                       unit = <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">if</span> (cleanerConfig.enableCleaner) &#123;</span><br><span class="line">    _cleaner = <span class="keyword">new</span> <span class="type">LogCleaner</span>(cleanerConfig, liveLogDirs, currentLogs, logDirFailureChannel, time = time)</span><br><span class="line">    _cleaner.startup()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>


        <h2 id="全部日志加载与恢复：loadLogs"   >
          <a href="#全部日志加载与恢复：loadLogs" class="heading-link"><i class="fas fa-link"></i></a><a href="#全部日志加载与恢复：loadLogs" class="headerlink" title="全部日志加载与恢复：loadLogs"></a>全部日志加载与恢复：loadLogs</h2>
      <p>  所有日志的加载与恢复的流程主要包含以下几步：</p>
<ol>
<li>加载并记录日志文件夹中标志状态信息的文件（kafka_cleanshutdown、recovery-point-offset-checkpoint、recovery-point-offset-checkpoint）</li>
<li>并发对每个 tp 的日志进行加载与恢复（下一小节详解）</li>
<li>记录并异步处理有问题的日志文件夹<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Recover and load all logs in the given data directories</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">private</span>[log] <span class="function"><span class="keyword">def</span> <span class="title">loadLogs</span></span>(topicConfigOverrides: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">LogConfig</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="comment">// 对所有可用的日志目录（liveLogDirs）进行加载，kafka server 启动时可能配置多个磁盘目录用来存储日志文件，但是不一定所有的磁盘都是可用的</span></span><br><span class="line">  info(<span class="string">s&quot;Loading logs from log dirs <span class="subst">$liveLogDirs</span>&quot;</span>)</span><br><span class="line">  <span class="keyword">val</span> startMs = time.hiResClockMs()</span><br><span class="line">  <span class="keyword">val</span> threadPools = <span class="type">ArrayBuffer</span>.empty[<span class="type">ExecutorService</span>]</span><br><span class="line">  <span class="keyword">val</span> offlineDirs = mutable.<span class="type">Set</span>.empty[(<span class="type">String</span>, <span class="type">IOException</span>)]</span><br><span class="line">  <span class="keyword">val</span> jobs = <span class="type">ArrayBuffer</span>.empty[<span class="type">Seq</span>[<span class="type">Future</span>[_]]]</span><br><span class="line">  <span class="keyword">var</span> numTotalLogs = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 遍历所有的磁盘，进行日志加载与恢复，如果出现 IOException，则将该目录记录到 offlineDirs 中进行后续处理</span></span><br><span class="line">  <span class="keyword">for</span> (dir &lt;- liveLogDirs) &#123;</span><br><span class="line">    <span class="keyword">val</span> logDirAbsolutePath = dir.getAbsolutePath</span><br><span class="line">    <span class="keyword">var</span> hadCleanShutdown: <span class="type">Boolean</span> = <span class="literal">false</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> pool = <span class="type">Executors</span>.newFixedThreadPool(numRecoveryThreadsPerDataDir)</span><br><span class="line">      threadPools.append(pool)</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 如果 .kafka_cleanshutdown 文件存在，则将该文件删除并记录 hadCleanShutdown 状态，后续不需要进行日志恢复的流程。</span></span><br><span class="line">      <span class="keyword">val</span> cleanShutdownFile = <span class="keyword">new</span> <span class="type">File</span>(dir, <span class="type">Log</span>.<span class="type">CleanShutdownFile</span>)</span><br><span class="line">      <span class="keyword">if</span> (cleanShutdownFile.exists) &#123;</span><br><span class="line">        info(<span class="string">s&quot;Skipping recovery for all logs in <span class="subst">$logDirAbsolutePath</span> since clean shutdown file was found&quot;</span>)</span><br><span class="line">        <span class="comment">// Cache the clean shutdown status and use that for rest of log loading workflow. Delete the CleanShutdownFile</span></span><br><span class="line">        <span class="comment">// so that if broker crashes while loading the log, it is considered hard shutdown during the next boot up. KAFKA-10471</span></span><br><span class="line">        <span class="type">Files</span>.deleteIfExists(cleanShutdownFile.toPath)</span><br><span class="line">        hadCleanShutdown = <span class="literal">true</span></span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// log recovery itself is being performed by `Log` class during initialization</span></span><br><span class="line">        info(<span class="string">s&quot;Attempting recovery for all logs in <span class="subst">$logDirAbsolutePath</span> since no clean shutdown file was found&quot;</span>)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 从 recovery-point-offset-checkpoint 文件读取所有 tp 目录的 recoveryPoint</span></span><br><span class="line">      <span class="keyword">var</span> recoveryPoints = <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Long</span>]()</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        recoveryPoints = <span class="keyword">this</span>.recoveryPointCheckpoints(dir).read()</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">          warn(<span class="string">s&quot;Error occurred while reading recovery-point-offset-checkpoint file of directory &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;<span class="subst">$logDirAbsolutePath</span>, resetting the recovery checkpoint to 0&quot;</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 从 log-start-offset-checkpoint 文件读取所有 tp 目录的 logStartOffset</span></span><br><span class="line">      <span class="keyword">var</span> logStartOffsets = <span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Long</span>]()</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        logStartOffsets = <span class="keyword">this</span>.logStartOffsetCheckpoints(dir).read()</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Exception</span> =&gt;</span><br><span class="line">          warn(<span class="string">s&quot;Error occurred while reading log-start-offset-checkpoint file of directory &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;<span class="subst">$logDirAbsolutePath</span>, resetting to the base offset of the first segment&quot;</span>, e)</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 日志的加载与恢复主流程，并发对所有 tp 的日志执行 loadLog</span></span><br><span class="line">      <span class="keyword">val</span> logsToLoad = <span class="type">Option</span>(dir.listFiles).getOrElse(<span class="type">Array</span>.empty).filter(logDir =&gt;</span><br><span class="line">        logDir.isDirectory &amp;&amp; <span class="type">Log</span>.parseTopicPartitionName(logDir).topic != <span class="type">KafkaRaftServer</span>.<span class="type">MetadataTopic</span>)</span><br><span class="line">      <span class="keyword">val</span> numLogsLoaded = <span class="keyword">new</span> <span class="type">AtomicInteger</span>(<span class="number">0</span>)</span><br><span class="line">      numTotalLogs += logsToLoad.length</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> jobsForDir = logsToLoad.map &#123; logDir =&gt;</span><br><span class="line">        <span class="keyword">val</span> runnable: <span class="type">Runnable</span> = () =&gt; &#123;</span><br><span class="line">          <span class="keyword">try</span> &#123;</span><br><span class="line">            debug(<span class="string">s&quot;Loading log <span class="subst">$logDir</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">val</span> logLoadStartMs = time.hiResClockMs()</span><br><span class="line">            <span class="keyword">val</span> log = loadLog(logDir, hadCleanShutdown, recoveryPoints, logStartOffsets, topicConfigOverrides)</span><br><span class="line">            <span class="keyword">val</span> logLoadDurationMs = time.hiResClockMs() - logLoadStartMs</span><br><span class="line">            <span class="keyword">val</span> currentNumLoaded = numLogsLoaded.incrementAndGet()</span><br><span class="line"></span><br><span class="line">            info(<span class="string">s&quot;Completed load of <span class="subst">$log</span> with <span class="subst">$&#123;log.numberOfSegments&#125;</span> segments in <span class="subst">$&#123;logLoadDurationMs&#125;</span>ms &quot;</span> +</span><br><span class="line">              <span class="string">s&quot;(<span class="subst">$currentNumLoaded</span>/<span class="subst">$&#123;logsToLoad.length&#125;</span> loaded in <span class="subst">$logDirAbsolutePath</span>)&quot;</span>)</span><br><span class="line">          &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt;</span><br><span class="line">              offlineDirs.add((logDirAbsolutePath, e))</span><br><span class="line">              error(<span class="string">s&quot;Error while loading log dir <span class="subst">$logDirAbsolutePath</span>&quot;</span>, e)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        runnable</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      jobs += jobsForDir.map(pool.submit)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt;</span><br><span class="line">        offlineDirs.add((logDirAbsolutePath, e))</span><br><span class="line">        error(<span class="string">s&quot;Error while loading log dir <span class="subst">$logDirAbsolutePath</span>&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// 等待所有并发执行的日志加载流程执行完成</span></span><br><span class="line">    <span class="keyword">for</span> (dirJobs &lt;- jobs) &#123;</span><br><span class="line">      dirJobs.foreach(_.get)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 记录所有有问题的的目录，后续该目录会被 ReplicaManager 执行下线操作</span></span><br><span class="line">    offlineDirs.foreach &#123; <span class="keyword">case</span> (dir, e) =&gt;</span><br><span class="line">      logDirFailureChannel.maybeAddOfflineLogDir(dir, <span class="string">s&quot;Error while loading log dir <span class="subst">$dir</span>&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">ExecutionException</span> =&gt;</span><br><span class="line">      error(<span class="string">s&quot;There was an error in one of the threads during logs loading: <span class="subst">$&#123;e.getCause&#125;</span>&quot;</span>)</span><br><span class="line">      <span class="keyword">throw</span> e.getCause</span><br><span class="line">  &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">    threadPools.foreach(_.shutdown())</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  info(<span class="string">s&quot;Loaded <span class="subst">$numTotalLogs</span> logs in <span class="subst">$&#123;time.hiResClockMs() - startMs&#125;</span>ms.&quot;</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure></li>
</ol>

        <h2 id="单-tp-日志加载与恢复"   >
          <a href="#单-tp-日志加载与恢复" class="heading-link"><i class="fas fa-link"></i></a><a href="#单-tp-日志加载与恢复" class="headerlink" title="单 tp 日志加载与恢复"></a>单 tp 日志加载与恢复</h2>
      <p>单个 tp 的日志加载与恢复是在 Log 类的静态代码块中进行的。如果该 tp 的文件夹的后缀为-delete，则认为该 tp 为待删除的，加入到 logsToBeDeleted 集合中等待定时任务对其进行清理。<br>Log 类的静态代码块中通过 loadSegments 加载日志</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">loadSegments</span></span>(): <span class="type">Long</span> = &#123;</span><br><span class="line">  <span class="comment">// 清理临时文件（.delete 和 .clean 后缀）并保留可用的 swap 文件</span></span><br><span class="line">  <span class="keyword">val</span> swapFiles = removeTempFilesAndCollectSwapFiles()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// retryOnOffsetOverflow 兜住可能发生的 LogSegmentOffsetOverflowException 异常，并进行日志切分处理。</span></span><br><span class="line">  retryOnOffsetOverflow &#123;</span><br><span class="line">    <span class="comment">// 加载文件的中的所有文件并进行必要的完整性检查</span></span><br><span class="line">    logSegments.foreach(_.close())</span><br><span class="line">    segments.clear()</span><br><span class="line">    loadSegmentFiles()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 根据 swap 文件恢复完成所有被中断的操作</span></span><br><span class="line">  completeSwapOperations(swapFiles)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 如果不是待删除的 tp 日志，执行 recover 流程</span></span><br><span class="line">  <span class="keyword">if</span> (!dir.getAbsolutePath.endsWith(<span class="type">Log</span>.<span class="type">DeleteDirSuffix</span>)) &#123;</span><br><span class="line">    <span class="keyword">val</span> nextOffset = retryOnOffsetOverflow &#123;</span><br><span class="line">      recoverLog()</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// reset the index size of the currently active log segment to allow more entries</span></span><br><span class="line">    activeSegment.resizeIndexes(config.maxIndexSize)</span><br><span class="line">    nextOffset</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     <span class="keyword">if</span> (logSegments.isEmpty) &#123;</span><br><span class="line">        addSegment(<span class="type">LogSegment</span>.open(dir = dir,</span><br><span class="line">          baseOffset = <span class="number">0</span>,</span><br><span class="line">          config,</span><br><span class="line">          time = time,</span><br><span class="line">          initFileSize = <span class="keyword">this</span>.initFileSize))</span><br><span class="line">     &#125;</span><br><span class="line">    <span class="number">0</span></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>
<p>recoverLog 的核心代码如下：</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="comment">// if we have the clean shutdown marker, skip recovery</span></span><br><span class="line"><span class="comment">// 只有未进行 cleanshutdown 的情况下才需要 recovery</span></span><br><span class="line"><span class="keyword">if</span> (!hadCleanShutdown) &#123;</span><br><span class="line">  <span class="comment">// 取出 recoveryPoint 之后的所有 segment（正常情况下只有一个）</span></span><br><span class="line">  <span class="keyword">val</span> unflushed = logSegments(<span class="keyword">this</span>.recoveryPoint, <span class="type">Long</span>.<span class="type">MaxValue</span>).iterator</span><br><span class="line">  <span class="keyword">var</span> truncated = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">while</span> (unflushed.hasNext &amp;&amp; !truncated) &#123;</span><br><span class="line">    <span class="keyword">val</span> segment = unflushed.next()</span><br><span class="line">    info(<span class="string">s&quot;Recovering unflushed segment <span class="subst">$&#123;segment.baseOffset&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">val</span> truncatedBytes =</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">// 清空 segment 对应的 index，逐个 batch 读取校验数据，并重新构造index</span></span><br><span class="line">        recoverSegment(segment, leaderEpochCache)</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> _: <span class="type">InvalidOffsetException</span> =&gt;</span><br><span class="line">          <span class="keyword">val</span> startOffset = segment.baseOffset</span><br><span class="line">          warn(<span class="string">&quot;Found invalid offset during recovery. Deleting the corrupt segment and &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;creating an empty one with starting offset <span class="subst">$startOffset</span>&quot;</span>)</span><br><span class="line">          segment.truncateTo(startOffset)</span><br><span class="line">      &#125;</span><br><span class="line">    <span class="keyword">if</span> (truncatedBytes &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="comment">// 如果前一个 segment 执行了 truncate， 则之后的所有 segment 直接删除</span></span><br><span class="line">      <span class="comment">// unflushed 为迭代器，所以 unflushed.toList 代表的是所有未遍历到的 segment，而不是全部 segment</span></span><br><span class="line">      warn(<span class="string">s&quot;Corruption found in segment <span class="subst">$&#123;segment.baseOffset&#125;</span>, truncating to offset <span class="subst">$&#123;segment.readNextOffset&#125;</span>&quot;</span>)</span><br><span class="line">      removeAndDeleteSegments(unflushed.toList,</span><br><span class="line">        asyncDelete = <span class="literal">true</span>,</span><br><span class="line">        reason = <span class="type">LogRecovery</span>)</span><br><span class="line">      truncated = <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka 源码学习：动态配置</title>
    <url>/2022/03/29/Kafka-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/</url>
    <content><![CDATA[<p>Kafka 的动态配置基于 Zookeeper 实现，本文主要梳理了 Kafka（version：2.8） 中动态配置的实现逻辑。</p>
<span id="more"></span>


        <h2 id="背景信息"   >
          <a href="#背景信息" class="heading-link"><i class="fas fa-link"></i></a><a href="#背景信息" class="headerlink" title="背景信息"></a>背景信息</h2>
      <p>在 Kafka 中，Zookeeper 客户端没有使用常见的客户端工具（如：Curator），而是直接基于原生的客户端实现了自己的 KafkaZkClient，将一些通用或特有的 Zookeeper 操作封装在内。因此，关于 Zookeeper 的使用及回调等逻辑也完全是独立实现的。另外，由于 Zookeeper 中一个节点下的 Watcher 顺序触发，如果同一个节点下有大量的 Watcher，将会产生性能瓶颈。下面将基于这些背景信息来介绍 Kafka 是如何基于 Zookeeper 实现高效的动态配置管理的。</p>
<p><img   src="https://github.com/fxbing/fxbing.GitHub.io/blob/master/2022/03/29/Kafka-%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9A%E5%8A%A8%E6%80%81%E9%85%8D%E7%BD%AE/dynamicconfig.png?raw=true" style=""  alt="Kafka 动态配置结构"></p>

        <h2 id="Kafka-动态配置-Zookeeper-目录结构"   >
          <a href="#Kafka-动态配置-Zookeeper-目录结构" class="heading-link"><i class="fas fa-link"></i></a><a href="#Kafka-动态配置-Zookeeper-目录结构" class="headerlink" title="Kafka 动态配置 Zookeeper 目录结构"></a>Kafka 动态配置 Zookeeper 目录结构</h2>
      <p>在当前版本的 Kafka 中，动态配置类型有 5 种：topic, client, user, broker, ip。Kafka 动态配置的目录结构为： <code>/config/entityType/entityName</code> ，entityType 代表配置的类型，entityName 代表具体某个实体，比如：Topic 类型对应的实体就是具体某个 Topic，某个配置类型下所有实体的默认配置的 entityName 为 <code>&lt;deafult&gt;</code> (<strong>topic 类型没有 <code>&lt;default&gt;</code> 配置，通过 broker 类型来修改 <code>LogConfig</code> 的默认配置</strong>)。具体来说，所有 Topic 的默认动态配置会放在 <code>/config/topic/&lt;default&gt;</code> 的节点信息中，Topic AAA 的所有动态配置会放在 <code>/config/topic/AAA</code> 的节点信息中。</p>

        <h2 id="Listener-实现"   >
          <a href="#Listener-实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#Listener-实现" class="headerlink" title="Listener 实现"></a>Listener 实现</h2>
      <p>下面介绍 Kafka 中 Zookeeper Listener 的实现。既然是基于 Zookeeper 实现，必然少不了 Zookeeper 的 Watcher 通知机制，但是，如背景信息中所说，在 Watcher 数量过多的情况下，会存在性能瓶颈。以 Topic 配置变更为例，在生产环境中，一个 Topic 的 Partition 数量可能多达上千，如果每个 Partition Leader 都去监听这个 Topic 配置信息，那么在一个 Kafka 集群内，仅监听 Topic 配置的 Watcher 就会有上万个甚至更多。Kafka 通过独立的通知机制来避免了这一问题，即：每次 AdminClient 进行配置变更时，会在 <code>/config/changes/</code> 目录下创建以 <code>config_change_</code> 为前缀的顺序节点，Wather 只监听 <code>/config/changes/</code> 目录的孩子节点变化，所以对于动态配置来说，所有 Broker 只监听 <code>/config/changes/</code> 这一个目录，大大减少集群整体的 Watcher 数量。</p>
<p>Kafka 中动态配置的 Zookeeper Listener 的实现在 <code>ZkNodeChangeNotificationListener</code> 类中，该类监听指定目录下的顺序节点添加动作，在收到子节点变化通知后，<code>ZkNodeChangeNotificationListener</code> 一方面执行通知动作，通知对应的 Handler 处理配置变更，另一面会清除所有已经处理过的配置变更。  </p>
<p>下面对 <code>ZkNodeChangeNotificationListener</code> 类的实现进行介绍，主要分为以下几个部分：<br>    a. 初始化：注册 zk 连接状态变更的 Handler 和 zk 子节点变更的 Handler；调用一次 <code>addChangeNotification()</code> 触发一次配置变更的处理，用来初始化动态配置；启动用来处理配置变更事件的线程 <code>ChangeEventProcessThread</code>。<br>    b. 配置变更处理：每次 zk 状态变更或者动态配置变更都会向 queue 中放入一个处理事件，与此同时，<code>ChangeEventProcessThread</code> 会持续不断的从 queue 中取出事件，执行对应的处理动作，即：<code>processNotifications()</code>。<br>    c. 清除过期通知：每次执行完 <code>processNotifications()</code>，都会调用 <code>purgeObsoleteNotifications</code> 执行过期通知的清理动作，删除所有进行本次 <code>processNotifications()</code> 之前创建的所有变更通知。  </p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ZkNodeChangeNotificationListener</span>(<span class="params">private val zkClient: <span class="type">KafkaZkClient</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                                       private val seqNodeRoot: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                                       private val seqNodePrefix: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                                       private val notificationHandler: <span class="type">NotificationHandler</span>,</span></span></span><br><span class="line"><span class="params"><span class="class">                                       private val changeExpirationMs: <span class="type">Long</span> = 15 * 60 * 1000,</span></span></span><br><span class="line"><span class="params"><span class="class">                                       private val time: <span class="type">Time</span> = <span class="type">Time</span>.<span class="type">SYSTEM</span></span>) <span class="keyword">extends</span> <span class="title">Logging</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">var</span> lastExecutedChange = <span class="number">-1</span>L</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> queue = <span class="keyword">new</span> <span class="type">LinkedBlockingQueue</span>[<span class="type">ChangeNotification</span>]</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> thread = <span class="keyword">new</span> <span class="type">ChangeEventProcessThread</span>(<span class="string">s&quot;<span class="subst">$seqNodeRoot</span>-event-process-thread&quot;</span>)</span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">val</span> isClosed = <span class="keyword">new</span> <span class="type">AtomicBoolean</span>(<span class="literal">false</span>)</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">init</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// ZkStateChangeHandler 和 ChangeNotificationHandler 都是 addChangeNotification()</span></span><br><span class="line">    zkClient.registerStateChangeHandler(<span class="type">ZkStateChangeHandler</span>)</span><br><span class="line">    zkClient.registerZNodeChildChangeHandler(<span class="type">ChangeNotificationHandler</span>)</span><br><span class="line">    addChangeNotification()</span><br><span class="line">    thread.start()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">close</span></span>() = &#123;</span><br><span class="line">    ···</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Process notifications</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">processNotifications</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">val</span> notifications = zkClient.getChildren(seqNodeRoot).sorted</span><br><span class="line">      <span class="keyword">if</span> (notifications.nonEmpty) &#123;</span><br><span class="line">        info(<span class="string">s&quot;Processing notification(s) to <span class="subst">$seqNodeRoot</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">val</span> now = time.milliseconds</span><br><span class="line">        <span class="keyword">for</span> (notification &lt;- notifications) &#123;</span><br><span class="line">          <span class="keyword">val</span> changeId = changeNumber(notification)</span><br><span class="line">          <span class="comment">// 只处理更新的变更信息</span></span><br><span class="line">          <span class="keyword">if</span> (changeId &gt; lastExecutedChange) &#123;</span><br><span class="line">            <span class="comment">// 调用 notificationHandler.processNotification() 进行配置变更的处理</span></span><br><span class="line">            processNotification(notification)</span><br><span class="line">            lastExecutedChange = changeId</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        purgeObsoleteNotifications(now, notifications)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      ···</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  ···</span><br><span class="line">  ···</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">addChangeNotification</span></span>(): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">if</span> (!isClosed.get &amp;&amp; queue.peek() == <span class="literal">null</span>)</span><br><span class="line">      queue.put(<span class="keyword">new</span> <span class="type">ChangeNotification</span>)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">ChangeNotification</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process</span></span>(): <span class="type">Unit</span> = processNotifications()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">purgeObsoleteNotifications</span></span>(now: <span class="type">Long</span>, notifications: <span class="type">Seq</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">for</span> (notification &lt;- notifications.sorted) &#123;</span><br><span class="line">      <span class="keyword">val</span> notificationNode = seqNodeRoot + <span class="string">&quot;/&quot;</span> + notification</span><br><span class="line">      <span class="keyword">val</span> (data, stat) = zkClient.getDataAndStat(notificationNode)</span><br><span class="line">      <span class="keyword">if</span> (data.isDefined) &#123;</span><br><span class="line">        <span class="keyword">if</span> (now - stat.getCtime &gt; changeExpirationMs) &#123;</span><br><span class="line">          debug(<span class="string">s&quot;Purging change notification <span class="subst">$notificationNode</span>&quot;</span>)</span><br><span class="line">          zkClient.deletePath(notificationNode)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* get the change number from a change notification znode */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">changeNumber</span></span>(name: <span class="type">String</span>): <span class="type">Long</span> = name.substring(seqNodePrefix.length).toLong</span><br><span class="line"></span><br><span class="line">  <span class="class"><span class="keyword">class</span> <span class="title">ChangeEventProcessThread</span>(<span class="params">name: <span class="type">String</span></span>) <span class="keyword">extends</span> <span class="title">ShutdownableThread</span>(<span class="params">name = name</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doWork</span></span>(): <span class="type">Unit</span> = queue.take().process()</span><br><span class="line">  &#125;</span><br><span class="line">  ···</span><br><span class="line">  ···</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>


        <h2 id="Handler-实现"   >
          <a href="#Handler-实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#Handler-实现" class="headerlink" title="Handler 实现"></a>Handler 实现</h2>
      <p>上面介绍了配置变更通知是如何接收的，实际的处理在 <code>NotificationHandler.processNotification()</code> 中进行，对于动态配置来说， <code>NotificationHandler</code> 接口的实现是类 <code>ConfigChangedNotificationHandler</code>, <code>ConfigChangedNotificationHandler</code> 的 <code>processNotification</code> 会根据配置变更通知版本对配置变更通知内容进行解析，然后调用对应的类型的 <code>ConfigHandler</code> 进行配置更新。</p>
<blockquote>
<ol>
<li>在当前版本中的配置变更通知分为 version1 和 version2 两个版本，不同版本格式不同，以某个 topic 下的某个 clientId 的动态配置为例，version1 的内容为 <code>&#123;&quot;version&quot; : 1, &quot;entity_type&quot;:&quot;topic/client&quot;, &quot;entity_name&quot; : &quot;&lt;topic_name&gt;/&lt;client_id&gt;&quot;&#125;</code>, version2 的内容为 <code>&#123;&quot;version&quot; : 2, &quot;entity_path&quot;:&quot;topic/&lt;topic_name&gt;/client/&lt;client_id&gt;&quot;&#125;</code>  </li>
<li>所有动态配置有默认的 entity_name： <code>&lt;default&gt;</code>，当 entity_name 为 <code>&lt;default&gt;</code> ，表示所有 entity 的默认配置，例如： <code>/config/topics/&lt;default&gt;</code> 中的配置表示所有 topic 的默认动态配置。</li>
</ol>
</blockquote>
<p>下面对 <code>ConfigHandler</code> 的实现类进行简单介绍：</p>
<ol>
<li><p>TopicConfigHandler：<br> 主要处理 3 类配置：<br> a. <code>LogManager</code> 中管理的 topic 配置<br> b. 副本限流配置<br> c. controller 中动态开关配置 <code>&quot;unclean.leader.election.enable&quot;</code></p>
</li>
<li><p>ClientIdConfigHandler 和 UserConfigHandler：<br> 都继承自 <code>QuotaConfigHandler</code>，用来更新客户端侧的限流配置，<code>ClientIdConfigHandler</code> 负责 client id 维度的限流配置更新， <code>UserConfigHandler</code> 用来负责用户维度的限流配置更新</p>
</li>
<li><p>IpConfigHandler：<br> 负责连接维度 <code>ConnectionQuotas</code> 的限流配置更新</p>
</li>
<li><p>BrokerConfigHandler：<br> 一方面负责 broker 相关的 quota 配置，另一方面负责 broker 动态配置的更新。broker 的动态配置逻辑在类 <code>DynamicBrokerConfig</code> 中实现，主要逻辑是根据以下优先级顺序进行 broker 配置的更新和覆盖：<br> a. DYNAMIC_BROKER_CONFIG：存储在 ZK 中的 <code>/configs/brokers/&#123;brokerId&#125;</code><br> b. DYNAMIC_DEFAULT_BROKER_CONFIG：存储在 ZK 中的 <code>/configs/brokers/&lt;default&gt;</code><br> c. STATIC_BROKER_CONFIG：broker 启动配置，通常来自 server.properties 文件<br> d. DEFAULT_CONFIG：<code>KafkaConfig</code> 中硬编码的默认配置</p>
</li>
</ol>

        <h2 id="其它补充"   >
          <a href="#其它补充" class="heading-link"><i class="fas fa-link"></i></a><a href="#其它补充" class="headerlink" title="其它补充"></a>其它补充</h2>
      <p>在 broker 初始化 partition 的过程中，该 topic 的配置可能会发生变化，为了避免漏掉这部分配置的更新，会在 <code>createLog</code> 过程中记录配置变更的情况，在 <code>createLog</code> 结束后处理这部分配置的更新， 具体可以参考：<span class="exturl"><a class="exturl__link"   href="https://issues.apache.org/jira/browse/KAFKA-8813" >https://issues.apache.org/jira/browse/KAFKA-8813</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka 和 Pulsar 的 Compaction 实现</title>
    <url>/2022/05/01/Kafka-%E5%92%8C-Pulsar-%E7%9A%84-Compaction-%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<p>本文主要对 Kafka 和 Pulsar 的 Log Compaction 原理进行介绍，并以我的理解进行简单的对比说明。</p>
<p>&lt;– more –&gt;</p>
<p>在 Kafka 和 Pulsar 中，都具备 Log Campaction（日志挤压）的能力，Compaction 不同于 Log Compression（日志压缩），Compaction 是指将 Topic 历史日志中相同 Key 的消息只保留最新的一条，而 Compression 是指消息维度利用各种压缩算法（如：gzip、lz4、zstd等）减小消息大小但不改变消息内容。Compaction 的使用场景的特点：一是消息有 key，二是相同 key 的消息只关心最新的内容，例如：记录每支股票价格变动的 Topic，股票名称设置为 key，股票价格设置为 value，一般只关心股票的最新价格。在这种场景下，配置 Compaction 可以让 Topic 存储的数据更少，从而在需要全量读取 Topic 内容时速度更快。</p>

        <h2 id="Kafka-Log-Compaction"   >
          <a href="#Kafka-Log-Compaction" class="heading-link"><i class="fas fa-link"></i></a><a href="#Kafka-Log-Compaction" class="headerlink" title="Kafka Log Compaction"></a>Kafka Log Compaction</h2>
      <blockquote>
<p>本文介绍基于 Kafka 2.8，并且忽略了幂等消息、事务消息的相关处理逻辑，如有兴趣，可以自行阅读源码了解。</p>
</blockquote>
<p>在 Kafka 中，Topic 配置 <code>cleanup.policy</code>用来控制 Topic 的数据清理策略，该配置的可选值有两个：一个是<code>delete</code>，表示 Topic 中数据超过保留时间或保留大小限制时，直接删除最旧的数据；另一个是<code>compact</code>，表示对于 Topic 中的旧数据（非 Active Segment 中的数据）执行挤压，一定范围内，对于 key 相同（没有 key 的消息会被删除）的消息，只保留最新的一条。对于每个 Topic 可以选择一种清理策略进行配置，也可以同时配置两种策略。本文介绍的是 <code>compact</code>这个策略，在 Kafka 使用过程中，用来存放 commit offset 信息的的内部 Topic:<code>__consumer_offsets</code> 会被配置为该策略，普通 Topic 一般很少使用。</p>

        <h3 id="实现原理"   >
          <a href="#实现原理" class="heading-link"><i class="fas fa-link"></i></a><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3>
      <p>对于一台 Kafka Broker， Log Compaction 的主要流程如下：</p>
<ol>
<li>创建 LogCleaner，启动配置指定数量的 CleanerThread，负责该 Broker 的 Log Compaction。</li>
<li>每个 CleanerThread 循环执行日志清理工作，循环过程如下：<ol>
<li>寻找一个待清理的 TopicPartition。</li>
<li>遍历该TopicPartition 中所有待清理的 Segment，构造 OffsetMap 记录每个 key 最新的 offset 及对应的消息时间。</li>
<li>对该TopicPartition 中所有待清理的 Segment 进行分组，保证每组 Segment 的 Log 文件总大小和 Index 文件总大小不会超过 LogConfig 允许的范围并且每组 Segment 的 offset 极差不会超过<code>Int.MaxValue</code>（Kafka 中 Segment 内的相对 offset 为整型，这个检查是为了避免相对 offset 溢出）。</li>
<li>将 Segment 按照分好的组进行清理，每一组 Segment 聚合为一个新的 Segment。每组 Segment 的清理过程为：创建一个新的 Segment，然后根据 OffsetMap 中记录的信息选择需要保留的消息，存入新 Segment，最后使用新 Segment 覆盖这一组旧 Segment。</li>
<li>对于所有已经执行完成 Compaction 流程并且<code>cleanup.policy</code>配置包含<code>compact</code>策略的 Log 进行删除，本次删除不是前面用一个新 Segment 替换一组旧 Segment 中的删除，而是调用<code>Log.deleteOldSegments</code>。该方法会删除<code>LogStartOffset</code>之前的所有 Segment，如果<code>cleanup.policy</code>配置同时还包含<code>delete</code>策略，也会删除超过保留时间或保留大小限制的 Segment。</li>
</ol>
</li>
</ol>

        <h3 id="详细说明"   >
          <a href="#详细说明" class="heading-link"><i class="fas fa-link"></i></a><a href="#详细说明" class="headerlink" title="详细说明"></a>详细说明</h3>
      <p>下面以Q&amp;A的方式介绍日志清理的细节和逻辑：</p>

        <h4 id="多个-CleanerThread-是如何保证-Compaction-过程线程安全的"   >
          <a href="#多个-CleanerThread-是如何保证-Compaction-过程线程安全的" class="heading-link"><i class="fas fa-link"></i></a><a href="#多个-CleanerThread-是如何保证-Compaction-过程线程安全的" class="headerlink" title="多个 CleanerThread 是如何保证 Compaction 过程线程安全的?"></a>多个 CleanerThread 是如何保证 Compaction 过程线程安全的?</h4>
      <p>Kafka 中 Log Compaction 的实现主要是<code>LogCleaner</code>和<code>LogCleanerManager</code>两个类，<code>LogCleaner</code>是 Compaction 工作的主类，负责整体的工作流程，<code>LogCleanerManager</code>负责 Compaction 状态机的管理。所有状态如下：</p>
<p><img src="https://s3.bmp.ovh/imgs/2022/04/29/52b607617aa123f4.png"></p>
<ol>
<li><code>None</code> ：TopicPartition 未清理状态。</li>
<li><code>LogCleaningInProgress</code> ：清理正在进行中，当 TopicPartition 被选中为待清理 Log 时会变为该状态。</li>
<li><code>LogCleaningAborted</code> ：清理中止，这是一个从<code>LogCleaningInProgress</code>到<code>LogCleaningPaused(1)</code>的中间状态，在外部发生 truncate、坏盘等情况时需要放弃现在正在的清理操作， 终止后该 TopicPartition 会标记为 <code>LogCleaningAborted</code>。</li>
<li><code>LogCleaningPaused(i)</code>：清理暂停，i 的初始值为1，这是一个重入的状态，即：如果当前状态是<code>LogCleaningPaused(i)</code>，再次暂停该 TopicPartition 的话，状态会变为<code>LogCleaningPaused(i+1)</code>，从暂停状态恢复的话，状态会变为<code>LogCleaningPaused(i-1)</code>（i-1=0 时直接变为<code>None</code>状态）。会触发状态变为<code>LogCleaningPaused(i)</code>的情况如下（下面的“暂停”和“暂停恢复”分别代表 i + 1 和 i - 1）：<ol>
<li>Topic 配置<code>cleanup.policy</code>不包含<code>compact</code>：暂停</li>
<li>外部发生 truncate、坏盘等情况时该 TopicPartition 状态为<code>None</code>或<code>LogCleaningPaused(i)</code>：暂停</li>
<li>本轮清理完成且该 TopicPartition 状态为<code>LogCleaningAborted</code>：暂停</li>
<li>触发暂停的操作完成：暂停恢复</li>
</ol>
</li>
</ol>
<blockquote>
<p>我理解中止状态和暂停状态的区别是：是否可以在本轮清理中恢复。在外部发生 truncate、坏盘等情况时，如果一个 TopicPartition 没有处于清理过程中，可以标记为暂停，在触发暂停的情况结束后，恢复清理流程就会重新执行清理流程。但是如果该 TopicPartition 处于清理过程中，则必须标记为终止，在触发暂停的情况结束后，即使本轮清理没结束，也必须要先标记为暂停，在下轮操作进行清理。这是因为如果已经在清理过程中了，本轮清理会有一些中间态的信息，不容易从中间态进行恢复。</p>
</blockquote>
<p>对于每个 CleanerThread，每次都会通过<code>LogCleanerManager.grabFilthiestCompactedLog</code>方法来搜索状态为<code>None</code>并且需要被清理的 TopicPartition 进行清理。<code>LogCleanerManager</code>中的所有状态变更都会加锁，保证状态机是线程安全的，多个 CleanerThread 通过该状态机保证了所有 TopicPartition 的 Compaction 过程是线程安全的。</p>

        <h4 id="如何决定哪些-TopicPartition-应该被清理（LogCleanerManager-grabFilthiestCompactedLog的详细流程）"   >
          <a href="#如何决定哪些-TopicPartition-应该被清理（LogCleanerManager-grabFilthiestCompactedLog的详细流程）" class="heading-link"><i class="fas fa-link"></i></a><a href="#如何决定哪些-TopicPartition-应该被清理（LogCleanerManager-grabFilthiestCompactedLog的详细流程）" class="headerlink" title="如何决定哪些 TopicPartition 应该被清理（LogCleanerManager.grabFilthiestCompactedLog的详细流程）?"></a>如何决定哪些 TopicPartition 应该被清理（<code>LogCleanerManager.grabFilthiestCompactedLog</code>的详细流程）?</h4>
      <p>可以清理的 TopicPartition 限制条件有以下几个：</p>
<ul>
<li><p>Topic 配置<code>cleanup.policy</code>包含<code>compact</code>。</p>
</li>
<li><p>TopicPartition 的状态为空：说明没有其他 CleanerThread 操作该 TopicPartition。</p>
</li>
<li><p>该 TopicPartition 是可以清理的：因为坏盘等问题某些 TopicPartition 会被标记为不可清理，需要跳过。</p>
</li>
<li><p>不需要延迟清理：消息在日志中必须存在<code>&quot;max.compaction.lag.ms&quot;</code>指定的时间后才能被删除（详情可参考<span class="exturl"><a class="exturl__link"   href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-354" >KIP-354</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>），只有第一个未压缩 Segment 的估计最早消息时间戳早于<code>&quot;max.compaction.lag.ms&quot;</code>才会可以进行 Compaction。</p>
</li>
<li><p>需要被清理的消息总大小大于0：从 LogStartOffset 或 CleanCheckPoint 开始到满足<code>&quot;max.compaction.lag.ms&quot;</code>配置要求的 offset 之间的消息总大小</p>
</li>
<li><p>满足清理频率满足要求：有关清理频率的配置可以直接看下面源码 Doc</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MIN_COMPACTION_LAG_MS_CONFIG = <span class="string">&quot;min.compaction.lag.ms&quot;</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MIN_COMPACTION_LAG_MS_DOC = <span class="string">&quot;The minimum time a message will remain &quot;</span> +</span><br><span class="line">    <span class="string">&quot;uncompacted in the log. Only applicable for logs that are being compacted.&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MAX_COMPACTION_LAG_MS_CONFIG = <span class="string">&quot;max.compaction.lag.ms&quot;</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MAX_COMPACTION_LAG_MS_DOC = <span class="string">&quot;The maximum time a message will remain &quot;</span> +</span><br><span class="line">    <span class="string">&quot;ineligible for compaction in the log. Only applicable for logs that are being compacted.&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MIN_CLEANABLE_DIRTY_RATIO_CONFIG = <span class="string">&quot;min.cleanable.dirty.ratio&quot;</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String MIN_CLEANABLE_DIRTY_RATIO_DOC = <span class="string">&quot;This configuration controls how frequently &quot;</span> +</span><br><span class="line">    <span class="string">&quot;the log compactor will attempt to clean the log (assuming &lt;a href=\&quot;#compaction\&quot;&gt;log &quot;</span> +</span><br><span class="line">    <span class="string">&quot;compaction&lt;/a&gt; is enabled). By default we will avoid cleaning a log where more than &quot;</span> +</span><br><span class="line">    <span class="string">&quot;50% of the log has been compacted. This ratio bounds the maximum space wasted in &quot;</span> +</span><br><span class="line">    <span class="string">&quot;the log by duplicates (at 50% at most 50% of the log could be duplicates). A &quot;</span> +</span><br><span class="line">    <span class="string">&quot;higher ratio will mean fewer, more efficient cleanings but will mean more wasted &quot;</span> +</span><br><span class="line">    <span class="string">&quot;space in the log. If the &quot;</span> + MAX_COMPACTION_LAG_MS_CONFIG + <span class="string">&quot; or the &quot;</span> + MIN_COMPACTION_LAG_MS_CONFIG +</span><br><span class="line">    <span class="string">&quot; configurations are also specified, then the log compactor considers the log to be eligible for compaction &quot;</span> +</span><br><span class="line">    <span class="string">&quot;as soon as either: (i) the dirty ratio threshold has been met and the log has had dirty (uncompacted) &quot;</span> +</span><br><span class="line">    <span class="string">&quot;records for at least the &quot;</span> + MIN_COMPACTION_LAG_MS_CONFIG + <span class="string">&quot; duration, or (ii) if the log has had &quot;</span> +</span><br><span class="line">    <span class="string">&quot;dirty (uncompacted) records for at most the &quot;</span> + MAX_COMPACTION_LAG_MS_CONFIG + <span class="string">&quot; period.&quot;</span>;</span><br></pre></td></tr></table></div></figure></li>
</ul>

        <h4 id="OffsetMap-的实现原理"   >
          <a href="#OffsetMap-的实现原理" class="heading-link"><i class="fas fa-link"></i></a><a href="#OffsetMap-的实现原理" class="headerlink" title="OffsetMap 的实现原理"></a>OffsetMap 的实现原理</h4>
      <p>OffsetMap 的实现类是<code>SkimpyOffsetsMap</code>，用来存储 message key 和 offset 的映射关系，用来保存相同 key 下最新消息的 Offset。此处不介绍该类的详细实现（感兴趣自行阅读<span class="exturl"><a class="exturl__link"   href="https://github.com/apache/kafka/blob/2.8/core/src/main/scala/kafka/log/OffsetMap.scala" >源码</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>），只列举其特点：</p>
<ul>
<li>创建时需要指定两个参数，一个是 memory，用来指定存储 offset 的 ByteBuffer 大小，另一个是 hashAlgorithm，用来确定计算 key hash 时使用的哈希算法。</li>
<li>只允许增加，不允许删除。</li>
<li>只在 ByteBuffer 中存储需要记录的 offset，每次 put/get 都是先对 key hash 确定 position，然后直接修改/读取 ByteBuffer 中的内容。</li>
</ul>
<blockquote>
<p>我理解该实现的主要优点是避免存储 message key，减少内存消耗。</p>
</blockquote>

        <h4 id="如何从一组旧的-Segment-中过滤出需要保留的消息以及过滤策略是怎样的"   >
          <a href="#如何从一组旧的-Segment-中过滤出需要保留的消息以及过滤策略是怎样的" class="heading-link"><i class="fas fa-link"></i></a><a href="#如何从一组旧的-Segment-中过滤出需要保留的消息以及过滤策略是怎样的" class="headerlink" title="如何从一组旧的 Segment 中过滤出需要保留的消息以及过滤策略是怎样的?"></a>如何从一组旧的 Segment 中过滤出需要保留的消息以及过滤策略是怎样的?</h4>
      <p>过滤消息的流程是，先将旧 Segment 中的消息读入MemoryRecords，然后使用<code>MemoryRecords.filterTo</code>方法进行过滤，该方法支持使用自定义实现的 <code>RecordFilter</code> 过滤消息。</p>
<p>消息过滤的策略（实际会有事务消息的处理）是：过滤掉相同 key 中非最新 offset 的消息以及满足删除条件的<strong>墓碑消息</strong>（key 不为 null 但是 value 为 null）。墓碑消息的删除条件是指，该墓碑消息所在的 Segment 最后修改时间距离最新 Segment 的最后修改时间超过<code>delete.retention.ms</code>配置的时间。</p>

        <h4 id="如果-Compaction-过程中-Broker-崩溃，重启后如何恢复"   >
          <a href="#如果-Compaction-过程中-Broker-崩溃，重启后如何恢复" class="heading-link"><i class="fas fa-link"></i></a><a href="#如果-Compaction-过程中-Broker-崩溃，重启后如何恢复" class="headerlink" title="如果 Compaction 过程中 Broker 崩溃，重启后如何恢复?"></a>如果 Compaction 过程中 Broker 崩溃，重启后如何恢复?</h4>
      <p>宕机恢复的考虑只发生在用新 Segment（文件名后缀是<code>.cleaned</code>） 替换旧 Segment 的过程中，其他阶段发生宕机的话，恢复后重新执行 Compaction 流程即可。</p>
<p>Segment 替换操作使用<code>replaceSegments</code>方法（源码如下）完成，替换流程是：</p>
<ol>
<li>将新 Segment 的文件名后缀从<code>.cleaned</code>改为<code>.swap</code></li>
<li>删除旧 Segment：删除过程是先将同步将文件后缀改为<code>.deleted</code>，然后进行异步删除</li>
<li>去掉新 Segment 的文件名后缀，流程结束</li>
</ol>
<p>下面是对于所有可能的阶段 Broker 崩溃后的恢复逻辑：</p>
<ul>
<li>步骤1之前：如果此时 broker 崩溃，则清理和交换操作将中止，并且在 <code>loadSegments() </code>中恢复时删除 <code>.cleaned</code> 文件。</li>
<li>步骤1执行过程中崩溃：新 Segment 重命名为 <code>.swap</code>。如果代理在所有 Segment 重命名为 <code>.swap</code> 之前崩溃，则清理和交换操作将中止 <code>.cleaned</code> 以及 <code>.swap</code> 文件在 <code>loadSegments()</code> 恢复时被删除。 <code>.cleaned</code> 重命名为 <code>.swap</code> 是按照文件按偏移量的降序进行的，恢复时，所有偏移量大于最小偏移量 <code>.clean</code>文件的<code>.swap</code> 文件都将被删除。</li>
<li>步骤1完成后崩溃：如果在所有新 Segment 重命名为 <code>.swap</code> 后代理崩溃，则操作完成，剩余操作流程会在 Broker 恢复时继续执行。</li>
<li>步骤2执行过程中崩溃：旧 Segment 文件被重命名为 <code>.deleted</code> 并安排了异步删除。如果 Broker 崩溃，任何留下的 <code>.deleted</code> 文件都会在 <code>loadSegments()</code> 恢复时被删除，然后调用 <code>replaceSegments()</code> 以完成替换，其中新 Segment 从 <code>.swap</code> 文件重新创建，旧 Segment 包含在崩溃前未重命名的 Segment。</li>
<li>步骤3完成后崩溃：此时可能存在未被异步删除完成的旧 Segment，任何可能留下的 <code>.deleted</code> 文件都会在 <code>loadSegments()</code> 恢复时被删除</li>
</ul>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span>[log] <span class="function"><span class="keyword">def</span> <span class="title">replaceSegments</span></span>(newSegments: <span class="type">Seq</span>[<span class="type">LogSegment</span>], oldSegments: <span class="type">Seq</span>[<span class="type">LogSegment</span>], isRecoveredSwapFile: <span class="type">Boolean</span> = <span class="literal">false</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">    lock synchronized &#123;</span><br><span class="line">      <span class="keyword">val</span> sortedNewSegments = newSegments.sortBy(_.baseOffset)</span><br><span class="line">      <span class="comment">// Some old segments may have been removed from index and scheduled for async deletion after the caller reads segments</span></span><br><span class="line">      <span class="comment">// but before this method is executed. We want to filter out those segments to avoid calling asyncDeleteSegment()</span></span><br><span class="line">      <span class="comment">// multiple times for the same segment.</span></span><br><span class="line">      <span class="keyword">val</span> sortedOldSegments = oldSegments.filter(seg =&gt; segments.containsKey(seg.baseOffset)).sortBy(_.baseOffset)</span><br><span class="line"></span><br><span class="line">      checkIfMemoryMappedBufferClosed()</span><br><span class="line">      <span class="comment">// need to do this in two phases to be crash safe AND do the delete asynchronously</span></span><br><span class="line">      <span class="comment">// if we crash in the middle of this we complete the swap in loadSegments()</span></span><br><span class="line">      <span class="keyword">if</span> (!isRecoveredSwapFile)</span><br><span class="line">        sortedNewSegments.reverse.foreach(_.changeFileSuffixes(<span class="type">Log</span>.<span class="type">CleanedFileSuffix</span>, <span class="type">Log</span>.<span class="type">SwapFileSuffix</span>))</span><br><span class="line">      sortedNewSegments.reverse.foreach(addSegment(_))</span><br><span class="line">      <span class="keyword">val</span> newSegmentBaseOffsets = sortedNewSegments.map(_.baseOffset).toSet</span><br><span class="line"></span><br><span class="line">      <span class="comment">// delete the old files</span></span><br><span class="line">      sortedOldSegments.foreach &#123; seg =&gt;</span><br><span class="line">        <span class="comment">// remove the index entry</span></span><br><span class="line">        <span class="keyword">if</span> (seg.baseOffset != sortedNewSegments.head.baseOffset)</span><br><span class="line">          segments.remove(seg.baseOffset)</span><br><span class="line">        <span class="comment">// delete segment files, but do not delete producer state for segment objects which are being replaced.</span></span><br><span class="line">        deleteSegmentFiles(<span class="type">List</span>(seg), asyncDelete = <span class="literal">true</span>, deleteProducerStateSnapshots = !newSegmentBaseOffsets.contains(seg.baseOffset))</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// okay we are safe now, remove the swap suffix</span></span><br><span class="line">      sortedNewSegments.foreach(_.changeFileSuffixes(<span class="type">Log</span>.<span class="type">SwapFileSuffix</span>, <span class="string">&quot;&quot;</span>))</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure>

<hr>

        <h2 id="Pulsar-Compaction"   >
          <a href="#Pulsar-Compaction" class="heading-link"><i class="fas fa-link"></i></a><a href="#Pulsar-Compaction" class="headerlink" title="Pulsar Compaction"></a>Pulsar Compaction</h2>
      <p>Pulsar 官方文档中关于 Compaction 的介绍也比较详细，具体可以参考：</p>
<ul>
<li><span class="exturl"><a class="exturl__link"   href="https://pulsar.apache.org/docs/zh-CN/next/concepts-topic-compaction/#compaction" >https://pulsar.apache.org/docs/zh-CN/next/concepts-topic-compaction/#compaction</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li><span class="exturl"><a class="exturl__link"   href="https://pulsar.apache.org/docs/zh-CN/next/cookbooks-compaction/" >https://pulsar.apache.org/docs/zh-CN/next/cookbooks-compaction/</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li><span class="exturl"><a class="exturl__link"   href="https://github.com/ivankelly/incubator-pulsar-wiki/blob/pip-9/PIP-9:-Topic-Compaction.md" >https://github.com/ivankelly/incubator-pulsar-wiki/blob/pip-9/PIP-9:-Topic-Compaction.md</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
</ul>
<p>在 Pulsar 中，Topic Compaction 与 NonCompaction 两个状态不是相互对立的，Compaction 是通过类似于创建一个Subscription 来消费现有 Topic 的消息，经过 Compaction 处理后，写入新的 Ledger 存储，在 Consumer 消费时，可以通过配置选择读取 Compacted 数据还是 NonCompacted 数据。注意：Compact 只能对 persistent topic 执行。</p>

        <h3 id="触发条件"   >
          <a href="#触发条件" class="heading-link"><i class="fas fa-link"></i></a><a href="#触发条件" class="headerlink" title="触发条件"></a>触发条件</h3>
      <p>Pulsar 中触发 Topic Compaction 的方式有两种：</p>
<ol>
<li>配置<code>CompactionThreshold</code>：如前面所说，Compaction 过程相当于建立一个 Subscription 来消费原来 Topic 中的数据写入新的 Ledger，Broker 会周期性检查所有 Persistent Topic，如果<code>CompactionThreshold</code>配置不为0并且这个 Subscription 的消息积压超过了配置的阈值，就会自动触发 Compaction。这个配置的粒度可以是 topic、broker、namespace，最终根据优先级（topic &gt; broker &gt; namespace）确定最终配置值。</li>
<li>外部触发 Topic Compaction：除自动触发 Compaction 外，也可以通过 CLI 工具触发，一种是 AdminCli，需要调用 broker 提供的 RestAPI，另一种是使用专用工具类，不经过 RestAPI 直接指定。</li>
</ol>
<figure class="highlight shell"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> bin/pulsar-admin topics compact persistent://my-tenant/my-namespace/my-topic <span class="comment"># AdminCli</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash"> bin/pulsar compact-topic --topic persistent://my-tenant-namespace/my-topic <span class="comment"># 专用工具</span></span></span><br></pre></td></tr></table></div></figure>


        <h3 id="实现原理-1"   >
          <a href="#实现原理-1" class="heading-link"><i class="fas fa-link"></i></a><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h3>
      <p>实现原理总体可以分为 Compaction 的处理过程和 Consumer 读取 Compacted 数据两个部分。</p>

        <h4 id="Compaction-处理"   >
          <a href="#Compaction-处理" class="heading-link"><i class="fas fa-link"></i></a><a href="#Compaction-处理" class="headerlink" title="Compaction 处理"></a>Compaction 处理</h4>
      <p>触发 Compaction 的统一入口是<code>Compactor.compact(String topic)</code>方法，<code>Compactor</code>是一个抽象类，目前的实现只有<code>TwoPhaseCompactor</code>一种，下面介绍的是<code>TwoPhaseCompactor</code>的实现逻辑。顾名思义，Compaction 过程分为两个阶段，遍历两次 Topic 内容，第一次遍历用来获取每个 key 中最新的 MessageId（相当于 Kafka 中的 offset），第二次遍历根据第一次遍历取得的结果，只将每个 key 的最新消息写入新的 Ledger 中。</p>

        <h4 id="读取-Compacted-数据"   >
          <a href="#读取-Compacted-数据" class="heading-link"><i class="fas fa-link"></i></a><a href="#读取-Compacted-数据" class="headerlink" title="读取 Compacted 数据"></a>读取 Compacted 数据</h4>
      <p>如果 Consumer 希望读取 Compacted 数据，需要在初始化时制定相关配置。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line">Consumer&lt;<span class="keyword">byte</span>[]&gt; compactedTopicConsumer = client.newConsumer()</span><br><span class="line">        .topic(<span class="string">&quot;some-compacted-topic&quot;</span>)</span><br><span class="line">        .readCompacted(<span class="keyword">true</span>)</span><br><span class="line">        .subscribe();</span><br></pre></td></tr></table></div></figure>

<p>Broker 在收到 Consumer 的请求后，会先获取到 Topic 对应的 cursor 信息，然后从 cursor 信息中找到 Compacted 数据对应的 LedgerId，然后进行对应数据的读取。</p>

        <h4 id="Compacted-Leger-信息如何传递给-Consumer？"   >
          <a href="#Compacted-Leger-信息如何传递给-Consumer？" class="heading-link"><i class="fas fa-link"></i></a><a href="#Compacted-Leger-信息如何传递给-Consumer？" class="headerlink" title="Compacted Leger 信息如何传递给 Consumer？"></a>Compacted Leger 信息如何传递给 Consumer？</h4>
      <p>如前文所说，在<code>TwoPhaseCompactor</code>处理过程中，实际是创建了一个 Subscription 来读取原来的数据。在读取数据完成进行 Ack 时，使用的接口是<code>RawReader.acknowledgeCumulativeAsync(MessageId messageId, Map&lt;String, Long&gt; properties)</code>，该接口可以在 Ack 的同时给 Broker 返回一些该 Subscription 的元信息，Broker 会将收到的元信息记录在 cursor 信息中。所以，<code>TwoPhaseCompactor</code>通过这一能力，将创建的用来存储 Compacted 数据的 LedgerId 记录在了 cursor 信息中，方便 Consumer 读取时使用。</p>

        <h2 id="总结思考"   >
          <a href="#总结思考" class="heading-link"><i class="fas fa-link"></i></a><a href="#总结思考" class="headerlink" title="总结思考"></a>总结思考</h2>
      <p>Kafka 和 Pulsar 中实现 Compaction 的目的是为了在特定的场景下减少 Topic 的数据量，加快获取 Topic 中全部数据的速度，而不是希望实现类似 KV 存储的能力。之所以这样说，是因为：</p>
<ol>
<li>Kafka 和 Pulsar 都没有保证最新数据的 Compaction：对于 Kafka 来说，Log Compaction 只会操作 ActiveSegment 之前的数据；对于 Pulsar 来说，Compaction 是一个周期性执行的工作，每次 Compaction 开始之前，都会先读取当前 Topic 中最后一个 MessageId 作为本轮 Compaction  的终点，因此只要有 Producer 在向 Topic 生产数据。就肯定不能保证所有数据都被 Compacted。</li>
<li>Kafka 和 Pulsar 的 Compaction 都是一定范围内的，不是全局的：Kafka 和 Pulsar 的 Compaction 都是以一种类似于滑动窗口的过程进行，“key 相同的情况下只保留最新的消息”针对的是一轮 Compaction 内，如果两轮 Compaction 中有相同 key 的消息，是没有办法合并的。</li>
</ol>
<p>对比 Kafka 和 Pulsar 两者的实现来看，最主要的区别就是是否保留 Compaction 前的数据。相较于 Kafka 的实现，Pulsar 这种形式一方面整体逻辑更为简单，不需要考虑各种文件替换过程中的崩溃恢复逻辑，另一方面也可以给 Consumer 更多选择的空间，但是这样也会带来一定的存储成本。两者的实现架构是不同的，如果想要 Kafka 也像 Pulsar 一样保留两份数据，由于 Kafka 的存储副本机制是自己的管理的，可能需要比现在更为复杂的实现才能够搞定，而不能像 Pulsar 一样直接通过切换 LedgerId 来选择数据就可以了。</p>
]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Pulsar</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
</search>
