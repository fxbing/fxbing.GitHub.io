<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello World, Hello Blog</title>
    <url>/2019/05/09/2019-05-09-hello-2019/</url>
    <content><![CDATA[
        <h1 id="开门啦"   >
          <a href="#开门啦" class="heading-link"><i class="fas fa-link"></i></a><a href="#开门啦" class="headerlink" title="开门啦"></a>开门啦</h1>
      <blockquote>
<p>万事开头难</p>
</blockquote>
<p>我的博客终于开通了，之后会在这里写一些东西，可能是一些想法，可能是一些笔记，也可能是一些技术文章，总之，希望我的博客可以发展起来！！！</p>
]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title>Pulsar 源码阅读： Retention</title>
    <url>/2019/07/23/2019-07-23-Pulsar-Retention/</url>
    <content><![CDATA[<p>对于已经消费确认的消息，Pulsar 可以通过配置 Retention 策略决定保留的时间及大小。</p>
<p>具体参见官方文档：<span class="exturl"><a class="exturl__link"   href="https://pulsar.apache.org/docs/zh-CN/cookbooks-retention-expiry/#docsNav" >Message retention and expiry</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>Pulsar 源码中有三个部分与 Retention 相关。</p>
<span id="more"></span>



        <h2 id="1-PersistentTopic"   >
          <a href="#1-PersistentTopic" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-PersistentTopic" class="headerlink" title="1. PersistentTopic"></a>1. PersistentTopic</h2>
      <p>在<strong>BrokerService</strong>启动之后，<code>this.startInactivityMonitor();</code>操作会对不活动任务进行定期清理，其中包括 GC 操作：</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">checkGC</span><span class="params">(<span class="keyword">int</span> gcIntervalInSeconds)</span> </span>&#123;</span><br><span class="line">        forEachTopic(topic -&gt; topic.checkGC(gcIntervalInSeconds));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>该操作会对 Broker 中的每个 Topic 进行 GC 检查清理的操作。</p>
<p>其中<code>checkGC()</code>为<code>PersistentTopic</code>类中的实现，如下：</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (isActive()) &#123;</span><br><span class="line">            lastActive = System.nanoTime();</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (System.nanoTime() - lastActive &lt; TimeUnit.SECONDS.toNanos(gcIntervalInSeconds)) &#123;</span><br><span class="line">            <span class="comment">// Gc interval did not expire yet</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (shouldTopicBeRetained()) &#123;</span><br><span class="line">            <span class="comment">// Topic activity is still within the retention period</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line"> &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p><code>shouldTopicBeRetained()</code>函数会对需要 retention 的数据进行检查。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Check whether the topic should be retained (based on time), even tough there are no producers/consumers and it&#x27;s</span></span><br><span class="line"><span class="comment">     * marked as inactive.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">shouldTopicBeRetained</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        TopicName name = TopicName.get(topic);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 从配置缓存中读取配置信息</span></span><br><span class="line">            Optional&lt;Policies&gt; policies = brokerService.pulsar().getConfigurationCache().policiesCache()</span><br><span class="line">                    .get(AdminResource.path(POLICIES, name.getNamespace()));</span><br><span class="line">            <span class="comment">// 如果没有配置信息，默认该 Topic 不需要 Retention ，清理。</span></span><br><span class="line">            <span class="comment">// 如果有配置信息，根据是否超过设定的 Retention 时间选择是否进行清理</span></span><br><span class="line">            <span class="keyword">return</span> policies.map(p -&gt; p.retention_policies).map(rp -&gt; &#123;</span><br><span class="line">                <span class="keyword">long</span> retentionTime = TimeUnit.MINUTES.toNanos(rp.getRetentionTimeInMinutes());</span><br><span class="line">                <span class="keyword">return</span> retentionTime &lt; <span class="number">0</span> || (System.nanoTime() - lastActive) &lt; retentionTime;</span><br><span class="line">            &#125;).orElse(<span class="keyword">false</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">                log.debug(<span class="string">&quot;[&#123;&#125;] Error getting policies&quot;</span>, topic);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Don&#x27;t delete in case we cannot get the policies</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></div></figure>

<p>上面对是否到达 Retention 时间的检查用到了 <code>AbstractTopic</code> 类中的<code>lastActive</code>字段：</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Timestamp of when this topic was last seen active</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">volatile</span> <span class="keyword">long</span> lastActive;</span><br></pre></td></tr></table></div></figure>

<p>该字段在每次移除<code>Producer</code>、移除订阅和执行<code>checkGC()</code>的时候进行更新。这里根据我的理解对两个问题进行解释：</p>
<ol>
<li><p>为什么只在移除的时候更新，而不再加入的时候更新？</p>
<p>lastActive指的是最后的存活时间，所以只有移除所有的producer、consumer之后才可能需要更新。</p>
</li>
<li><p>在每次移除Producer和consumer之后都进行更新，如果保证lastActive就代表了该Topic清空Producer和Consumer的时间？</p>
<p>shiyonglastActive并不能代表这个意思，首先lastActive只在判断是否需要进行GC和是否需要被保留的时候使用（后者是在前者之中调用的），在使用lastActive之前，会执行<code>isActive()</code>函数，该函数是对该Topic是否还有与其连接的Producer和Consumer，所有之后使用lastActive参数时已经保证了<code>isActive()</code>不成立，即：<strong>该Topic上已经不存在Producer和Consumer</strong>了。</p>
</li>
</ol>
<p>以上是BrokerService中进行Topic清理时对**<code>RetentionTime</code>**的使用，这一部分是在清理 Topic 之前根据 Retention 策略决定该 Topic 是否应该被清理。</p>

        <h2 id="2-ManagedLedgerImpl"   >
          <a href="#2-ManagedLedgerImpl" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-ManagedLedgerImpl" class="headerlink" title="2. ManagedLedgerImpl"></a>2. ManagedLedgerImpl</h2>
      <p>Ledger 有关的 Retention 特性是在**<code>ManagedLedgerImpl</code>**类中实现的，下面介绍该部分。</p>
<p>在启动BrokerService的时候，会设置<code>managedLedgerConfig</code>:</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line">managedLedgerConfig.setRetentionTime(retentionPolicies.getRetentionTimeInMinutes(), TimeUnit.MINUTES);</span><br><span class="line">managedLedgerConfig.setRetentionSizeInMB(retentionPolicies.getRetentionSizeInMB());</span><br></pre></td></tr></table></div></figure>

<p>在<code>ManagedLedgerImpl</code>类中，下面的函数会对已经完全被消费（所有消息已经被所有 Consumer 消费和确认过）Ledger进行周期性检查清理，</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">internalTrimConsumedLedgers</span><span class="params">(CompletableFuture&lt;?&gt; promise)</span></span></span><br></pre></td></tr></table></div></figure>

<p>在上面的函数执行过程中，会通过<code>hasLedgerRetentionExpired</code>函数判断该Ledger是否需要被Retention。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">hasLedgerRetentionExpired</span><span class="params">(<span class="keyword">long</span> ledgerTimestamp)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (config.getRetentionTimeMillis() &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// Negative retention time equates to infinite retention</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> elapsedMs = clock.millis() - ledgerTimestamp;</span><br><span class="line">        <span class="keyword">return</span> elapsedMs &gt; config.getRetentionTimeMillis();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>其中<code>ledgerTimestamp</code>参数表示Ledger建立的时间。</p>

        <h2 id="3-NamespaceBase"   >
          <a href="#3-NamespaceBase" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-NamespaceBase" class="headerlink" title="3. NamespaceBase"></a>3. NamespaceBase</h2>
      <p>  还有一个用到<code>Retention</code>的地方是在<code>NamespaceBase</code>类中，可以对存储在Zookeeper中的<code>Retention</code>配置信息进行get和set，它通过<code>Namespaces</code>类中的Restful接口对外提供服务，client中的<code>cmd/namepaces</code>也是通过调用Restful接口实现的对Broker端的配置的修改。</p>
<p>  Retention 属于 Namespace 级别的配置，Namespace 只是一个逻辑上的概念，具体消息的存储是通过 Ledger 进行的（Ledger 是 Pulsar 中增加删除持久化信息的最小单位），所以 Retention 这一特性也是有 Ledger 部分实现的。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Pulsar</tag>
      </tags>
  </entry>
  <entry>
    <title>Pulsar 源码阅读： Backlog</title>
    <url>/2019/08/06/2019-08-06-Pulsar%20Backlog/</url>
    <content><![CDATA[<p>对于<del>已经消费但是</del>没有确认的消息，Pulsar 可以通过配置 BacklogQuota 决定保留大小及丢弃策略。</p>
<p>具体参见官方文档：<span class="exturl"><a class="exturl__link"   href="https://pulsar.apache.org/docs/zh-CN/cookbooks-retention-expiry/#docsNav" >Message retention and expiry</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>当 Backlog 大小未达到限额时，不需要处理，当 Backlog 大小超限时，根据丢弃策略进行处理。</p>
<p>BacklogQuota 的丢弃策略一共有三种：</p>
<ol>
<li><code>producer_request_hold</code>：① 断开所有的 Producer ② 在新建 Producer 时进行检查，如果超出 BacklogQuota，则拒绝新建请求并等待超时（异步返回结果调用<code>get()</code>时才抛出异常）</li>
<li><code>producer_exception</code>：① 断开所有的 Producer ② 在新建 Producer 时进行检查，如果超出 BacklogQuota，则拒绝新建请求并抛出异常</li>
<li><code>consumer_backlog_eviction</code>：丢弃最早的 Backlog</li>
</ol>
<span id="more"></span>



        <h2 id="BacklogQuotaManager"   >
          <a href="#BacklogQuotaManager" class="heading-link"><i class="fas fa-link"></i></a><a href="#BacklogQuotaManager" class="headerlink" title="BacklogQuotaManager"></a>BacklogQuotaManager</h2>
      <p>Pulsar 中有<code>BacklogQuotaManager</code>用来进行 Backlog 处理，有下面几个关键函数。</p>

        <h3 id="handleExceededBacklogQuota"   >
          <a href="#handleExceededBacklogQuota" class="heading-link"><i class="fas fa-link"></i></a><a href="#handleExceededBacklogQuota" class="headerlink" title="handleExceededBacklogQuota"></a><code>handleExceededBacklogQuota</code></h3>
      <p>该函数用来处理 Backlog 超限的情况，对于<code>consumer_backlog_eviction</code>策略，调用<code>dropBacklog(persistentTopic, quota);</code>；对于<code>producer_exception</code>和<code>producer_request_hold</code>两种策略，调用<code>disconnectProducers(persistentTopic);</code></p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handleExceededBacklogQuota</span><span class="params">(PersistentTopic persistentTopic)</span> </span>&#123;</span><br><span class="line">        TopicName topicName = TopicName.get(persistentTopic.getName());</span><br><span class="line">        String namespace = topicName.getNamespace();</span><br><span class="line">        String policyPath = AdminResource.path(POLICIES, namespace);</span><br><span class="line"></span><br><span class="line">        BacklogQuota quota = getBacklogQuota(namespace, policyPath);</span><br><span class="line">        log.info(<span class="string">&quot;Backlog quota exceeded for topic [&#123;&#125;]. Applying [&#123;&#125;] policy&quot;</span>, persistentTopic.getName(),</span><br><span class="line">                quota.getPolicy());</span><br><span class="line">        <span class="keyword">switch</span> (quota.getPolicy()) &#123;</span><br><span class="line">        <span class="keyword">case</span> consumer_backlog_eviction:</span><br><span class="line">            dropBacklog(persistentTopic, quota);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> producer_exception:</span><br><span class="line">        <span class="keyword">case</span> producer_request_hold:</span><br><span class="line">            disconnectProducers(persistentTopic);</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>下面介绍<code>dropBacklog(persistentTopic, quota);</code>和<code>disconnectProducers(persistentTopic);</code>两个函数。</p>

        <h3 id="dropBacklog-persistentTopic-quota"   >
          <a href="#dropBacklog-persistentTopic-quota" class="heading-link"><i class="fas fa-link"></i></a><a href="#dropBacklog-persistentTopic-quota" class="headerlink" title="dropBacklog(persistentTopic, quota)"></a><code>dropBacklog(persistentTopic, quota)</code></h3>
      <p><code>dropBacklog(persistentTopic, quota);</code>函数负责在 Backlog 超限之后对 Backlog 中最早的消息进行丢弃，这里的丢弃实际是指<strong>向后移动未确认消息的起始标记</strong>（该 Topic 上最慢的 Consumer 的位置）。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">dropBacklog</span><span class="params">(PersistentTopic persistentTopic, BacklogQuota quota)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 设置丢弃比例为 0.9 ，即丢弃任务完成之后 Backlog 大小变为 Backlog 限额的 90%</span></span><br><span class="line">        <span class="keyword">double</span> reductionFactor = <span class="number">0.9</span>;</span><br><span class="line">        <span class="keyword">double</span> targetSize = reductionFactor * quota.getLimit();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取 Backlog 大小的估计值，这里不直接使用 Ledger 的实际大小是因为 Ledger 不一定会被及时清理，实际大小会大于 Backlog 的大小</span></span><br><span class="line">        ManagedLedgerImpl mLedger = (ManagedLedgerImpl) persistentTopic.getManagedLedger();</span><br><span class="line">        <span class="keyword">long</span> backlogSize = mLedger.getEstimatedBacklogSize(); <span class="comment">//这个函数后面介绍</span></span><br><span class="line"></span><br><span class="line">        ManagedCursor previousSlowestConsumer = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span> (backlogSize &gt; targetSize) &#123;</span><br><span class="line">            <span class="comment">// 最慢的 Consumer</span></span><br><span class="line">            ManagedCursor slowestConsumer = mLedger.getSlowestConsumer();</span><br><span class="line">            <span class="keyword">if</span> (slowestConsumer == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 需要跳过的比例</span></span><br><span class="line">            <span class="keyword">double</span> messageSkipFactor = ((backlogSize - targetSize) / backlogSize);</span><br><span class="line">            <span class="comment">// Cursor 没有移动，不需要执行清理</span></span><br><span class="line">            <span class="keyword">if</span> (slowestConsumer == previousSlowestConsumer) &#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 计算需要移动的距离</span></span><br><span class="line">            <span class="keyword">long</span> entriesInBacklog = slowestConsumer.getNumberOfEntriesInBacklog();</span><br><span class="line">            <span class="keyword">int</span> messagesToSkip = (<span class="keyword">int</span>) (messageSkipFactor * entriesInBacklog);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (messagesToSkip == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 移动 slowestConsumer 位置</span></span><br><span class="line">                slowestConsumer.skipEntries(messagesToSkip, IndividualDeletedEntries.Include);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                log.error(<span class="string">&quot;Error skipping [&#123;&#125;] messages from slowest consumer : [&#123;&#125;]&quot;</span>, messagesToSkip,</span><br><span class="line">                        slowestConsumer.getName());</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 移动完成之后更新 backlogSize，再次执行上面的流程，确保移动之后 Backlog 没有再次超限</span></span><br><span class="line">            backlogSize = mLedger.getEstimatedBacklogSize();</span><br><span class="line">            previousSlowestConsumer = slowestConsumer;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>这里用到了一个<code>ManagedLedgerImpl</code>类中的一个函数<code>getEstimatedBacklogSize()</code>，用来估计 Backlog的大小。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getEstimatedBacklogSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="comment">// 未确认消息的起始标记</span></span><br><span class="line">        PositionImpl pos = getMarkDeletePositionOfSlowestConsumer();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (pos == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">long</span> size = <span class="number">0</span>; <span class="comment">// Backlog 大小</span></span><br><span class="line">            <span class="keyword">final</span> <span class="keyword">long</span> slowestConsumerLedgerId = pos.getLedgerId();</span><br><span class="line"></span><br><span class="line">            <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">                <span class="comment">// 获取所有 Ledger 总大小</span></span><br><span class="line">                size = getTotalSize();</span><br><span class="line">                <span class="comment">// 减去没有及时清理的 Ledger 的大小</span></span><br><span class="line">                size -= ledgers.values().stream().filter(li -&gt; li.getLedgerId() &lt; slowestConsumerLedgerId)</span><br><span class="line">                        .mapToLong(li -&gt; li.getSize()).sum();</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            LedgerInfo ledgerInfo = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">synchronized</span> (<span class="keyword">this</span>) &#123;</span><br><span class="line">                ledgerInfo = ledgers.get(pos.getLedgerId());</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (ledgerInfo == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 如果 pos 指向的 Ledger 已经被删除，但是删除标记还没有更新（每次启动新的 manageLedger 时才会更新），就直接返回结果</span></span><br><span class="line">                <span class="keyword">if</span> (pos.compareTo(getMarkDeletePositionOfSlowestConsumer()) == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="keyword">return</span> size;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 如果删除标记已经更新，说明当前 pos 指向的 Ledger 已经被完全清理，则需要更新 pos 进行重试</span></span><br><span class="line">                pos = getMarkDeletePositionOfSlowestConsumer();</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">long</span> numEntries = pos.getEntryId();</span><br><span class="line">            <span class="comment">// consumedLedgerSize()第三个参数需要作为除数，不能为 0</span></span><br><span class="line">            <span class="keyword">if</span> (ledgerInfo.getEntries() == <span class="number">0</span>) &#123;</span><br><span class="line">                size -= consumedLedgerSize(currentLedgerSize, currentLedgerEntries, numEntries);</span><br><span class="line">                <span class="keyword">return</span> size;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                size -= consumedLedgerSize(ledgerInfo.getSize(), ledgerInfo.getEntries(), numEntries);</span><br><span class="line">                <span class="keyword">return</span> size;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">consumedLedgerSize</span><span class="params">(<span class="keyword">long</span> ledgerSize, <span class="keyword">long</span> ledgerEntries, <span class="keyword">long</span> consumedEntries)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (ledgerEntries &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    	<span class="comment">// 计算平均 Entry 大小</span></span><br><span class="line">        <span class="keyword">long</span> averageSize = ledgerSize / ledgerEntries;</span><br><span class="line">    	<span class="comment">// Entry Id 的起始编号为 -1，所以这里需要 +1</span></span><br><span class="line">        <span class="keyword">return</span> consumedEntries &gt;= <span class="number">0</span> ? (consumedEntries + <span class="number">1</span>) * averageSize : <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="disconnectProducers-persistentTopic"   >
          <a href="#disconnectProducers-persistentTopic" class="heading-link"><i class="fas fa-link"></i></a><a href="#disconnectProducers-persistentTopic" class="headerlink" title="disconnectProducers(persistentTopic)"></a><code>disconnectProducers(persistentTopic)</code></h3>
      <p><code>disconnectProducers(persistentTopic);</code>函数负责在<code>producer_request_hold</code>和<code>producer_exception</code>两种模式下 Backlog 超限时断开与 Producer 的链接。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">disconnectProducers</span><span class="params">(PersistentTopic persistentTopic)</span> </span>&#123;</span><br><span class="line">        List&lt;CompletableFuture&lt;Void&gt;&gt; futures = Lists.newArrayList();</span><br><span class="line">        ConcurrentOpenHashSet&lt;Producer&gt; producers = persistentTopic.getProducers();</span><br><span class="line"></span><br><span class="line">        producers.forEach(producer -&gt; &#123;</span><br><span class="line">            futures.add(producer.disconnect());</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        FutureUtil.waitForAll(futures).thenRun(() -&gt; &#123;</span><br><span class="line">            log.info(<span class="string">&quot;All producers on topic [&#123;&#125;] are disconnected&quot;</span>, persistentTopic.getName());</span><br><span class="line">        &#125;).exceptionally(exception -&gt; &#123;</span><br><span class="line">            log.error(<span class="string">&quot;Error in disconnecting producers on topic [&#123;&#125;] [&#123;&#125;]&quot;</span>, persistentTopic.getName(), exception);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>


        <h2 id="BacklogQuota-检查"   >
          <a href="#BacklogQuota-检查" class="heading-link"><i class="fas fa-link"></i></a><a href="#BacklogQuota-检查" class="headerlink" title="BacklogQuota 检查"></a>BacklogQuota 检查</h2>
      <p>BacklogQuota 有两种形式的检查，一种是<strong>周期性检查</strong>，另一种是<strong>创建 Producer 之前检查</strong>。</p>

        <h3 id="周期性检查"   >
          <a href="#周期性检查" class="heading-link"><i class="fas fa-link"></i></a><a href="#周期性检查" class="headerlink" title="周期性检查"></a>周期性检查</h3>
      <p>在<code>BrokerService</code>启动时，会启动<code>startBacklogQuotaChecker();</code>，<code>startBacklogQuotaChecker();</code>负责周期性执行<code>monitorBacklogQuota() </code>，对于 Backlog 超限的情况，会通过<code>BacklogQuotaManager</code>进行处理。</p>
 <figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">monitorBacklogQuota</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        forEachTopic(topic -&gt; &#123;</span><br><span class="line">            <span class="keyword">if</span> (topic <span class="keyword">instanceof</span> PersistentTopic) &#123;</span><br><span class="line">                PersistentTopic persistentTopic = (PersistentTopic) topic;</span><br><span class="line">                <span class="keyword">if</span> (isBacklogExceeded(persistentTopic)) &#123;</span><br><span class="line">                    getBacklogQuotaManager().handleExceededBacklogQuota(persistentTopic);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">if</span> (log.isDebugEnabled()) &#123;</span><br><span class="line">                        log.debug(<span class="string">&quot;quota not exceeded for [&#123;&#125;]&quot;</span>, topic.getName());</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="创建-Producer-之前检查"   >
          <a href="#创建-Producer-之前检查" class="heading-link"><i class="fas fa-link"></i></a><a href="#创建-Producer-之前检查" class="headerlink" title="创建 Producer 之前检查"></a>创建 Producer 之前检查</h3>
      <p>在 Broker 与 Client 对接的服务端<code>ServerCnx</code>上，收到建立 Producer 的触发之后，在创建 Producer 之前，会进行 BacklogQuota 检查。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (topic.isBacklogQuotaExceeded(producerName)) &#123;</span><br><span class="line">    IllegalStateException illegalStateException = <span class="keyword">new</span> IllegalStateException(</span><br><span class="line">            <span class="string">&quot;Cannot create producer on topic with backlog quota exceeded&quot;</span>);</span><br><span class="line">    BacklogQuota.RetentionPolicy retentionPolicy = topic.getBacklogQuota().getPolicy();</span><br><span class="line">    <span class="keyword">if</span> (retentionPolicy == BacklogQuota.RetentionPolicy.producer_request_hold) &#123;</span><br><span class="line">        <span class="comment">// 返回 Error</span></span><br><span class="line">        ctx.writeAndFlush( Commands.newError(requestId, ServerError.ProducerBlockedQuotaExceededError,</span><br><span class="line">                        illegalStateException.getMessage()));</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (retentionPolicy == BacklogQuota.RetentionPolicy.producer_exception) &#123;</span><br><span class="line">        <span class="comment">// 返回 Exception</span></span><br><span class="line">        ctx.writeAndFlush(Commands.newError(requestId, ServerError.ProducerBlockedQuotaExceededException,</span><br><span class="line">                illegalStateException.getMessage()));</span><br><span class="line">    &#125;</span><br><span class="line">    producerFuture.completeExceptionally(illegalStateException);</span><br><span class="line">    producers.remove(producerId, producerFuture);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>

<p>这里只进行<code>producer_request_hold</code>和<code>producer_exception</code>两种策略的处理，<code>consumer_backlog_eviction</code>只在周期性检查时进行处理。</p>
<p>对于<code>producer_request_hold</code>策略，返回 Error ，<code>ClientCnx</code>在收到 Error 之后，不会直接结束请求，会在 Future 任务超时或者调用<code>get()</code>时抛出<code>ProducerBlockedQuotaExceededError</code>异常。</p>
<figure class="highlight java"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">handleError</span><span class="params">(CommandError error)</span> </span>&#123;</span><br><span class="line">        checkArgument(state == State.Ready);</span><br><span class="line"></span><br><span class="line">        log.warn(<span class="string">&quot;&#123;&#125; Received error from server: &#123;&#125;&quot;</span>, ctx.channel(), error.getMessage());</span><br><span class="line">        <span class="keyword">long</span> requestId = error.getRequestId();</span><br><span class="line">        <span class="keyword">if</span> (error.getError() == ServerError.ProducerBlockedQuotaExceededError) &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;&#123;&#125; Producer creation has been blocked because backlog quota exceeded for producer topic&quot;</span>,</span><br><span class="line">                    ctx.channel());</span><br><span class="line">        &#125;</span><br><span class="line">        CompletableFuture&lt;ProducerResponse&gt; requestFuture = pendingRequests.remove(requestId);</span><br><span class="line">        <span class="keyword">if</span> (requestFuture != <span class="keyword">null</span>) &#123;</span><br><span class="line">            requestFuture.completeExceptionally(getPulsarClientException(error.getError(), error.getMessage()));</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            log.warn(<span class="string">&quot;&#123;&#125; Received unknown request id from server: &#123;&#125;&quot;</span>, ctx.channel(), error.getRequestId());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></div></figure>

<p>对于<code>producer_exception</code>策略，直接返回<code>ProducerBlockedQuotaExceededException</code>异常。</p>
<p>以上就是对 Pulsar 代码中 BacklogQuota 机制的实现。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Pulsar</tag>
      </tags>
  </entry>
  <entry>
    <title>CompletableFuture 总结</title>
    <url>/2019/08/18/2019-08-18-CompletableFuture/</url>
    <content><![CDATA[<p><code>CompletableFuture</code> 是Java8 中新增的用来进行函数式异步编程的工具类。</p>
<p>最近学习源码的过程中看到有很多 <code>CompletableFuture</code> 的使用，感觉自己对这个类中的各个方法的使用场景和方法不是很熟悉，遂参考了下面几篇博客进行学习（本文大部分内容也都来自下面几篇博客）：</p>
<p><span class="exturl"><a class="exturl__link"   href="https://colobu.com/2016/02/29/Java-CompletableFuture/" >Java CompletableFuture 详解</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link"   href="https://juejin.im/post/59eae61b51882549fc512b34" >Java8新的异步编程方式 CompletableFuture(一)</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link"   href="https://juejin.im/post/59eae6e4f265da430e4e4cb5" >Java8新的异步编程方式 CompletableFuture(二)</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p><span class="exturl"><a class="exturl__link"   href="https://juejin.im/post/59eae6e4f265da430e4e4cb5" >Java8新的异步编程方式 CompletableFuture(三)</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
<p>上面的博客介绍的比较详细，为了自己查阅回看的方便，这里对这些方法进行一下总结（这里只总结不举例，具体使用需要看上面的博客）。</p>
<span id="more"></span>



        <h2 id="Future接口"   >
          <a href="#Future接口" class="heading-link"><i class="fas fa-link"></i></a><a href="#Future接口" class="headerlink" title="Future接口"></a>Future接口</h2>
      <p><code>Feture</code> 接口包含五个方法，介绍如下：</p>
<ul>
<li><p><code>boolean cancel (boolean mayInterruptIfRunning)</code> 取消任务的执行。参数指定是否立即中断任务执行，或者等等任务结束</p>
</li>
<li><p><code>boolean isCancelled ()</code> 任务是否已经取消，任务正常完成前将其取消，则返回 <code>true</code></p>
</li>
<li><p><code>boolean isDone ()</code> 任务是否已经完成。需要注意的是如果任务正常终止、异常或取消，都将返回<code>true</code></p>
</li>
<li><p><code>V get () throws InterruptedException, ExecutionException</code>  等待任务执行结束，然后获得V类型的结果。InterruptedException 线程被中断异常， ExecutionException任务执行异常，如果任务被取消，还会抛出CancellationException</p>
</li>
<li><p><code>V get (long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException </code>同上面的get功能一样，多了设置超时时间。参数timeout指定超时时间，uint指定时间的单位，在枚举类TimeUnit中有相关的定义。如果计 算超时，将抛出TimeoutException</p>
</li>
</ul>

        <h2 id="主动完成计算"   >
          <a href="#主动完成计算" class="heading-link"><i class="fas fa-link"></i></a><a href="#主动完成计算" class="headerlink" title="主动完成计算"></a>主动完成计算</h2>
      <p><code>CompletableFuture</code>实现了<code>CompletionStage</code>和<code>Future</code>两个接口。</p>

        <h4 id="通过阻塞或者轮询获得结果"   >
          <a href="#通过阻塞或者轮询获得结果" class="heading-link"><i class="fas fa-link"></i></a><a href="#通过阻塞或者轮询获得结果" class="headerlink" title="通过阻塞或者轮询获得结果"></a>通过阻塞或者轮询获得结果</h4>
      <div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>public T get()</code></td>
<td><code>Future</code>接口实现</td>
</tr>
<tr>
<td><code>public T get(long timeout, TimeUnit unit)</code></td>
<td><code>Future</code>接口实现</td>
</tr>
<tr>
<td><code>public T getNow(T valueIfAbsent)</code></td>
<td>如果结果已经计算完则返回结果或者抛出异常，否则返回给定的<code>valueIfAbsent</code>值。</td>
</tr>
<tr>
<td><code>public T join()</code></td>
<td>返回计算的结果或者抛出一个unchecked异常(CompletionException)</td>
</tr>
</tbody></table></div>
<blockquote>
<p><code>join()</code>和<code>get()</code>的区别是，<code>join()</code>只会抛出<strong>未检查异常</strong>（不需要使用<code>try...catch..</code>进行处理），而<code>get()</code>会抛出<strong>检查异常</strong>。</p>
</blockquote>

        <h4 id="异步获取结果"   >
          <a href="#异步获取结果" class="heading-link"><i class="fas fa-link"></i></a><a href="#异步获取结果" class="headerlink" title="异步获取结果"></a>异步获取结果</h4>
      <blockquote>
<ul>
<li><p>下面两个函数的调用会立即执行，并且只能执行一次。</p>
</li>
<li><p>如果该任务已经执行完成，那么下面两个调用会无效，只能获取执行完成的结果。其实就是使任务立即结束（返回指定结果或者指定抛出异常）。</p>
</li>
<li><p>比较适合需要返回<code>CompletableFuture</code>的方法，先创建一个空的<code>CompletableFuture</code>，之后通过下面两个函数指定前面创建的<code>CompletableFuture</code>的返回值。</p>
</li>
</ul>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>complete(T t)</code></td>
<td>完成异步执行，并返回future的结果</td>
</tr>
<tr>
<td><code>completeExceptionally(Throwable ex)</code></td>
<td>异步执行不正常的结束</td>
</tr>
</tbody></table></div>

        <h2 id="静态工厂方法"   >
          <a href="#静态工厂方法" class="heading-link"><i class="fas fa-link"></i></a><a href="#静态工厂方法" class="headerlink" title="静态工厂方法"></a>静态工厂方法</h2>
      <blockquote>
<p>run 和 supply 的主要区别是异步操作是否有返回值（下面列出的所有方法也基本都是按照<strong>是否有返回值</strong>分为两类）。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>runAsync(Runnable runnable)</code></td>
<td>使用ForkJoinPool.commonPool()作为它的线程池执行异步代码。</td>
</tr>
<tr>
<td><code>runAsync(Runnable runnable, Executor executor)</code></td>
<td>使用指定的thread pool执行异步代码。</td>
</tr>
<tr>
<td><code>supplyAsync(Supplier&lt;U&gt; supplier)</code></td>
<td>使用ForkJoinPool.commonPool()作为它的线程池执行异步代码，异步操作有返回值。</td>
</tr>
<tr>
<td><code>supplyAsync(Supplier&lt;U&gt; supplier, Executor executor)</code></td>
<td>使用指定的thread pool执行异步代码，异步操作有返回值。</td>
</tr>
</tbody></table></div>
<blockquote>
<p>下面几乎所有的方法都是一式三份，三种方法的区别是</p>
<ul>
<li>直接在当前线程执行</li>
<li>换另一个线程（但是不指定线程）异步执行</li>
<li>指定线程执行</li>
</ul>
</blockquote>

        <h2 id="转换"   >
          <a href="#转换" class="heading-link"><i class="fas fa-link"></i></a><a href="#转换" class="headerlink" title="转换"></a>转换</h2>
      <blockquote>
<p>相当于 map 操作</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenApply(Function&lt;? super T,? extends U&gt; fn)</code></td>
<td>接受一个Function&lt;? super T,? extends U&gt;参数用来转换CompletableFuture</td>
</tr>
<tr>
<td><code>thenApplyAsync(Function&lt;? super T,? extends U&gt; fn)</code></td>
<td>接受一个Function&lt;? super T,? extends U&gt;参数用来转换CompletableFuture，使用ForkJoinPool</td>
</tr>
<tr>
<td><code>thenApplyAsync(Function&lt;? super T,? extends U&gt; fn, Executor executor)</code></td>
<td>接受一个Function&lt;? super T,? extends U&gt;参数用来转换CompletableFuture，使用指定的线程池</td>
</tr>
</tbody></table></div>
<blockquote>
<p>相当于 flatMap 操作</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn)</code></td>
<td>在异步操作完成的时候对异步操作的结果进行一些操作，并且仍然返回CompletableFuture类型。</td>
</tr>
<tr>
<td><code>thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn)</code></td>
<td>在异步操作完成的时候对异步操作的结果进行一些操作，并且仍然返回CompletableFuture类型。使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>thenComposeAsync(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn,Executor executor)</code></td>
<td>在异步操作完成的时候对异步操作的结果进行一些操作，并且仍然返回CompletableFuture类型。使用指定的线程池。</td>
</tr>
</tbody></table></div>

        <h2 id="组合"   >
          <a href="#组合" class="heading-link"><i class="fas fa-link"></i></a><a href="#组合" class="headerlink" title="组合"></a>组合</h2>
      <div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的fn，用它来组合另外一个CompletableFuture的结果。</td>
</tr>
<tr>
<td><code>thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的fn，用它来组合另外一个CompletableFuture的结果。使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>thenCombineAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn, Executor executor)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的fn，用它来组合另外一个CompletableFuture的结果。使用指定的线程池。</td>
</tr>
</tbody></table></div>
<blockquote>
<p>thenAcceptBoth跟thenCombine类似，但是返回CompletableFuture类型。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenAcceptBoth(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; action)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的action，用它来组合另外一个CompletableFuture的结果。</td>
</tr>
<tr>
<td><code>thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; action)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的action，用它来组合另外一个CompletableFuture的结果。使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>thenAcceptBothAsync(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; action, Executor executor)</code></td>
<td>当两个CompletableFuture都正常完成后，执行提供的action，用它来组合另外一个CompletableFuture的结果。使用指定的线程池。</td>
</tr>
</tbody></table></div>

        <h2 id="计算结果完成时的处理"   >
          <a href="#计算结果完成时的处理" class="heading-link"><i class="fas fa-link"></i></a><a href="#计算结果完成时的处理" class="headerlink" title="计算结果完成时的处理"></a>计算结果完成时的处理</h2>
      <blockquote>
<ul>
<li><code>Action</code>的类型是<code>BiConsumer&lt;? super T,? super Throwable&gt;</code>，它可以处理正常的计算结果，或者异常情况。</li>
<li>方法不以<code>Async</code>结尾，意味着<code>Action</code>使用相同的线程执行，而<code>Async</code>可能会使用其它的线程去执行(如果使用相同的线程池，也可能会被同一个线程选中执行</li>
</ul>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>whenComplete(BiConsumer&lt;? super T,? super Throwable&gt; action)</code></td>
<td>当CompletableFuture完成计算结果时对结果进行处理，或者当CompletableFuture产生异常的时候对异常进行处理。</td>
</tr>
<tr>
<td><code>whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action)</code></td>
<td>当CompletableFuture完成计算结果时对结果进行处理，或者当CompletableFuture产生异常的时候对异常进行处理。使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>whenCompleteAsync(BiConsumer&lt;? super T,? super Throwable&gt; action, Executor executor)</code></td>
<td>当CompletableFuture完成计算结果时对结果进行处理，或者当CompletableFuture产生异常的时候对异常进行处理。使用指定的线程池。</td>
</tr>
</tbody></table></div>
<blockquote>
<p><code>handle()</code>相当于whenComplete()+转换。</p>
<p><code>handle()</code>也可以理解为和<code>thenApply()</code>的含义更为相似，但是比<code>thenApply()</code>增加异常处理的功能。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>handle(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn)</code></td>
<td>当CompletableFuture完成计算结果或者抛出异常的时候，执行提供的fn</td>
</tr>
<tr>
<td><code>handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn)</code></td>
<td>当CompletableFuture完成计算结果或者抛出异常的时候，执行提供的fn，使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>handleAsync(BiFunction&lt;? super T, Throwable, ? extends U&gt; fn, Executor executor)</code></td>
<td>当CompletableFuture完成计算结果或者抛出异常的时候，执行提供的fn，使用指定的线程池。</td>
</tr>
</tbody></table></div>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>exceptionally(Function fn)</code></td>
<td>只有当CompletableFuture抛出异常的时候，才会触发这个exceptionally的计算，调用function计算值。</td>
</tr>
</tbody></table></div>

        <h2 id="纯消费"   >
          <a href="#纯消费" class="heading-link"><i class="fas fa-link"></i></a><a href="#纯消费" class="headerlink" title="纯消费"></a>纯消费</h2>
      <div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>thenAccept(Consumer&lt;? super T&gt; action)</code></td>
<td>当CompletableFuture完成计算结果，只对结果执行Action，而不返回新的计算值</td>
</tr>
<tr>
<td><code>thenAcceptAsync(Consumer&lt;? super T&gt; action)</code></td>
<td>当CompletableFuture完成计算结果，只对结果执行Action，而不返回新的计算值，使用ForkJoinPool。</td>
</tr>
<tr>
<td><code>thenAcceptAsync(Consumer&lt;? super T&gt; action, Executor executor)</code></td>
<td>当CompletableFuture完成计算结果，只对结果执行Action，而不返回新的计算值</td>
</tr>
</tbody></table></div>

        <h2 id="Either"   >
          <a href="#Either" class="heading-link"><i class="fas fa-link"></i></a><a href="#Either" class="headerlink" title="Either"></a>Either</h2>
      <blockquote>
<p>Either 表示的是两个CompletableFuture，当其中任意一个CompletableFuture计算完成的时候就会执行。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>acceptEither(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)</code></td>
<td>当任意一个CompletableFuture完成的时候，action这个消费者就会被执行。</td>
</tr>
<tr>
<td><code>acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action)</code></td>
<td>当任意一个CompletableFuture完成的时候，action这个消费者就会被执行。使用ForkJoinPool</td>
</tr>
<tr>
<td><code>acceptEitherAsync(CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action, Executor executor)</code></td>
<td>当任意一个CompletableFuture完成的时候，action这个消费者就会被执行。使用指定的线程池</td>
</tr>
</tbody></table></div>
<blockquote>
<p><code>applyToEither()</code> 是<code>acceptEither()</code>的哥哥. 当两个future其中一个完成后，后者用于只是简单地调用一些代码，<code>applyToEither()</code>会返回一个新的future. 这个future是在前面两个future其中一个完成后进行执行完成。</p>
</blockquote>
<div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>applyToEither(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn)</code></td>
<td>当任意一个CompletableFuture完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture<U>的计算结果。</td>
</tr>
<tr>
<td><code>applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn)</code></td>
<td>当任意一个CompletableFuture完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture<U>的计算结果。使用ForkJoinPool</td>
</tr>
<tr>
<td><code>applyToEitherAsync(CompletionStage&lt;? extends T&gt; other, Function&lt;? super T,U&gt; fn, Executor executor)</code></td>
<td>当任意一个CompletableFuture完成的时候，fn会被执行，它的返回值会当作新的CompletableFuture<U>的计算结果。使用指定的线程池</td>
</tr>
</tbody></table></div>

        <h2 id="其他方法"   >
          <a href="#其他方法" class="heading-link"><i class="fas fa-link"></i></a><a href="#其他方法" class="headerlink" title="其他方法"></a>其他方法</h2>
      <div class="table-container"><table>
<thead>
<tr>
<th>方法名</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td><code>allOf(CompletableFuture&lt;?&gt;... cfs)</code></td>
<td>在所有Future对象完成后结束，并返回一个future。</td>
</tr>
<tr>
<td><code>anyOf(CompletableFuture&lt;?&gt;... cfs)</code></td>
<td>在任何一个Future对象结束后结束，并返回一个future。</td>
</tr>
</tbody></table></div>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次kafka宕机问题排查</title>
    <url>/2021/05/08/%E8%AE%B0%E4%B8%80%E6%AC%A1kafka%E5%AE%95%E6%9C%BA%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<p>kafka集群出现宕机报警，自动替换新broker一直无法成功。</p>
<span id="more"></span>


        <h2 id="排查过程"   >
          <a href="#排查过程" class="heading-link"><i class="fas fa-link"></i></a><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2>
      <ol>
<li><p>kafka集群有一个broker宕机，自动替换机器一直无法成功，手动重启时发现该broker对应的zookeeper上的/brokers/ids目录一直被删除导致。</p>
</li>
<li><p>定位zk目录一直被删除的原因：参照<span class="exturl"><a class="exturl__link"   href="https://www.cnblogs.com/cyl048/p/8984661.html" >Zookeeper日志文件&amp;事务日志&amp;数据快照</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span>查看zk事务日志</p>
</li>
<li><p>首先查看zk事务日志所在的目录:</p>
<figure class="highlight shell"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> <span class="built_in">cd</span> zookeeper/conf</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> grep dataLogDir *</span></span><br><span class="line">zoo.cfg:dataLogDir=/home/var/lib/zookeeper/</span><br></pre></td></tr></table></div></figure></li>
<li><p>通过<code>java -classpath .:lib/slf4j-api-1.6.1.jar:zookeeper-3.4.6.jar org.apache.zookeeper.server.LogFormatter /home/var/lib/zookeeper/version-2/log.10263212a| grep brokers/ids</code>查看事务日志，发现/brokers/ids/9984确实在刚刚创建时就被立刻删除了，并且可以找到zk的session id<img src="1.png"></p>
</li>
<li><p>任一找到一个删除该zk节点的session id，查找zk日志，确定删除操作的客户端<img src="2.png"></p>
<blockquote>
<ul>
<li>排查过程中发现，好多session id在zk日志中找不到，后面经同学提示才发现原因是zk有5个节点，事务日志在所有节点时相同的，但是普通日志只包含连接本节点的session id，所以需要在所有zk节点的普通日志中进行查找。</li>
<li>session closed时才会打印客户端ip</li>
</ul>
</blockquote>
</li>
<li><p>问题确定：原来是删除操作的broker与新启动的broker id相同，都为9884，但是由于执行删除操作的机器有问题，一直在重启，每次启动时前都会先删除/brokers/ids/9984这个zk节点</p>
</li>
</ol>

        <h2 id="经验总结"   >
          <a href="#经验总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#经验总结" class="headerlink" title="经验总结"></a>经验总结</h2>
      <ol>
<li>zk事务日志的查看方式：<span class="exturl"><a class="exturl__link"   href="https://www.cnblogs.com/cyl048/p/8984661.html" >Zookeeper日志文件&amp;事务日志&amp;数据快照</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></li>
<li>zk所有节点的事务日志是相同的，但是普通日志中只有与当前节点连接的session信息</li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>zookeeper</tag>
        <tag>问题排查</tag>
      </tags>
  </entry>
  <entry>
    <title>记一次线上服务Full GC问题排查</title>
    <url>/2021/05/06/%E8%AE%B0%E4%B8%80%E6%AC%A1%E7%BA%BF%E4%B8%8A%E6%9C%8D%E5%8A%A1%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url>
    <content><![CDATA[<p>有一个线上服务多个集群出现FGC，降低集群压力之后并没有改善。</p>
<span id="more"></span>


        <h2 id="背景"   >
          <a href="#背景" class="heading-link"><i class="fas fa-link"></i></a><a href="#背景" class="headerlink" title="背景"></a>背景</h2>
      <ul>
<li>这是一个kafka mirror服务，用来在多个kafka集群之间进行数据同步。</li>
<li>mirror服务是无状态的，因此一般情况下FGC不会对系统产生严重影响，但是仍然存在较大风险。</li>
</ul>

        <h2 id="排查过程"   >
          <a href="#排查过程" class="heading-link"><i class="fas fa-link"></i></a><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2>
      
        <h3 id="一-缩小范围"   >
          <a href="#一-缩小范围" class="heading-link"><i class="fas fa-link"></i></a><a href="#一-缩小范围" class="headerlink" title="一. 缩小范围"></a>一. 缩小范围</h3>
      <p>​    FGC是从五一长假期间开始发生的，并且在FGC发生之前，在两个FGC集群中增加过任务，因此推测可能与<strong>集群压力较大</strong>有关系，为了确定这一推测，在五一长假结束之后，将新增加的任务全部迁移至同一个mirror集群A，使另一个mirror集群B状态与出现FGC之前完全相同，但是，事与愿违，集群B的FGC没有恢复，仍然存在问题。</p>
<p>​    因此，基本可以确认本次FGC与五一长假期间集群压力增加没有关系，需要具体分析FGC的原因，确认是否存在<strong>内存泄漏</strong>的情况。</p>

        <h3 id="二-具体分析"   >
          <a href="#二-具体分析" class="heading-link"><i class="fas fa-link"></i></a><a href="#二-具体分析" class="headerlink" title="二. 具体分析"></a>二. 具体分析</h3>
      <ol>
<li><p>首先通过jmap查看内存的占用情况：</p>
<figure class="highlight shell"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> jmap -histo <span class="variable">$&#123;PID&#125;</span></span></span><br></pre></td></tr></table></div></figure>

<p><img src="1.png"></p>
<p>可以发现，<code>com.mysql.cj.jdbc.ByteArrayRow</code>这个对象占了4G多的内存（总内存32G），虽然代码中有查询mysql代码，但是查询结果都已经解析存放在了<code>Map</code>、<code>List</code>等对象中。</p>
</li>
<li><p>为了确认该mysql对象是不是查询的临时变量，会不会被FGC清理，主动找一台机器执行FGC，</p>
<figure class="highlight shell"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> jmap -histo:live  <span class="variable">$&#123;PID&#125;</span></span></span><br></pre></td></tr></table></div></figure>

<p>发现mysql对象占用的大小并未减少且仍在增加，推测这个mysql对象应该是引起FGC的原因。</p>
</li>
<li><p>查看代码发现，除了一处定期执行的SQL查询外，在任务不变的情况下，其他代码在系统启动后都不会进行SQL查询。并且，这条定期执行的SQL执行周期在这个版本中并没有发生变化，一直是2分钟一次。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line">kafkaScheduler.schedule(<span class="string">&quot;update-Maps-Task&quot;</span>, updateMapsTask, <span class="number">20000</span>, <span class="number">120000</span>, <span class="type">TimeUnit</span>.<span class="type">MILLISECONDS</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">updateMapsTask</span></span>() &#123;</span><br><span class="line">    mysqlUtil.updateTopicMap(<span class="string">&quot;SELECT * FROM table2&quot;</span>)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure></li>
<li><p>验证<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象的内存占用是否与上述Scheduler有关：</p>
<ul>
<li>找一台机器每2分钟查询一次<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象大小，发现每两次查询到的对象大小之间的差值均相同，为395360</li>
<li>根据服务启动时间，按照每两分钟增长395360B的速度进行计算，得到<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象大小为4GB，该估算值与当前通过jmap看到的对象大小一致</li>
</ul>
<p>基本可以确认是这个定时查询导致的。</p>
</li>
<li><p>进一步验证：</p>
<ul>
<li>重启服务，发现<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象特别小；</li>
<li>将定时任务周期从2分钟改为3秒，发现<code>com.mysql.cj.jdbc.ByteArrayRow</code>对象3分钟内增长了15MB，且与估算值一致。</li>
</ul>
</li>
<li><p>问题修复：</p>
<p>通过查看代码和Google发现，需要显式关闭mysql查询使用的<code>Statement</code>对象和<code>ResultSet</code>对象，</p>
<blockquote>
<p><span class="exturl"><a class="exturl__link"   href="https://stackoverflow.com/questions/4507440/must-jdbc-resultsets-and-statements-be-closed-separately-although-the-connection/15728512" >https://stackoverflow.com/questions/4507440/must-jdbc-resultsets-and-statements-be-closed-separately-although-the-connection/15728512</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></p>
</blockquote>
</li>
<li><p>修复验证：</p>
<p>JVM内存设置为50MB，定时任务周期设置为3秒。</p>
<p>修复前，mysql内存不断增加，出现几次FGC，直到OOM 。</p>
<p><img src="2.png"></p>
<p>修复后，未出现FGC，有YGC，YGC之后mysql内存被回收 。</p>
<p><img src="3.png"></p>
</li>
</ol>

        <h2 id="总结"   >
          <a href="#总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#总结" class="headerlink" title="总结"></a>总结</h2>
      <ul>
<li>旧版本代码虽然也是2分钟执行一次查询，但是查询数据表不同，旧版本数据表中只有2条数据，新版本数据表中有7000+数据，内存积累很慢，所以旧版本一致没有发现问题。</li>
<li>查询mysql时需要及时关闭<code>Statement</code>对象和<code>ResultSet</code>对象，否则会因为对象一直被引用而无法自动进行垃圾回收。</li>
<li>分析FGC问题时需要主动使用jmap等工具，尽早发现问题。</li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>问题排查</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>《深入理解Java虚拟机》笔记</title>
    <url>/2019/07/28/2019-07-28-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JAVA%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>阅读了《深入理解Java虚拟机》的部分章节，并做了一些简单的笔记，不是很详细，但是可以方便自己查阅。</p>
<span id="more"></span>



        <h2 id="第三章-垃圾收集器与内存分配策略"   >
          <a href="#第三章-垃圾收集器与内存分配策略" class="heading-link"><i class="fas fa-link"></i></a><a href="#第三章-垃圾收集器与内存分配策略" class="headerlink" title="第三章 垃圾收集器与内存分配策略"></a>第三章 垃圾收集器与内存分配策略</h2>
      
        <h3 id="1-对象是否存活"   >
          <a href="#1-对象是否存活" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-对象是否存活" class="headerlink" title="1. 对象是否存活"></a>1. 对象是否存活</h3>
      
        <h4 id="引用计数法："   >
          <a href="#引用计数法：" class="heading-link"><i class="fas fa-link"></i></a><a href="#引用计数法：" class="headerlink" title="引用计数法："></a>引用计数法：</h4>
      <p>很难解决对象间的循环引用</p>

        <h4 id="可达性分析"   >
          <a href="#可达性分析" class="heading-link"><i class="fas fa-link"></i></a><a href="#可达性分析" class="headerlink" title="可达性分析"></a>可达性分析</h4>
      
        <h5 id="可以作为GC-Roots的对象："   >
          <a href="#可以作为GC-Roots的对象：" class="heading-link"><i class="fas fa-link"></i></a><a href="#可以作为GC-Roots的对象：" class="headerlink" title="可以作为GC Roots的对象："></a>可以作为GC Roots的对象：</h5>
      <ul>
<li>虚拟机栈中引用的对象</li>
<li>方法区中类静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
<li>本地方法栈中JNI（Native方法）引用的对象</li>
</ul>

        <h3 id="2-引用分类（JDK1-2实现）"   >
          <a href="#2-引用分类（JDK1-2实现）" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-引用分类（JDK1-2实现）" class="headerlink" title="2. 引用分类（JDK1.2实现）"></a>2. 引用分类（JDK1.2实现）</h3>
      <ul>
<li><strong>强引用</strong>：永远不回收</li>
<li><strong>软引用SoftReference</strong>（有用但非必须）：内存溢出之前回收</li>
<li><strong>弱引用WeakReference</strong>（非必须）：GC时回收</li>
<li><strong>虚引用PhantomReference</strong>（幽灵引用/幻影引用）：目的是能在这个对象被收集器回收时收到一个系统通知</li>
</ul>

        <h3 id="3-finalize-（不建议使用）"   >
          <a href="#3-finalize-（不建议使用）" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-finalize-（不建议使用）" class="headerlink" title="3. finalize()（不建议使用）"></a>3. finalize()（不建议使用）</h3>
      <blockquote>
<p>判断对象是否死亡会经历<strong>两次标记</strong>过程：<br>①判断是否与GC Roots相连；<br>②执行finalize()（对象没有覆盖finalize()或finalize()已经被调用过一次时，虚拟机认为没必要执行finalize()，不会进行第二次标记）。</p>
</blockquote>
<ul>
<li>被调用时会放在由虚拟机自动创建的、低优先级的队列<strong>F-Queue</strong>中</li>
<li>finalize()是对象唯一的自救机会，例如：在finalize()中将this赋值给某个类变量或者对象的成员变量</li>
<li>运行代价高昂，不确定性大、无法保证各个对象的调用顺序</li>
<li>finalize()能做的所有工作使用try-finally或者其他方式可以做得更好、更及时</li>
</ul>

        <h3 id="4-回收方法区"   >
          <a href="#4-回收方法区" class="heading-link"><i class="fas fa-link"></i></a><a href="#4-回收方法区" class="headerlink" title="4. 回收方法区"></a>4. 回收方法区</h3>
      
        <h5 id="废弃常量"   >
          <a href="#废弃常量" class="heading-link"><i class="fas fa-link"></i></a><a href="#废弃常量" class="headerlink" title="废弃常量"></a>废弃常量</h5>
      <p>与Java堆的回收逻辑类似</p>

        <h5 id="无用的类"   >
          <a href="#无用的类" class="heading-link"><i class="fas fa-link"></i></a><a href="#无用的类" class="headerlink" title="无用的类"></a>无用的类</h5>
      <ul>
<li>该类的所有实例已经被回收</li>
<li>加载该类的ClassLoader已经被回收</li>
<li>该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。</li>
</ul>

        <h3 id="5-垃圾收集算法"   >
          <a href="#5-垃圾收集算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#5-垃圾收集算法" class="headerlink" title="5. 垃圾收集算法"></a>5. 垃圾收集算法</h3>
      
        <h4 id="（1）标记清除算法"   >
          <a href="#（1）标记清除算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）标记清除算法" class="headerlink" title="（1）标记清除算法"></a>（1）标记清除算法</h4>
      <ul>
<li>效率不高</li>
<li>会大量不连续内存碎片</li>
</ul>

        <h4 id="（2）复制算法"   >
          <a href="#（2）复制算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）复制算法" class="headerlink" title="（2）复制算法"></a>（2）复制算法</h4>
      <ul>
<li>内存缩小为原来的一半</li>
<li>HotSpot默认的Eden与Survivor的大小比例为8:1</li>
<li>没有办法保证每次回收都只有不多于10%的对象存活。当Survivor空间不够用时，需要依赖老年代进行<strong>分配担保</strong>。<blockquote>
<p>分配担保：当Survivor空间不能放下上一次 YGC 之后存活的对象时，这些对象直接通过分配担保机制进入老年代。</p>
</blockquote>
</li>
</ul>

        <h4 id="（3）标记整理算法"   >
          <a href="#（3）标记整理算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）标记整理算法" class="headerlink" title="（3）标记整理算法"></a>（3）标记整理算法</h4>
      
        <h4 id="（4）分代收集算法"   >
          <a href="#（4）分代收集算法" class="heading-link"><i class="fas fa-link"></i></a><a href="#（4）分代收集算法" class="headerlink" title="（4）分代收集算法"></a>（4）分代收集算法</h4>
      <p>新生代每次垃圾收集都会有大量对象死去，少量存活，所以采用复制算法。<br>老年代对象存活率高、没有额外的空间对它进行担保，必须使用“标记-清理”或者“标记-整理”算法。</p>

        <h3 id="6-HotSpot算法实现"   >
          <a href="#6-HotSpot算法实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#6-HotSpot算法实现" class="headerlink" title="6. HotSpot算法实现"></a>6. HotSpot算法实现</h3>
      
        <h4 id="（1）枚举根节点"   >
          <a href="#（1）枚举根节点" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）枚举根节点" class="headerlink" title="（1）枚举根节点"></a>（1）枚举根节点</h4>
      <ul>
<li>Java虚拟机使用准确式GC（必须确定一个变量是引用还是真正的数据）</li>
<li>虚拟机停顿之后不需要检查所有的执行上下文和全局的引用位置。</li>
<li>类加载完成时计算出什么偏移量上是什么类型的数据，JIT编译时在特定位置（<strong>安全点</strong>）记录<strong>OopMap</strong>数据结构（指明栈和寄存器哪些位置是引用）</li>
</ul>

        <h4 id="（2）安全点（SafePoint）"   >
          <a href="#（2）安全点（SafePoint）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）安全点（SafePoint）" class="headerlink" title="（2）安全点（SafePoint）"></a>（2）安全点（SafePoint）</h4>
      <ul>
<li>程序执行时并非在所有地方都能停顿下来开始GC，只有到达安全点时才能暂停。</li>
<li><strong>安全点选定原则</strong>：是否具有让程序<strong>长时间执行</strong>的特征</li>
<li><strong>长时间执行</strong>：指令序列复用（如：方法调用、循环跳转、异常跳转）</li>
<li><strong>抢先式中断（已经被弃用）</strong>：所有线程中断，不在安全点的线程恢复执行。  </li>
</ul>
<p><strong>主动式中断</strong>：在安全点设置中断标志，程序执行到安全点时主动轮询这个标志，判断是否需要进行中断。</p>

        <h4 id="（3）安全区域（Safe-Region）"   >
          <a href="#（3）安全区域（Safe-Region）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）安全区域（Safe-Region）" class="headerlink" title="（3）安全区域（Safe Region）"></a>（3）安全区域（Safe Region）</h4>
      <ul>
<li>定义：一段代码中，引用关系不会发生变化。（线程处于Sleep或Blocked状态）</li>
<li>线程执行到Safe Region时，标识自己进入Safe Region状态；<br>JVM GC时不管Safe Region状态的线程；<br>当线程离开Safe Region状态时，检查系统是否完成了根节点枚举或整个GC过程；<br>如果完成了，那线程继续执行，否则，必须等待收到可以安全离开Safe Region的信号为止。</li>
</ul>

        <h3 id="7-垃圾收集器"   >
          <a href="#7-垃圾收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#7-垃圾收集器" class="headerlink" title="7. 垃圾收集器"></a>7. 垃圾收集器</h3>
      <p>连线代表可以组合使用。<br><img src="https://i.bmp.ovh/imgs/2019/05/8e139eb7578dd5fc.jpg"></p>

        <h4 id="（1）Serial收集器（Client模式下新生代垃圾清理首选）"   >
          <a href="#（1）Serial收集器（Client模式下新生代垃圾清理首选）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）Serial收集器（Client模式下新生代垃圾清理首选）" class="headerlink" title="（1）Serial收集器（Client模式下新生代垃圾清理首选）"></a>（1）Serial收集器（Client模式下新生代垃圾清理首选）</h4>
      <ul>
<li>进行垃圾收集时，必须暂停其他所有的工作线程，直到它收集结束。</li>
<li>Serial/Serial Old收集器在新生代采用<strong>复制算法</strong>，老年代采用<strong>标记-整理算法</strong>。</li>
</ul>

        <h4 id="（2）ParNew收集器（Server模式下新生代垃圾清理首选）"   >
          <a href="#（2）ParNew收集器（Server模式下新生代垃圾清理首选）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）ParNew收集器（Server模式下新生代垃圾清理首选）" class="headerlink" title="（2）ParNew收集器（Server模式下新生代垃圾清理首选）"></a>（2）ParNew收集器（Server模式下新生代垃圾清理首选）</h4>
      <ul>
<li>多线程版本的Serial收集器</li>
<li>第一款真正意义上的<strong>并发</strong>收集器</li>
<li>默认开启的收集线程数与CPU的数量相同</li>
</ul>

        <h4 id="（3）Parallel-Scavenge收集器"   >
          <a href="#（3）Parallel-Scavenge收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）Parallel-Scavenge收集器" class="headerlink" title="（3）Parallel Scavenge收集器"></a>（3）Parallel Scavenge收集器</h4>
      <ul>
<li>目标：达到一个可控制的吞吐量。（吞吐量 = 运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间)）</li>
<li>适合在后台运算而不需要太多交互的任务</li>
<li>可以设置最大垃圾收集停段时间（-XX:MaxGCPauseMillis）和吞吐量大小（-XX:GCTimeRatio）</li>
<li>可以开启-XX:UseAdaptiveSizePolicy，之后虚拟机根据系统运行状况自动设置新生代大小、Eden与Survivor比例、晋升老年代对象大小等细节参数。（<strong>GC自适应的调节策略</strong>）</li>
</ul>

        <h4 id="（4）Serial-Old收集器"   >
          <a href="#（4）Serial-Old收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#（4）Serial-Old收集器" class="headerlink" title="（4）Serial Old收集器"></a>（4）Serial Old收集器</h4>
      
        <h4 id="（5）Parallel-Old收集器"   >
          <a href="#（5）Parallel-Old收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#（5）Parallel-Old收集器" class="headerlink" title="（5）Parallel Old收集器"></a>（5）Parallel Old收集器</h4>
      
        <h4 id="（6）CMS收集器"   >
          <a href="#（6）CMS收集器" class="heading-link"><i class="fas fa-link"></i></a><a href="#（6）CMS收集器" class="headerlink" title="（6）CMS收集器"></a>（6）CMS收集器</h4>
      <ul>
<li>四个步骤：<br>a: 初始标记（停顿）：记录与GC Roots直接相连的对象<br>b: 并发标记：GC Roots Tracing<br>c: 重新标记（停顿更长）：修正并发标记期间因用户程序继续运作而导致的标记产生变动的记录<br>d: 并发清除</li>
<li>对 CPU 资源敏感</li>
<li>无法处理<strong>浮动垃圾</strong>（并发清除阶段用户程序产生的新的垃圾，需要等下次GC时再进行清理），可能出现“Concurrent Mode Failure”失败而导致另一次Full GC的产生。（不能等老年代被填满之后进行清理，需要为并发清除期间用户程序的执行预留空间）</li>
<li>空间碎片过多</li>
</ul>

        <h4 id="（7）G1收集器（JDK1-7）"   >
          <a href="#（7）G1收集器（JDK1-7）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（7）G1收集器（JDK1-7）" class="headerlink" title="（7）G1收集器（JDK1.7）"></a>（7）G1收集器（JDK1.7）</h4>
      <ul>
<li>并行与并发</li>
<li>分代收集</li>
<li><strong>空间整合</strong>：从整体上看是基于“标记-整理”算法实现的收集器，从局部（两个Region之间）上来看是基于“复制“算法实现的。</li>
<li><strong>可预测的停顿</strong>：使用者可以指定垃圾收集上消耗的时间不得超过 M 毫秒。</li>
<li>分配的对象会记录在 Remembered Set 中，内存回收时再GC根节点的枚举范围中加入 Remembered Set ，确保不对全堆扫描也不会有泄露。</li>
<li>不计算维护 Remembered Set 的过程，可以分为以下几个步骤：<br>a: 初始标记<br>b: 并发标记<br>c: 最终标记：并发标记期间对象变化记录在线程 Remembered Set Logs 中，该阶段将 Remembered Set Logs 整合到 Remembered Set 中。<br>d: 筛选回收：根据用户期望的 GC 停顿时间制定回收计划。</li>
</ul>

        <h3 id="8-内存分配与回收策略"   >
          <a href="#8-内存分配与回收策略" class="heading-link"><i class="fas fa-link"></i></a><a href="#8-内存分配与回收策略" class="headerlink" title="8. 内存分配与回收策略"></a>8. 内存分配与回收策略</h3>
      <ul>
<li><strong>对象优先在Eden分配</strong><blockquote>
<p>新生代 GC （Minor GC）：非常频繁，回收速度也比较块。<br>老年代 GC （Major GC / Full GC）：伴随至少一次的 Minor GC ， 比 Minor GC 慢10倍以上。</p>
</blockquote>
</li>
<li><strong>大对象直接进入老年代</strong></li>
<li><strong>长期存活的对象将进入老年代</strong>（可以通过 -XX:MaxTenuringThreshold 参数进行设置，默认执行完<strong>15</strong>次 Minor GC）</li>
<li><strong>动态对象年龄判断</strong>：如果在 Survivor 空间中相同年龄所有对象大小总和大于 Survivor 空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。</li>
<li><strong>空间分配担保</strong>：在进行 Minor GC 之前会执行下面的流程，<br>a: 检查<strong>老年代最大连续可用空间是否大于新生代所有对象总空间</strong>，如果是 Minor GC 可以确保安全，否则， 执行b；<br>b: 查看 HandlePromotionFailure 设置的值是否允许担保失败，如果是，执行c，否则，执行 Full GC；<br>c: 检查<strong>老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小</strong>，如果是，尝试一次 Minor GC （可能存在风险），否则，将 HandlePromotionFailure 设置为不允许冒险，改为进行一次 Full GC。</li>
</ul>

        <h2 id="第七章-虚拟机类加载机制"   >
          <a href="#第七章-虚拟机类加载机制" class="heading-link"><i class="fas fa-link"></i></a><a href="#第七章-虚拟机类加载机制" class="headerlink" title="第七章 虚拟机类加载机制"></a>第七章 虚拟机类加载机制</h2>
      
        <h3 id="1-类的加载过程"   >
          <a href="#1-类的加载过程" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-类的加载过程" class="headerlink" title="1. 类的加载过程"></a>1. 类的加载过程</h3>
      <p><img src="https://i.bmp.ovh/imgs/2019/05/ab251c96094d3f7d.png">  </p>
<ul>
<li>按顺序按部就班的开始（不是结束，一个阶段中调用激活另一个阶段），解析阶段可以在初始化之后再开始（动态绑定）</li>
<li>Java虚拟机规定的必须进行<strong>初始化</strong>的5种情况：<br>（1） 遇到 new、getstatic、putstatic、invokestatic这4条字节码指令（对应使用 <strong>new 关键字实例化对象</strong>、<strong>读取或设置类的静态字段</strong>（被 final 修饰、已在编译期把结果放入常量池的静态字段除外）以及<strong>调用一个类的静态方法</strong>几种情况）<br>（2） 反射调用。<br>（3） 初始化一个类时，如果父类没有进行过初始化，需要先触发父类初始化。<br>（4） 虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的类），虚拟机会先初始化主类。<br>（5） 但是用动态语言支持时，如果一个java.lang.invoke.MethodHandle实例后解析结果 REF_putStatic , REF_getStatic , REF_invokeStatic 的方法句柄时，当改方法句柄对应的类没有初始化时，需要初始化该类。<blockquote>
<p>接口初始化时并不要求其父类接口全部都初始化完成，只有在真正使用到父类接口时才会初始化。</p>
</blockquote>
</li>
</ul>
<blockquote>

        <h5 id="有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。"   >
          <a href="#有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。" class="heading-link"><i class="fas fa-link"></i></a><a href="#有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。" class="headerlink" title="有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。"></a>有且仅有上面五种情况会触发初始化，成为主动引用，除此之外，其他所有方式都不会触发初始化，称为被动引用。</h5>
      <p>被动引用举例：  </p>
<ul>
<li>通过子类引用父类的静态字段，不会导致子类的初始化。</li>
<li>通过数组定义来引用类，不会触发此类的初始化。</li>
<li>常量在编译阶段会存入调用类的常量池中，本质上并没有直接引用到定义常量的类，因此不会触发定义常量的类的初始化。</li>
</ul>
</blockquote>

        <h4 id="1-1-加载"   >
          <a href="#1-1-加载" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-加载" class="headerlink" title="1.1 加载"></a>1.1 加载</h4>
      <ol>
<li>通过一个类的全限定名来获取定义此类的二进制字节流<blockquote>
<p>获取途径：ZIP包（JAR、EAR、WAR）、网络（Applet）、运行时计算生成（动态代理）、其他文件（JSP应用）、数据库</p>
</blockquote>
</li>
<li>将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构</li>
<li>在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口<blockquote>
<ul>
<li>非数组类型使用引导类加载器或者用户自定义类加载器进行加载</li>
<li>数组的组件类型（去掉一个维度之后的类型）是引用类型，则按照普通类加载过程加载；不是引用类型，标记为与引导类加载器关联。</li>
<li>数组类可见性与组件类型可见性一致。如果组件类型不是引用类型，可见性默认为 public 。</li>
</ul>
</blockquote>
</li>
</ol>

        <h4 id="1-2-验证（非常重要但不一定必要）"   >
          <a href="#1-2-验证（非常重要但不一定必要）" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-验证（非常重要但不一定必要）" class="headerlink" title="1.2 验证（非常重要但不一定必要）"></a>1.2 验证（非常重要但不一定必要）</h4>
      <ol>
<li>文件格式验证：保证输入的字节流能正确地解析并存储于方法区之内，格式上符合描述一个Java类型信息的要求。<blockquote>
<p>经过此验证之后字节流才会进入内存方法区，后面3个验证阶段都是基于方法区中的存储结构</p>
</blockquote>
</li>
<li>元数据验证（语义分析）：保证不存在不符合语言规范的元数据信息。</li>
<li>字节码验证（并不能完全保证安全）：对类的方法体进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件。</li>
<li>符号引用验证：发生在虚拟机将符号引用转化为直接引用阶段，确保解析动作可以正常执行。</li>
</ol>

        <h4 id="1-3-准备"   >
          <a href="#1-3-准备" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-3-准备" class="headerlink" title="1.3 准备"></a>1.3 准备</h4>
      <p>为类变量（被 static 修饰的变量，不包括实例变量）分配内存并设置类变量初始值（一般是零值）。</p>
<blockquote>
<p>通常情况下初始化零值，如果存在 ConstantValue 属性，则指定为 ConstantValue 属性的值。<br><code>public static int value = 123;</code>此代码 value 准备阶段之后的结果为0；<br><code>public static final int value = 123;</code>此代码 value 准备阶段之后的结果为123。</p>
</blockquote>

        <h4 id="1-4-解析"   >
          <a href="#1-4-解析" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-4-解析" class="headerlink" title="1.4 解析"></a>1.4 解析</h4>
      <p>将常量池中的符号引用替换为直接引用。</p>
<blockquote>
<p>除invokeddynamic指令，其余需要进行解析的字节码指令都会对第一次解析结果进行缓存。<br>解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符七类符号引用进行。</p>
</blockquote>

        <h4 id="1-5-初始化"   >
          <a href="#1-5-初始化" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-5-初始化" class="headerlink" title="1.5 初始化"></a>1.5 初始化</h4>
      <p>执行类构造器<code>&lt;clinit&gt;()</code>方法。</p>
<ul>
<li>静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但不能访问。</li>
<li><code>&lt;clinit&gt;()</code>不需要显示调用父类的<code>&lt;clinit&gt;()</code>，由虚拟机保证父类<code>&lt;clinit&gt;()</code>执行。<br>第一个被执行的<code>&lt;clinit&gt;()</code>方法的类肯定是<code>java.lang.Object</code>。</li>
<li>父类中定义的静态语句块优于子类变量的复制操作。</li>
<li><code>&lt;clinit&gt;()</code>是非必需的（没有静态语句块和变量赋值操作）</li>
<li>接口不能使用静态语句块，但是可以对变量赋值。<br>只有父接口中定义的变量使用时，父接口才会初始化。</li>
<li>虚拟机保证一个类的<code>&lt;clinit&gt;()</code>方法在多线程环境下被正确的加锁、同步。</li>
</ul>

        <h3 id="2-类加载器"   >
          <a href="#2-类加载器" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-类加载器" class="headerlink" title="2. 类加载器"></a>2. 类加载器</h3>
      
        <h4 id="2-1-判断两个类相等"   >
          <a href="#2-1-判断两个类相等" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-判断两个类相等" class="headerlink" title="2.1 判断两个类相等"></a>2.1 判断两个类相等</h4>
      <ol>
<li>使用相同类加载器</li>
<li>全限定名相同</li>
</ol>

        <h4 id="2-2-双亲委派模型"   >
          <a href="#2-2-双亲委派模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-双亲委派模型" class="headerlink" title="2.2 双亲委派模型"></a>2.2 双亲委派模型</h4>
      <p><img src="https://images2018.cnblogs.com/blog/1256203/201807/1256203-20180714171531925-1737231049.png" alt="image"></p>

        <h5 id="双亲委派模型工作过程："   >
          <a href="#双亲委派模型工作过程：" class="heading-link"><i class="fas fa-link"></i></a><a href="#双亲委派模型工作过程：" class="headerlink" title="双亲委派模型工作过程："></a>双亲委派模型工作过程：</h5>
      <p>如果一个类加载器收到类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器完成。每个类加载器都是如此，只有当父加载器在自己的搜索范围内找不到指定的类时（即ClassNotFoundException），子加载器才会尝试自己去加载。</p>
<blockquote>
<p>类加载器之间的父子关系不会以继承实现，而是使用组合的方式。</p>
</blockquote>

        <h5 id="双亲委派模型的三次破坏"   >
          <a href="#双亲委派模型的三次破坏" class="heading-link"><i class="fas fa-link"></i></a><a href="#双亲委派模型的三次破坏" class="headerlink" title="双亲委派模型的三次破坏"></a>双亲委派模型的三次破坏</h5>
      <ul>
<li>第一次破坏是<strong>在jdk 1.2之前，用户自定义的类加载器都是重写Classloader中的loadClass方法</strong>,这样就导致每个自定义的类加载器其实是在使用自己的loadClass方法中的加载机制来进行加载,这种模式当然是不符合双亲委派机制的，也是无法保证同一个类在jvm中的唯一性的。为了向前兼容，java官方<strong>在Classloader中添加了findClass方法</strong>,用户只需要重新这个findClass方法，在loadClass方法的逻辑里，如果父类加载失败的时候，才会调用自己的findClass方法来完成类加载，这样就保证了写出的类加载器是符合双亲委派机制的。</li>
<li>第二次的破坏是由模型本身的缺陷导致的，<strong>根类加载器加载了基础代码，但是基础代码中有可能调用了用户的代码</strong>，但是对于根类加载器而言是不认识用户的代码的。<blockquote>
<p>那么这时候java团队使用了一个不太优雅的设计：线程上下文类加载器。这个类加载器可以通过Thread类的setContextClassLoader方法进行设置,如果创建线程时还未设置，它就从父线程继承一个，如果在应用全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。  </p>
</blockquote>
</li>
</ul>
<blockquote>
<p>利用这个线程上下文类加载器傅，父类加载器请求子类加载器去加载某些自己识别不了的类。</p>
</blockquote>
<blockquote>
<p>java中基本所有涉及spi的加载动作基本上都采用了这种方式，例如jndi，jdbc等。</p>
</blockquote>
<ul>
<li>第三次的破坏是因为<strong>用户对于程序的动态性追求，诸如：代码热替换，模块热部署</strong>。<br>目前业界Java模块化的标准是OSGI。而OSGI实现模块热部署的关键是他自己的类加载机制：每个程序模块(bundle)都有自己的类加载器，需要更换程序(bundle)的时候，连同类加载器一起替换，以实现代码的热部署。</li>
</ul>

        <h2 id="第八章-虚拟机字节码执行引擎"   >
          <a href="#第八章-虚拟机字节码执行引擎" class="heading-link"><i class="fas fa-link"></i></a><a href="#第八章-虚拟机字节码执行引擎" class="headerlink" title="第八章 虚拟机字节码执行引擎"></a>第八章 虚拟机字节码执行引擎</h2>
      
        <h3 id="1-运行时栈帧结构"   >
          <a href="#1-运行时栈帧结构" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-运行时栈帧结构" class="headerlink" title="1. 运行时栈帧结构"></a>1. 运行时栈帧结构</h3>
      <ul>
<li>包含<strong>局部变量表、操作数栈、动态连接和方法返回地址</strong>等信息。</li>
<li>编译时确定栈帧中的局部变量表大小。</li>
<li>一个栈帧需要分配多少内存不会受到程序运行期变量数据的影响，而仅仅取决于具体的虚拟机实现。</li>
<li>只有位于栈顶的栈帧（当前栈帧）才是有效的。</li>
</ul>

        <h4 id="1-1-局部变量表"   >
          <a href="#1-1-局部变量表" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-局部变量表" class="headerlink" title="1.1 局部变量表"></a>1.1 局部变量表</h4>
      <ul>
<li>以容量槽（Slot）为最小单位</li>
<li>每个Slot都应该能够存放一个boolean、byte、char、short、int、float、reference或returnAddress类型数据。</li>
<li>如果一个局部变量定义了但是没有赋初始值是不能使用的</li>
</ul>

        <h4 id="1-2-操作数栈"   >
          <a href="#1-2-操作数栈" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-操作数栈" class="headerlink" title="1.2 操作数栈"></a>1.2 操作数栈</h4>
      <ul>
<li>Java 虚拟机的解释执行引擎称为“基于栈的执行引擎”，其中所指的“栈”就是操作数栈</li>
</ul>

        <h4 id="1-3-动态连接"   >
          <a href="#1-3-动态连接" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-3-动态连接" class="headerlink" title="1.3 动态连接"></a>1.3 动态连接</h4>
      <p>指向运行时常量池中该栈帧所属方法的引用。<br><strong>静态解析</strong>：符号引用在类加载阶段或第一次使用时转化为直接引用。<br><strong>动态连接</strong>：符号引用在每一次运行期间转化为直接引用。</p>

        <h4 id="1-4-方法返回地址"   >
          <a href="#1-4-方法返回地址" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-4-方法返回地址" class="headerlink" title="1.4 方法返回地址"></a>1.4 方法返回地址</h4>
      <p>方法正常退出时，调用者的<strong>PC计数器</strong>的值可以作为返回地址，栈帧中很可能会保存这个计数器的值。<br>方法异常退出时，返回地址通过<strong>异常处理器</strong>表来确定，栈帧中一般不会保存这部分信息。<br><strong>方法退出过程：</strong></p>
<ol>
<li>恢复上层方法的局部变量表和操作数栈</li>
<li>把返回值压入调用者栈帧的操作数栈</li>
<li>调整PC计数器的值以指向方法调用指令后面的一条指令</li>
</ol>

        <h3 id="2-方法调用"   >
          <a href="#2-方法调用" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-方法调用" class="headerlink" title="2. 方法调用"></a>2. 方法调用</h3>
      
        <h4 id="2-1-解析"   >
          <a href="#2-1-解析" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-1-解析" class="headerlink" title="2.1 解析"></a>2.1 解析</h4>
      <ul>
<li>只要能被 invokestatic 和 invokespecial 指令调用的方法都可以在解析阶段确定唯一的调用版本。</li>
<li>符合上述条件的的有<strong>静态方法、私有方法、实例构造器、父类方法</strong> 4 种。都称为<strong>非虚方法</strong>。其余方法为<strong>虚方法</strong>。<blockquote>
<p>final 方法也是非虚方法。</p>
</blockquote>
</li>
</ul>

        <h4 id="2-2-分派（与多态特性有关）"   >
          <a href="#2-2-分派（与多态特性有关）" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-2-分派（与多态特性有关）" class="headerlink" title="2.2 分派（与多态特性有关）"></a>2.2 分派（与多态特性有关）</h4>
      <div class="table-container"><table>
<thead>
<tr>
<th>静态分派</th>
<th>动态分派</th>
</tr>
</thead>
<tbody><tr>
<td>编译阶段</td>
<td>运行阶段</td>
</tr>
<tr>
<td>重载</td>
<td>重写</td>
</tr>
<tr>
<td>多分派（关心静态类型与方法参数两个因素）</td>
<td>单分派（只关心方法接收者）</td>
</tr>
</tbody></table></div>

        <h5 id="（1）静态分派（重载）"   >
          <a href="#（1）静态分派（重载）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）静态分派（重载）" class="headerlink" title="（1）静态分派（重载）"></a>（1）静态分派（重载）</h5>
      <p>所有通过静态类型来定位方法执行版本的分派动作称为静态分派。</p>
<blockquote>
<ul>
<li>方法重载是静态分派的典型应用  </li>
<li>静态分派发生在编译阶段</li>
</ul>
</blockquote>
<p><code>Human man = new Man();</code><br><code>Human</code>为变量的<strong>静态类型</strong>，静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，并且最终的静态类型是在编译期可知的；<br><code>Man</code>为变量的<strong>实际类型</strong>，实际类型的变化结果在运行期才可以确定，编译期间不知道对象的实际类型。<br><strong>重载</strong>通过参数的<strong>静态类型而不是实际类型</strong>作为判定依据。</p>

        <h5 id="（2）动态分派（重写）"   >
          <a href="#（2）动态分派（重写）" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）动态分派（重写）" class="headerlink" title="（2）动态分派（重写）"></a>（2）动态分派（重写）</h5>
      <p>运行期根据实际类型确定方法执行版本的分派过程称为动态分派。</p>
<blockquote>
<p>根据操作数栈中的信息确定接受者的实际类型</p>
</blockquote>

        <h5 id="（3）单分派与多分派"   >
          <a href="#（3）单分派与多分派" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）单分派与多分派" class="headerlink" title="（3）单分派与多分派"></a>（3）单分派与多分派</h5>
      <p>方法的接收者与方法的参数统称为方法的<strong>宗量</strong>。<br><strong>单分派</strong>是根据一个宗量对目标方法进行选择，<strong>多分派</strong>则是根据多个宗量对目标方法进行选择。<br><strong>静态分派</strong>属于<strong>多分派</strong>，<strong>动态分派</strong>属于<strong>单分派</strong>。</p>

        <h5 id="（4）多分派的实现"   >
          <a href="#（4）多分派的实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#（4）多分派的实现" class="headerlink" title="（4）多分派的实现"></a>（4）多分派的实现</h5>
      <p>为类在方法区中建立<strong>虚方法表</strong>，存放各个方法的实际入口地址。<br>如果子类重写了父类函数，虚方法表中存放指向子类实现版本的入口地址；否则，与父类相同方法的入口地址一致。</p>

        <h2 id="第十二章-Java内存模型与线程"   >
          <a href="#第十二章-Java内存模型与线程" class="heading-link"><i class="fas fa-link"></i></a><a href="#第十二章-Java内存模型与线程" class="headerlink" title="第十二章 Java内存模型与线程"></a>第十二章 Java内存模型与线程</h2>
      
        <h3 id="1-Java内存模型"   >
          <a href="#1-Java内存模型" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-Java内存模型" class="headerlink" title="1. Java内存模型"></a>1. Java内存模型</h3>
      <div class="table-container"><table>
<thead>
<tr>
<th align="center">工作内存</th>
<th align="center">主内存</th>
</tr>
</thead>
<tbody><tr>
<td align="center">线程对变量读取、赋值等操作</td>
<td align="center">线程间变量值的传递</td>
</tr>
<tr>
<td align="center">虚拟机栈中的部分区域</td>
<td align="center">Java堆中的对象实例数据部分</td>
</tr>
</tbody></table></div>

        <h4 id="1-1-内存间的交互操作"   >
          <a href="#1-1-内存间的交互操作" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-内存间的交互操作" class="headerlink" title="1.1 内存间的交互操作"></a>1.1 内存间的交互操作</h4>
      <p><img src="https://img-blog.csdn.net/20180522220730109" alt="image"></p>
<ol>
<li>**lock(锁定)**：作用于主内存的变量，把一个变量标记为一条线程独占状态</li>
<li>**unlock(解锁)**：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定</li>
<li>**read(读取)**：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用</li>
<li>**load(载入)**：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中</li>
<li>**use(使用)**：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎</li>
<li>**assign(赋值)**：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量</li>
<li>**store(存储)**：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作</li>
<li>**write(写入)**：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中</li>
</ol>

        <h5 id="同步规则分析："   >
          <a href="#同步规则分析：" class="heading-link"><i class="fas fa-link"></i></a><a href="#同步规则分析：" class="headerlink" title="同步规则分析："></a>同步规则分析：</h5>
      <ol>
<li>不允许read和load、store和write操作之一单独出现，以上两个操作必须按顺序执行，但没有保证必须连续执行，也就是说，read与load之间、store与write之间是可插入其他指令的。</li>
<li>不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。</li>
<li>不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步会主内存中</li>
<li>一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或者assign）的变量。即就是对一个变量实施use和store操作之前，必须先自行assign和load操作。</li>
<li>一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现。</li>
<li>如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量之前需要重新执行load或assign操作初始化变量的值。</li>
<li>如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。</li>
<li>对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）</li>
</ol>

        <h4 id="2-3-volatile"   >
          <a href="#2-3-volatile" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-3-volatile" class="headerlink" title="2.3 volatile"></a>2.3 volatile</h4>
      
        <h5 id="1-保证可见性，read与load、aggsin与store两两不分开。"   >
          <a href="#1-保证可见性，read与load、aggsin与store两两不分开。" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-保证可见性，read与load、aggsin与store两两不分开。" class="headerlink" title="1. 保证可见性，read与load、aggsin与store两两不分开。"></a>1. 保证可见性，read与load、aggsin与store两两不分开。</h5>
      
        <h5 id="2-禁止指令重排序优化，内存屏障"   >
          <a href="#2-禁止指令重排序优化，内存屏障" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-禁止指令重排序优化，内存屏障" class="headerlink" title="2. 禁止指令重排序优化，内存屏障"></a>2. 禁止指令重排序优化，内存屏障</h5>
      
        <h4 id="2-4-long与double型变量的特殊规则"   >
          <a href="#2-4-long与double型变量的特殊规则" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-4-long与double型变量的特殊规则" class="headerlink" title="2.4 long与double型变量的特殊规则"></a>2.4 long与double型变量的特殊规则</h4>
      <p>虚拟机不保证64位数据类型的load、store、read和write这四个操作的原子性。</p>
<blockquote>
<p>目前的商用虚拟机保证了64位数据的类型读写操作的原子性</p>
</blockquote>

        <h4 id="2-5-原子性、可见性与有序性"   >
          <a href="#2-5-原子性、可见性与有序性" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-5-原子性、可见性与有序性" class="headerlink" title="2.5 原子性、可见性与有序性"></a>2.5 原子性、可见性与有序性</h4>
      
        <h5 id="（1）原子性"   >
          <a href="#（1）原子性" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）原子性" class="headerlink" title="（1）原子性"></a>（1）原子性</h5>
      <ul>
<li>基本数据类型具备原子性</li>
<li><code>sychronized</code> 关键字保证更大范围内的原子性</li>
</ul>

        <h5 id="（2）可见性"   >
          <a href="#（2）可见性" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）可见性" class="headerlink" title="（2）可见性"></a>（2）可见性</h5>
      <ul>
<li><code>volatile</code>、<code>sychronized</code>和<code>final</code>三个关键字实现可见性。</li>
<li><code>final</code>关键字的可见性：<br>被 final 修饰的字段在构造器中一旦初始化完成，并且构造器没有把<code>this</code>的引用传递出去，那在其他线程中就能看到 final 字段的值。</li>
</ul>

        <h5 id="（3）有序性"   >
          <a href="#（3）有序性" class="heading-link"><i class="fas fa-link"></i></a><a href="#（3）有序性" class="headerlink" title="（3）有序性"></a>（3）有序性</h5>
      <ul>
<li><code>volatile</code>和<code>sychronized</code>两个关键字实现有序性。</li>
<li>如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。</li>
</ul>

        <h4 id="2-6-先行发生原则（happens-before）"   >
          <a href="#2-6-先行发生原则（happens-before）" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-6-先行发生原则（happens-before）" class="headerlink" title="2.6 先行发生原则（happens-before）"></a>2.6 先行发生原则（happens-before）</h4>
      
        <h5 id="（1）定义"   >
          <a href="#（1）定义" class="heading-link"><i class="fas fa-link"></i></a><a href="#（1）定义" class="headerlink" title="（1）定义"></a>（1）定义</h5>
      <ol>
<li>如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。</li>
<li>两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。</li>
</ol>

        <h5 id="（2）具体规则"   >
          <a href="#（2）具体规则" class="heading-link"><i class="fas fa-link"></i></a><a href="#（2）具体规则" class="headerlink" title="（2）具体规则"></a>（2）具体规则</h5>
      <ol>
<li><strong>程序顺序规则</strong>：一个线程中的每个操作，happens-before于该线程中的任意后续操作。</li>
<li><strong>监视器锁规则</strong>：对一个锁的解锁，happens-before于随后对这个锁的加锁。</li>
<li><strong>volatile变量规则</strong>：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。</li>
<li><strong>传递性</strong>：如果A happens-before B，且B happens-before C，那么A happens-before C。</li>
<li><strong>start()规则</strong>：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。</li>
<li><strong>join()规则</strong>：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。</li>
<li><strong>程序中断规则</strong>：对线程interrupted()方法的调用先行于被中断线程的代码检测到中断时间的发生。</li>
<li><strong>对象finalize规则</strong>：一个对象的初始化完成（构造函数执行结束）先行于发生它的finalize()方法的开始。</li>
</ol>

        <h3 id="Java与线程"   >
          <a href="#Java与线程" class="heading-link"><i class="fas fa-link"></i></a><a href="#Java与线程" class="headerlink" title="Java与线程"></a>Java与线程</h3>
      <blockquote>
<p>在Java中，JDK1.2之前由用户线程实现，JDK1.2之后使用基于操作系统原生线程模型实现，win和linux都是用的一对一的线程模型（一条Java线程映射到一条轻量级进程中）。</p>
</blockquote>

        <h4 id="1-线程的实现"   >
          <a href="#1-线程的实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-线程的实现" class="headerlink" title="1. 线程的实现"></a>1. 线程的实现</h4>
      
        <h5 id="1-1-使用内核线程实现"   >
          <a href="#1-1-使用内核线程实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-1-使用内核线程实现" class="headerlink" title="1.1 使用内核线程实现"></a>1.1 使用内核线程实现</h5>
      <ul>
<li>不直接使用内核线程，而是使用内核线程的高级接口：轻量级进程。</li>
<li>轻量级进程与内核线程的数量比为 1 ：1。</li>
<li>轻量级进程消耗内核资源，一个系统支持的轻量级进程的数量是有限的。</li>
</ul>

        <h5 id="1-2-使用用户线程实现（实现复杂，没有使用）"   >
          <a href="#1-2-使用用户线程实现（实现复杂，没有使用）" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-2-使用用户线程实现（实现复杂，没有使用）" class="headerlink" title="1.2 使用用户线程实现（实现复杂，没有使用）"></a>1.2 使用用户线程实现（实现复杂，没有使用）</h5>
      <ul>
<li>进程与用户线程之间是 1 ：N 的关系</li>
</ul>

        <h5 id="1-3-使用用户线程加轻量级进程混合实现"   >
          <a href="#1-3-使用用户线程加轻量级进程混合实现" class="heading-link"><i class="fas fa-link"></i></a><a href="#1-3-使用用户线程加轻量级进程混合实现" class="headerlink" title="1.3 使用用户线程加轻量级进程混合实现"></a>1.3 使用用户线程加轻量级进程混合实现</h5>
      <ul>
<li>用户线程与轻量级进程之间是 N:M 的关系。</li>
</ul>

        <h4 id="2-线程调度"   >
          <a href="#2-线程调度" class="heading-link"><i class="fas fa-link"></i></a><a href="#2-线程调度" class="headerlink" title="2. 线程调度"></a>2. 线程调度</h4>
      <ul>
<li>协同式线程调度：实现简单，但线程执行时间不可控</li>
<li>抢占式线程调度：Java一共10个优先级，但windows系统只有7个</li>
</ul>

        <h4 id="3-状态转换"   >
          <a href="#3-状态转换" class="heading-link"><i class="fas fa-link"></i></a><a href="#3-状态转换" class="headerlink" title="3. 状态转换"></a>3. 状态转换</h4>
      <p><img src="https://pic2.zhimg.com/80/v2-326a2be9b86b1446d75b6f52f54c98fb_hd.jpg" alt="线程状态转移图"></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka源码学习：KafkaApis-LEADER_AND_ISR</title>
    <url>/2021/06/05/kafka%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%EF%BC%9AKafkaApis-LEADER-AND-ISR/</url>
    <content><![CDATA[<blockquote>
<p>本文源码基于kafka 0.10.2版本</p>
</blockquote>
<p>​    每当controller发生状态变更时，都会通过调用<code>sendRequestsToBrokers</code>方法发送<code>leaderAndIsrRequest</code>请求，本文主要介绍kafka服务端处理该请求的逻辑和过程。</p>
<span id="more"></span>


        <h1 id="LEADER-AND-ISR"   >
          <a href="#LEADER-AND-ISR" class="heading-link"><i class="fas fa-link"></i></a><a href="#LEADER-AND-ISR" class="headerlink" title="LEADER_AND_ISR"></a>LEADER_AND_ISR</h1>
      
        <h2 id="整体逻辑流程"   >
          <a href="#整体逻辑流程" class="heading-link"><i class="fas fa-link"></i></a><a href="#整体逻辑流程" class="headerlink" title="整体逻辑流程"></a>整体逻辑流程</h2>
      <figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="type">ApiKeys</span>.<span class="type">LEADER_AND_ISR</span> =&gt; handleLeaderAndIsrRequest(request)</span><br></pre></td></tr></table></div></figure>

<p>在server端收到LEADER_AND_ISR请求后，会调用<code>handleLeaderAndIsrRequest</code>方法进行处理，该方法的处理流程如图所示：</p>
<p><img src="%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="流程图"></p>

        <h2 id="源码"   >
          <a href="#源码" class="heading-link"><i class="fas fa-link"></i></a><a href="#源码" class="headerlink" title="源码"></a>源码</h2>
      
        <h3 id="handleLeaderAndIsrRequest"   >
          <a href="#handleLeaderAndIsrRequest" class="heading-link"><i class="fas fa-link"></i></a><a href="#handleLeaderAndIsrRequest" class="headerlink" title="handleLeaderAndIsrRequest"></a>handleLeaderAndIsrRequest</h3>
      <p><code>handleLeaderAndIsrRequest</code>函数的逻辑结果主要分为以下几个部分：</p>
<ol>
<li>构造callback函数<code>onLeadershipChange</code>,用来回调coordinator处理新增的leader或者follower节点</li>
<li>校验请求权限，如果校验成功调用<code>replicaManager.becomeLeaderOrFollower(correlationId, leaderAndIsrRequest, metadataCache, onLeadershipChange)</code>进行后续处理【此处该函数的主流程】，否则，直接返回错误码<code>Errors.CLUSTER_AUTHORIZATION_FAILED.code</code></li>
</ol>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">handleLeaderAndIsrRequest</span></span>(request: <span class="type">RequestChannel</span>.<span class="type">Request</span>) &#123;</span><br><span class="line">    <span class="comment">// ensureTopicExists is only for client facing requests</span></span><br><span class="line">    <span class="comment">// We can&#x27;t have the ensureTopicExists check here since the controller sends it as an advisory to all brokers so they</span></span><br><span class="line">    <span class="comment">// stop serving data to clients for the topic being deleted</span></span><br><span class="line">    <span class="keyword">val</span> correlationId = request.header.correlationId</span><br><span class="line">    <span class="keyword">val</span> leaderAndIsrRequest = request.body.asInstanceOf[<span class="type">LeaderAndIsrRequest</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">onLeadershipChange</span></span>(updatedLeaders: <span class="type">Iterable</span>[<span class="type">Partition</span>], updatedFollowers: <span class="type">Iterable</span>[<span class="type">Partition</span>]) &#123;</span><br><span class="line">        <span class="comment">// for each new leader or follower, call coordinator to handle consumer group migration.</span></span><br><span class="line">        <span class="comment">// this callback is invoked under the replica state change lock to ensure proper order of</span></span><br><span class="line">        <span class="comment">// leadership changes</span></span><br><span class="line">        updatedLeaders.foreach &#123; partition =&gt;</span><br><span class="line">          <span class="keyword">if</span> (partition.topic == <span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>)</span><br><span class="line">            coordinator.handleGroupImmigration(partition.partitionId)</span><br><span class="line">        &#125;</span><br><span class="line">        updatedFollowers.foreach &#123; partition =&gt;</span><br><span class="line">          <span class="keyword">if</span> (partition.topic == <span class="type">Topic</span>.<span class="type">GroupMetadataTopicName</span>)</span><br><span class="line">            coordinator.handleGroupEmigration(partition.partitionId)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">val</span> leaderAndIsrResponse =</span><br><span class="line">        <span class="keyword">if</span> (authorize(request.session, <span class="type">ClusterAction</span>, <span class="type">Resource</span>.<span class="type">ClusterResource</span>)) &#123;</span><br><span class="line">          <span class="keyword">val</span> result = replicaManager.becomeLeaderOrFollower(correlationId, leaderAndIsrRequest, metadataCache, onLeadershipChange)</span><br><span class="line">          <span class="keyword">new</span> <span class="type">LeaderAndIsrResponse</span>(result.errorCode, result.responseMap.mapValues(<span class="keyword">new</span> <span class="type">JShort</span>(_)).asJava)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="keyword">val</span> result = leaderAndIsrRequest.partitionStates.asScala.keys.map((_, <span class="keyword">new</span> <span class="type">JShort</span>(<span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.code))).toMap</span><br><span class="line">          <span class="keyword">new</span> <span class="type">LeaderAndIsrResponse</span>(<span class="type">Errors</span>.<span class="type">CLUSTER_AUTHORIZATION_FAILED</span>.code, result.asJava)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      requestChannel.sendResponse(<span class="keyword">new</span> <span class="type">Response</span>(request, leaderAndIsrResponse))</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">KafkaStorageException</span> =&gt;</span><br><span class="line">        fatal(<span class="string">&quot;Disk error during leadership change.&quot;</span>, e)</span><br><span class="line">        <span class="type">Runtime</span>.getRuntime.halt(<span class="number">1</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="becomeLeaderOrFollower"   >
          <a href="#becomeLeaderOrFollower" class="heading-link"><i class="fas fa-link"></i></a><a href="#becomeLeaderOrFollower" class="headerlink" title="becomeLeaderOrFollower"></a>becomeLeaderOrFollower</h3>
      <p><code>ReplicaManager</code>的主要工作有以下几个部分，具体代码位置见中文注释：</p>
<ol>
<li>校验controller epoch是否合规，只处理比自己epoch大且本地有副本的tp的请求</li>
<li>调用<code>makeLeaders</code>和<code>makeFollowers</code>方法构造新增的leader partition和follower partition【此处为主要逻辑，后面小结详细介绍】</li>
<li>如果是第一次收到请求，启动定时更新hw的线程</li>
<li>停掉空的Fetcher线程</li>
<li>调用回调函数，coordinator处理新增的leader partition和follower partition</li>
</ol>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">becomeLeaderOrFollower</span></span>(correlationId: <span class="type">Int</span>,leaderAndISRRequest: <span class="type">LeaderAndIsrRequest</span>,</span><br><span class="line">                           metadataCache: <span class="type">MetadataCache</span>,</span><br><span class="line">                           onLeadershipChange: (<span class="type">Iterable</span>[<span class="type">Partition</span>], <span class="type">Iterable</span>[<span class="type">Partition</span>]) =&gt; <span class="type">Unit</span>): <span class="type">BecomeLeaderOrFollowerResult</span> = &#123;</span><br><span class="line">    leaderAndISRRequest.partitionStates.asScala.foreach &#123; <span class="keyword">case</span> (topicPartition, stateInfo) =&gt;</span><br><span class="line">        stateChangeLogger.trace(<span class="string">&quot;Broker %d received LeaderAndIsr request %s correlation id %d from controller %d epoch %d for partition [%s,%d]&quot;</span></span><br><span class="line">                                .format(localBrokerId, stateInfo, correlationId,</span><br><span class="line">                                        leaderAndISRRequest.controllerId, leaderAndISRRequest.controllerEpoch, topicPartition.topic, topicPartition.partition))</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//主要代码，构造返回结果</span></span><br><span class="line">    replicaStateChangeLock synchronized &#123;</span><br><span class="line">        <span class="keyword">val</span> responseMap = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>]</span><br><span class="line">        <span class="comment">//如果controller epoch不正确，直接返回Errors.STALE_CONTROLLER_EPOCH.code错误码</span></span><br><span class="line">        <span class="keyword">if</span> (leaderAndISRRequest.controllerEpoch &lt; controllerEpoch) &#123;</span><br><span class="line">            stateChangeLogger.warn((<span class="string">&quot;Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d since &quot;</span> +</span><br><span class="line">                                    <span class="string">&quot;its controller epoch %d is old. Latest known controller epoch is %d&quot;</span>).format(localBrokerId, leaderAndISRRequest.controllerId,</span><br><span class="line">                                                                                                                  correlationId, leaderAndISRRequest.controllerEpoch, controllerEpoch))</span><br><span class="line">            <span class="type">BecomeLeaderOrFollowerResult</span>(responseMap, <span class="type">Errors</span>.<span class="type">STALE_CONTROLLER_EPOCH</span>.code)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">val</span> controllerId = leaderAndISRRequest.controllerId</span><br><span class="line">            controllerEpoch = leaderAndISRRequest.controllerEpoch</span><br><span class="line"></span><br><span class="line">            <span class="comment">// First check partition&#x27;s leader epoch</span></span><br><span class="line">            <span class="comment">//校验所有的partition信息，分为以下3种情况：</span></span><br><span class="line">            <span class="comment">//1. 本地不包含该partition，返回Errors.UNKNOWN_TOPIC_OR_PARTITION.code</span></span><br><span class="line">            <span class="comment">//2. 本地包含该partition，controller epoch比本地epoch大，信息正确</span></span><br><span class="line">            <span class="comment">//3. controller epoch比本地epoch小，返回Errors.STALE_CONTROLLER_EPOCH.code</span></span><br><span class="line">            <span class="keyword">val</span> partitionState = <span class="keyword">new</span> mutable.<span class="type">HashMap</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>]()</span><br><span class="line">            leaderAndISRRequest.partitionStates.asScala.foreach &#123; <span class="keyword">case</span> (topicPartition, stateInfo) =&gt;</span><br><span class="line">                <span class="keyword">val</span> partition = getOrCreatePartition(topicPartition)</span><br><span class="line">                <span class="keyword">val</span> partitionLeaderEpoch = partition.getLeaderEpoch</span><br><span class="line">                <span class="comment">// If the leader epoch is valid record the epoch of the controller that made the leadership decision.</span></span><br><span class="line">                <span class="comment">// This is useful while updating the isr to maintain the decision maker controller&#x27;s epoch in the zookeeper path</span></span><br><span class="line">                <span class="keyword">if</span> (partitionLeaderEpoch &lt; stateInfo.leaderEpoch) &#123;</span><br><span class="line">                    <span class="keyword">if</span>(stateInfo.replicas.contains(localBrokerId))</span><br><span class="line">                    partitionState.put(partition, stateInfo)</span><br><span class="line">                    <span class="keyword">else</span> &#123;</span><br><span class="line">                        stateChangeLogger.warn((<span class="string">&quot;Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d &quot;</span> +</span><br><span class="line">                                                <span class="string">&quot;epoch %d for partition [%s,%d] as itself is not in assigned replica list %s&quot;</span>)</span><br><span class="line">                                               .format(localBrokerId, controllerId, correlationId, leaderAndISRRequest.controllerEpoch,</span><br><span class="line">                                                       topicPartition.topic, topicPartition.partition, stateInfo.replicas.asScala.mkString(<span class="string">&quot;,&quot;</span>)))</span><br><span class="line">                        responseMap.put(topicPartition, <span class="type">Errors</span>.<span class="type">UNKNOWN_TOPIC_OR_PARTITION</span>.code)</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="comment">// Otherwise record the error code in response</span></span><br><span class="line">                    stateChangeLogger.warn((<span class="string">&quot;Broker %d ignoring LeaderAndIsr request from controller %d with correlation id %d &quot;</span> +</span><br><span class="line">                                            <span class="string">&quot;epoch %d for partition [%s,%d] since its associated leader epoch %d is not higher than the current leader epoch %d&quot;</span>)</span><br><span class="line">                                           .format(localBrokerId, controllerId, correlationId, leaderAndISRRequest.controllerEpoch,</span><br><span class="line">                                                   topicPartition.topic, topicPartition.partition, stateInfo.leaderEpoch, partitionLeaderEpoch))</span><br><span class="line">                    responseMap.put(topicPartition, <span class="type">Errors</span>.<span class="type">STALE_CONTROLLER_EPOCH</span>.code)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//处理leader&amp;follower副本，构造partitionsBecomeLeader和partitionsBecomeFollower供callback处理（coordinator处理）</span></span><br><span class="line">            <span class="keyword">val</span> partitionsTobeLeader = partitionState.filter &#123; <span class="keyword">case</span> (_, stateInfo) =&gt;</span><br><span class="line">                stateInfo.leader == localBrokerId</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">val</span> partitionsToBeFollower = partitionState -- partitionsTobeLeader.keys</span><br><span class="line"></span><br><span class="line">            <span class="keyword">val</span> partitionsBecomeLeader = <span class="keyword">if</span> (partitionsTobeLeader.nonEmpty)</span><br><span class="line">            <span class="comment">// 主要调用</span></span><br><span class="line">            makeLeaders(controllerId, controllerEpoch, partitionsTobeLeader, correlationId, responseMap)</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            <span class="type">Set</span>.empty[<span class="type">Partition</span>]</span><br><span class="line">            <span class="keyword">val</span> partitionsBecomeFollower = <span class="keyword">if</span> (partitionsToBeFollower.nonEmpty)</span><br><span class="line">            <span class="comment">// 主要调用</span></span><br><span class="line">            makeFollowers(controllerId, controllerEpoch, partitionsToBeFollower, correlationId, responseMap, metadataCache)</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">            <span class="type">Set</span>.empty[<span class="type">Partition</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment">// we initialize highwatermark thread after the first leaderisrrequest. This ensures that all the partitions</span></span><br><span class="line">            <span class="comment">// have been completely populated before starting the checkpointing there by avoiding weird race conditions</span></span><br><span class="line">            <span class="comment">// 在第一次收到收到请求后，就会启动Scheduler，定时更新hw checkpoint</span></span><br><span class="line">            <span class="keyword">if</span> (!hwThreadInitialized) &#123;</span><br><span class="line">                startHighWaterMarksCheckPointThread()</span><br><span class="line">                hwThreadInitialized = <span class="literal">true</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 因为上面更新了元信息，此处检查停掉不必要的Fetcher线程</span></span><br><span class="line">            replicaFetcherManager.shutdownIdleFetcherThreads()</span><br><span class="line">            <span class="comment">// 回调</span></span><br><span class="line">            onLeadershipChange(partitionsBecomeLeader, partitionsBecomeFollower)</span><br><span class="line">            <span class="type">BecomeLeaderOrFollowerResult</span>(responseMap, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="makeLeaders"   >
          <a href="#makeLeaders" class="heading-link"><i class="fas fa-link"></i></a><a href="#makeLeaders" class="headerlink" title="makeLeaders"></a>makeLeaders</h3>
      <p>处理新增的leader partition</p>
<ol>
<li>停止这些partition的follower线程</li>
<li>更新这些partition的metadata cache</li>
<li>构造新增leader集合</li>
</ol>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeLeaders</span></span>(controllerId: <span class="type">Int</span>,</span><br><span class="line">                          epoch: <span class="type">Int</span>,</span><br><span class="line">                          partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</span><br><span class="line">                          correlationId: <span class="type">Int</span>,</span><br><span class="line">                          responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>]): <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</span><br><span class="line">    <span class="comment">// 构造becomeLeaderOrFollower需要的返回结果</span></span><br><span class="line">    <span class="keyword">for</span> (partition &lt;- partitionState.keys)</span><br><span class="line">      responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> partitionsToMakeLeaders: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// First stop fetchers for all the partitions</span></span><br><span class="line">      <span class="comment">// 停止Fetcher线程 </span></span><br><span class="line">        replicaFetcherManager.removeFetcherForPartitions(partitionState.keySet.map(_.topicPartition))</span><br><span class="line">      <span class="comment">// Update the partition information to be the leader</span></span><br><span class="line">      <span class="comment">// 构造新增leader partition集合</span></span><br><span class="line">      partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (partition.makeLeader(controllerId, partitionStateInfo, correlationId))</span><br><span class="line">          partitionsToMakeLeaders += partition</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">          stateChangeLogger.info((<span class="string">&quot;Broker %d skipped the become-leader state change after marking its partition as leader with correlation id %d from &quot;</span> +</span><br><span class="line">            <span class="string">&quot;controller %d epoch %d for partition %s since it is already the leader for the partition.&quot;</span>)</span><br><span class="line">            .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</span><br><span class="line">      &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        partitionState.keys.foreach &#123; partition =&gt;</span><br><span class="line">          <span class="keyword">val</span> errorMsg = (<span class="string">&quot;Error on broker %d while processing LeaderAndIsr request correlationId %d received from controller %d&quot;</span> +</span><br><span class="line">            <span class="string">&quot; epoch %d for partition %s&quot;</span>).format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition)</span><br><span class="line">          stateChangeLogger.error(errorMsg, e)</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></span><br><span class="line">        <span class="keyword">throw</span> e</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    partitionsToMakeLeaders</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure>

<p><code>partition.makeLeader(controllerId, partitionStateInfo, correlationId)</code>会进行元信息的处理，并更新hw，此方法会调用<code>maybeIncrementLeaderHW</code>函数，该函数会尝试追赶hw：<strong>如果其他副本落后leader不太远，并且比之前的hw大，会延缓hw增长速度，尽可能让其他副本进队。</strong></p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeLeader</span></span>(controllerId: <span class="type">Int</span>, partitionStateInfo: <span class="type">PartitionState</span>, correlationId: <span class="type">Int</span>): <span class="type">Boolean</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> (leaderHWIncremented, isNewLeader) = inWriteLock(leaderIsrUpdateLock) &#123;</span><br><span class="line">      <span class="keyword">val</span> allReplicas = partitionStateInfo.replicas.asScala.map(_.toInt)</span><br><span class="line">      <span class="comment">// record the epoch of the controller that made the leadership decision. This is useful while updating the isr</span></span><br><span class="line">      <span class="comment">// to maintain the decision maker controller&#x27;s epoch in the zookeeper path</span></span><br><span class="line">      controllerEpoch = partitionStateInfo.controllerEpoch</span><br><span class="line">      <span class="comment">// add replicas that are new</span></span><br><span class="line">      <span class="comment">// 构造新ISR</span></span><br><span class="line">      allReplicas.foreach(replica =&gt; getOrCreateReplica(replica))</span><br><span class="line">      <span class="keyword">val</span> newInSyncReplicas = partitionStateInfo.isr.asScala.map(r =&gt; getOrCreateReplica(r)).toSet</span><br><span class="line">      <span class="comment">// remove assigned replicas that have been removed by the controller</span></span><br><span class="line">      <span class="comment">// 移除所有不在新ISR中的副本</span></span><br><span class="line">      (assignedReplicas.map(_.brokerId) -- allReplicas).foreach(removeReplica)</span><br><span class="line">      inSyncReplicas = newInSyncReplicas</span><br><span class="line">      leaderEpoch = partitionStateInfo.leaderEpoch</span><br><span class="line">      zkVersion = partitionStateInfo.zkVersion</span><br><span class="line">      <span class="comment">//是否第一次成为该partition的leader</span></span><br><span class="line">      <span class="keyword">val</span> isNewLeader =</span><br><span class="line">        <span class="keyword">if</span> (leaderReplicaIdOpt.isDefined &amp;&amp; leaderReplicaIdOpt.get == localBrokerId) &#123;</span><br><span class="line">          <span class="literal">false</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          leaderReplicaIdOpt = <span class="type">Some</span>(localBrokerId)</span><br><span class="line">          <span class="literal">true</span></span><br><span class="line">        &#125;</span><br><span class="line">      <span class="keyword">val</span> leaderReplica = getReplica().get</span><br><span class="line">      <span class="keyword">val</span> curLeaderLogEndOffset = leaderReplica.logEndOffset.messageOffset</span><br><span class="line">      <span class="keyword">val</span> curTimeMs = time.milliseconds</span><br><span class="line">      <span class="comment">// initialize lastCaughtUpTime of replicas as well as their lastFetchTimeMs and lastFetchLeaderLogEndOffset.</span></span><br><span class="line">      <span class="comment">//新leader初始化</span></span><br><span class="line">      (assignedReplicas - leaderReplica).foreach &#123; replica =&gt;</span><br><span class="line">        <span class="keyword">val</span> lastCaughtUpTimeMs = <span class="keyword">if</span> (inSyncReplicas.contains(replica)) curTimeMs <span class="keyword">else</span> <span class="number">0</span>L</span><br><span class="line">        replica.resetLastCaughtUpTime(curLeaderLogEndOffset, curTimeMs, lastCaughtUpTimeMs)</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// we may need to increment high watermark since ISR could be down to 1</span></span><br><span class="line">      <span class="keyword">if</span> (isNewLeader) &#123;</span><br><span class="line">        <span class="comment">// construct the high watermark metadata for the new leader replica</span></span><br><span class="line">        leaderReplica.convertHWToLocalOffsetMetadata()</span><br><span class="line">        <span class="comment">// reset log end offset for remote replicas</span></span><br><span class="line">        assignedReplicas.filter(_.brokerId != localBrokerId).foreach(_.updateLogReadResult(<span class="type">LogReadResult</span>.<span class="type">UnknownLogReadResult</span>))</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">//  尝试追赶hw,如果其他副本落后leader不太远，并且比之前的hw大，会延缓hw增长速度，尽可能让其他副本进队</span></span><br><span class="line">      (maybeIncrementLeaderHW(leaderReplica), isNewLeader)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// some delayed operations may be unblocked after HW changed</span></span><br><span class="line">    <span class="comment">//  hw更新后会处理一些request</span></span><br><span class="line">    <span class="keyword">if</span> (leaderHWIncremented)</span><br><span class="line">      tryCompleteDelayedRequests()</span><br><span class="line">    isNewLeader</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure>


        <h3 id="makeFollowers"   >
          <a href="#makeFollowers" class="heading-link"><i class="fas fa-link"></i></a><a href="#makeFollowers" class="headerlink" title="makeFollowers"></a>makeFollowers</h3>
      <p>处理新增的follower partition</p>
<ol>
<li>从leaderpartition集合中移除这些partition</li>
<li>标记为follower，阻止producer请求</li>
<li>移除Fetcher线程</li>
<li>根据hw truncate这些partition的本地日志</li>
<li>清理producer和fetch请求</li>
<li>如果没有宕机，从新的leader fetch数据</li>
</ol>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">makeFollowers</span></span>(controllerId: <span class="type">Int</span>,</span><br><span class="line">                          epoch: <span class="type">Int</span>,</span><br><span class="line">                          partitionState: <span class="type">Map</span>[<span class="type">Partition</span>, <span class="type">PartitionState</span>],</span><br><span class="line">                          correlationId: <span class="type">Int</span>,</span><br><span class="line">                          responseMap: mutable.<span class="type">Map</span>[<span class="type">TopicPartition</span>, <span class="type">Short</span>],</span><br><span class="line">                          metadataCache: <span class="type">MetadataCache</span>) : <span class="type">Set</span>[<span class="type">Partition</span>] = &#123;</span><br><span class="line">    partitionState.keys.foreach &#123; partition =&gt;</span><br><span class="line">        stateChangeLogger.trace((<span class="string">&quot;Broker %d handling LeaderAndIsr request correlationId %d from controller %d epoch %d &quot;</span> +</span><br><span class="line">                                 <span class="string">&quot;starting the become-follower transition for partition %s&quot;</span>)</span><br><span class="line">                                .format(localBrokerId, correlationId, controllerId, epoch, partition.topicPartition))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 构造becomeLeaderOrFollower需要的返回结果</span></span><br><span class="line">    <span class="keyword">for</span> (partition &lt;- partitionState.keys)</span><br><span class="line">    responseMap.put(partition.topicPartition, <span class="type">Errors</span>.<span class="type">NONE</span>.code)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> partitionsToMakeFollower: mutable.<span class="type">Set</span>[<span class="type">Partition</span>] = mutable.<span class="type">Set</span>()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// <span class="doctag">TODO:</span> Delete leaders from LeaderAndIsrRequest</span></span><br><span class="line">        partitionState.foreach&#123; <span class="keyword">case</span> (partition, partitionStateInfo) =&gt;</span><br><span class="line">            <span class="keyword">val</span> newLeaderBrokerId = partitionStateInfo.leader</span><br><span class="line">            metadataCache.getAliveBrokers.find(_.id == newLeaderBrokerId) <span class="keyword">match</span> &#123;</span><br><span class="line">                <span class="comment">// Only change partition state when the leader is available</span></span><br><span class="line">                <span class="keyword">case</span> <span class="type">Some</span>(_) =&gt;</span><br><span class="line">                <span class="comment">// 构造返回结果</span></span><br><span class="line">                <span class="keyword">if</span> (partition.makeFollower(controllerId, partitionStateInfo, correlationId))</span><br><span class="line">                partitionsToMakeFollower += partition</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                stateChangeLogger.info((<span class="string">&quot;Broker %d skipped the become-follower state change after marking its partition as follower with correlation id %d from &quot;</span> +</span><br><span class="line">                                        <span class="string">&quot;controller %d epoch %d for partition %s since the new leader %d is the same as the old leader&quot;</span>)</span><br><span class="line">                                       .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</span><br><span class="line">                                               partition.topicPartition, newLeaderBrokerId))</span><br><span class="line">                <span class="keyword">case</span> <span class="type">None</span> =&gt;</span><br><span class="line">                <span class="comment">// The leader broker should always be present in the metadata cache.</span></span><br><span class="line">                <span class="comment">// If not, we should record the error message and abort the transition process for this partition</span></span><br><span class="line">                stateChangeLogger.error((<span class="string">&quot;Broker %d received LeaderAndIsrRequest with correlation id %d from controller&quot;</span> +</span><br><span class="line">                                         <span class="string">&quot; %d epoch %d for partition %s but cannot become follower since the new leader %d is unavailable.&quot;</span>)</span><br><span class="line">                                        .format(localBrokerId, correlationId, controllerId, partitionStateInfo.controllerEpoch,</span><br><span class="line">                                                partition.topicPartition, newLeaderBrokerId))</span><br><span class="line">                <span class="comment">// Create the local replica even if the leader is unavailable. This is required to ensure that we include</span></span><br><span class="line">                <span class="comment">// the partition&#x27;s high watermark in the checkpoint file (see KAFKA-1647)</span></span><br><span class="line">                partition.getOrCreateReplica()</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">//移除Fetcher线程</span></span><br><span class="line">        replicaFetcherManager.removeFetcherForPartitions(partitionsToMakeFollower.map(_.topicPartition))</span><br><span class="line">        <span class="comment">//根据新hw进行truncate</span></span><br><span class="line">        logManager.truncateTo(partitionsToMakeFollower.map &#123; partition =&gt;</span><br><span class="line">            (partition.topicPartition, partition.getOrCreateReplica().highWatermark.messageOffset)</span><br><span class="line">        &#125;.toMap)</span><br><span class="line">        <span class="comment">//hw更新，尝试处理请求</span></span><br><span class="line">        partitionsToMakeFollower.foreach &#123; partition =&gt;</span><br><span class="line">            <span class="keyword">val</span> topicPartitionOperationKey = <span class="keyword">new</span> <span class="type">TopicPartitionOperationKey</span>(partition.topicPartition)</span><br><span class="line">            tryCompleteDelayedProduce(topicPartitionOperationKey)</span><br><span class="line">            tryCompleteDelayedFetch(topicPartitionOperationKey)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (isShuttingDown.get()) &#123;</span><br><span class="line">            partitionsToMakeFollower.foreach &#123; partition =&gt;</span><br><span class="line">                stateChangeLogger.trace((<span class="string">&quot;Broker %d skipped the adding-fetcher step of the become-follower state change with correlation id %d from &quot;</span> +</span><br><span class="line">                                         <span class="string">&quot;controller %d epoch %d for partition %s since it is shutting down&quot;</span>).format(localBrokerId, correlationId,</span><br><span class="line">                                                                                                                     controllerId, epoch, partition.topicPartition))</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// we do not need to check if the leader exists again since this has been done at the beginning of this process</span></span><br><span class="line">            <span class="comment">// 重置fetch位置，加入Fetcher</span></span><br><span class="line">            <span class="keyword">val</span> partitionsToMakeFollowerWithLeaderAndOffset = partitionsToMakeFollower.map(partition =&gt;</span><br><span class="line">                                                                                           partition.topicPartition -&gt; <span class="type">BrokerAndInitialOffset</span>(</span><br><span class="line">                                                                                               metadataCache.getAliveBrokers.find(_.id == partition.leaderReplicaIdOpt.get).get.getBrokerEndPoint(config.interBrokerListenerName),</span><br><span class="line">                                                                                               partition.getReplica().get.logEndOffset.messageOffset)).toMap</span><br><span class="line">            replicaFetcherManager.addFetcherForPartitions(partitionsToMakeFollowerWithLeaderAndOffset)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">        <span class="keyword">val</span> errorMsg = (<span class="string">&quot;Error on broker %d while processing LeaderAndIsr request with correlationId %d received from controller %d &quot;</span> +</span><br><span class="line">                        <span class="string">&quot;epoch %d&quot;</span>).format(localBrokerId, correlationId, controllerId, epoch)</span><br><span class="line">        stateChangeLogger.error(errorMsg, e)</span><br><span class="line">        <span class="comment">// Re-throw the exception for it to be caught in KafkaApis</span></span><br><span class="line">        <span class="keyword">throw</span> e</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    partitionsToMakeFollower</span><br><span class="line">&#125;</span><br></pre></td></tr></table></div></figure>]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>二零二一年七月书单</title>
    <url>/2021/08/15/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E4%B8%83%E6%9C%88%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<p>​    这是我的第一次书单总结，希望以后每个月都能有一次书单总结将自己读过的书记录下来。</p>
<span id="more"></span>

<blockquote>
<p>📚以下书籍出现的顺序代表我对这些书的评分排序。</p>
</blockquote>

        <h3 id="《朝闻道》"   >
          <a href="#《朝闻道》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《朝闻道》" class="headerlink" title="《朝闻道》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/27191786/" >《朝闻道》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      
        <h4 id="相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长"   >
          <a href="#相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长" class="heading-link"><i class="fas fa-link"></i></a><a href="#相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长" class="headerlink" title="相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长"></a>相比于从“不知道”到“知道”，从“不知道自己不知道”到“知道自己不知道”之间的路更长</h4>
      <p>​    宇宙排险者的职责是负责排除宇宙中存在的知识的巨大发展，因为当人们获取到更多的宇宙奥秘时，对宇宙也更加危险。人类第一次触发排险者报警是因为原始人类第一次<strong>仰望星空</strong>，因为，<strong>“当生命意识到宇宙奥秘的存在时，距它最终解开这个奥秘只有一步之遥。”</strong></p>

        <h4 id="“朝闻道夕死可矣”"   >
          <a href="#“朝闻道夕死可矣”" class="heading-link"><i class="fas fa-link"></i></a><a href="#“朝闻道夕死可矣”" class="headerlink" title="“朝闻道夕死可矣”"></a>“朝闻道夕死可矣”</h4>
      <p>​    这是一句论语中的话，老刘从科幻的角度进行了解释。宇宙排险者的工作是阻止人们获取宇宙的奥秘，防止宇宙被破坏。宇宙排险者知道宇宙的奥秘，却不能告诉人类。丁仪想到了可以既能得到宇宙的终极奥秘，又不违反宇宙排险者的职责的方法：“把宇宙的终极奥秘告诉我，然后再毁灭我。”之后便有大量的顶级学者前赴后继地选择得到宇宙的奥秘然后死去。</p>
<p>​        在我看来，普通人不会参与、选择“朝闻道夕死”，是因为越是有知识的人，才会知道自己不知道什么，人们的学习过程，不是一个从“不知道”到“知道”的过程，而是一个“不知道自己不知道”到“知道自己不知道”的过程，普通人“知道自己不知道”的东西，还远到不了需要宇宙排险者来解答的程度。</p>
<p>​    但是，如果成为了顶级学者，是否又真的能选择“朝闻道夕死可矣”？</p>

        <h3 id="《你当像鸟飞往你的山》"   >
          <a href="#《你当像鸟飞往你的山》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《你当像鸟飞往你的山》" class="headerlink" title="《你当像鸟飞往你的山》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/33440205//" >《你当像鸟飞往你的山》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书讲述了一个女孩关于原生家庭的自述，在她的家里有暴力狂的哥哥、不让孩子受教育的父亲、只会听从父亲话的母亲，十七岁前从未上过学，现在却成为了剑桥大学的博士。虽然主要是作者自身经历的描写，但是作者心路历程的变化清晰可见。从作者心路历程的变化中也可以看到许多关于原生家庭的道理，这些道理在原生家庭与现实世界的冲突没有那么严重时是不容易触及的。</p>

        <h4 id="原生家庭的影响很难改变"   >
          <a href="#原生家庭的影响很难改变" class="heading-link"><i class="fas fa-link"></i></a><a href="#原生家庭的影响很难改变" class="headerlink" title="原生家庭的影响很难改变"></a>原生家庭的影响很难改变</h4>
      <p>​    作者的成长过程中，即便读书使她见到了更加广阔的世界，认识到父亲那些顽固的观点（读书不好，政府不好，医院里的医生都是恶魔等）不是正确的，但是依旧会对当下的生活持有怀疑，怀疑现在的世界是否真的如父亲所讲。</p>

        <h4 id="一个人从不好的原生家庭中走出后总是会想着帮助家人改变"   >
          <a href="#一个人从不好的原生家庭中走出后总是会想着帮助家人改变" class="heading-link"><i class="fas fa-link"></i></a><a href="#一个人从不好的原生家庭中走出后总是会想着帮助家人改变" class="headerlink" title="一个人从不好的原生家庭中走出后总是会想着帮助家人改变"></a>一个人从不好的原生家庭中走出后总是会想着帮助家人改变</h4>
      <p>​    当作者离开原生家庭，外出读书，知道了生病就应该去医院，知道到了指定年龄就应该去读书。虽然对原生家庭怀有恨意，但是仍然很想帮助他们，让他们知道什么是对的，什么是不对的，想让妹妹去上学，想让母亲不迷恋草药去相信医院。</p>

        <h4 id="相比于外界的认可，自我认可才更为重要"   >
          <a href="#相比于外界的认可，自我认可才更为重要" class="heading-link"><i class="fas fa-link"></i></a><a href="#相比于外界的认可，自我认可才更为重要" class="headerlink" title="相比于外界的认可，自我认可才更为重要"></a>相比于外界的认可，自我认可才更为重要</h4>
      <p>​    逃离原生家庭的过程中面临着种种困难，来到外面的世界后，作者会有各种不适应，自卑，格格不入的感觉，认为别人听到她的人生经历会不理解，看不起她。其实不然，真正的困难从来不是来自于外界，而是自己，自己都无法认可自己时怎么能到到外界的认可，反之，当自己可以认可自己时，外界的认可也便不再那么重要。</p>

        <h3 id="《非暴力沟通》"   >
          <a href="#《非暴力沟通》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《非暴力沟通》" class="headerlink" title="《非暴力沟通》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/26728136/" >《非暴力沟通》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书介绍了一种沟通模式，不论是表达自己还是倾听他人，都要遵循以下四个步骤：观察、感受、需要、请求。需要在平时的沟通中提醒自己，按照下面的模式进行。</p>

        <h4 id="诚实地表达自己，而不批评、指责"   >
          <a href="#诚实地表达自己，而不批评、指责" class="heading-link"><i class="fas fa-link"></i></a><a href="#诚实地表达自己，而不批评、指责" class="headerlink" title="诚实地表达自己，而不批评、指责"></a>诚实地表达自己，而不批评、指责</h4>
      <ol>
<li><p>观察我所观察（看、听、回忆、想）到的有助于（或无助于）我的福祉的具体行为：“当我（看、听、想到我看到的/听到的）……”</p>
</li>
<li><p>感受对于这些行为，我有什么样的感受（情感而非思想）：“我感到……”</p>
</li>
<li><p>需要什么样的需要或价值（而非偏好或某种具体的行为）导致我那样的感受：“因为我需要/看重……”</p>
</li>
<li><p>请求清楚地请求（而非命令）那些能丰富我生命的具体行为，“你是否愿意……？”</p>
</li>
</ol>

        <h4 id="关切地倾听他人，而不解读为批评或指责"   >
          <a href="#关切地倾听他人，而不解读为批评或指责" class="heading-link"><i class="fas fa-link"></i></a><a href="#关切地倾听他人，而不解读为批评或指责" class="headerlink" title="关切地倾听他人，而不解读为批评或指责"></a>关切地倾听他人，而不解读为批评或指责</h4>
      <ol>
<li>观察你所观察（看、听、回忆、想）到的有助于（或无助于）你的福祉的具体行为：“当你（看、听、想到你看到的/听到的）……”</li>
<li>感受对于这些行为，你有什么样的感受（是情感而非思想）：“你感到……吗？”</li>
<li>需要什么样的需要或价值（而非偏好或某种具体的行为）导致你那样的感受：“因为你需要/看重……”</li>
<li>请求关切地倾听那些能丰富你生命的具体请求，而不解读为命令：“所以，你想……”</li>
</ol>

        <h3 id="《代码整洁之道》"   >
          <a href="#《代码整洁之道》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《代码整洁之道》" class="headerlink" title="《代码整洁之道》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/34986245/" >《代码整洁之道》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    从命名规范、注释、代码规范等各个方面介绍了如果写出一份好的代码，其中有许多内容其实在实际编码过程中已经遵守，只不过自己没有意识到，没有系统化的梳理，但是也存在需要自己没有意识到的事情，比如：尽量避免在函数参数中使用布尔型变量来区分不同功能，而是要写成两个名称不同的函数。代码不只是写给自己的，除了功能正确外，可读性强也是好代码的标准，按照书上的总结进行执行，让自己的代码更好。</p>

        <h3 id="《指数基金投资指南》"   >
          <a href="#《指数基金投资指南》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《指数基金投资指南》" class="headerlink" title="《指数基金投资指南》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/27204860/" >《指数基金投资指南》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书可以算一个指数基金的科普手册，通过这本书可以了解大部分主要的指数基金类型的基本知识，并且给出一些投资方面的建议。指数基金的投资，关键还是要稳定投资，长期持有。</p>

        <h3 id="《我的第一本人生规划手册》"   >
          <a href="#《我的第一本人生规划手册》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《我的第一本人生规划手册》" class="headerlink" title="《我的第一本人生规划手册》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/35334790/" >《我的第一本人生规划手册》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书更像是一个公众号文章的合集，它会告诉你要赚钱，要规划，会告诉你什么样的目标在每个阶段应该赚得多少钱，但是并没有什么实质性的建议，每个人的实际情况并不相同，每个人需要考虑、选择、努力的事情也并不相同，重要还是自己认真的思考，然后脚踏实地好好努力。</p>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>2021书单</tag>
      </tags>
  </entry>
  <entry>
    <title>kafka日志清理引发的core dump问题</title>
    <url>/2021/08/15/kafka%E6%97%A5%E5%BF%97%E6%B8%85%E7%90%86%E5%BC%95%E5%8F%91%E7%9A%84core-dump%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<p>​    团队开发了kafka on hdfs的功能，用以将kafka数据存储在hdfs上，但是在使用的过程中发现，有机器出现core dump现象。</p>
<span id="more"></span>

<blockquote>
<p>本文基于kafka版本0.10.2</p>
</blockquote>

        <h2 id="排查过程"   >
          <a href="#排查过程" class="heading-link"><i class="fas fa-link"></i></a><a href="#排查过程" class="headerlink" title="排查过程"></a>排查过程</h2>
      
        <h3 id="一、排查core-dump文件"   >
          <a href="#一、排查core-dump文件" class="heading-link"><i class="fas fa-link"></i></a><a href="#一、排查core-dump文件" class="headerlink" title="一、排查core dump文件"></a>一、排查core dump文件</h3>
      <p>由于出现了多次core dump问题，所以首先需要从core dump文件中进行分析。从core dump文件可以看出，以下几个问题：</p>
<ol>
<li>挂掉的线程名称都是hdfs相关的，所以推测与hdfs相关功能有关</li>
<li>挂掉的代码位置都与index读取逻辑有关，所以推测和index清理逻辑有关</li>
</ol>
<p><img src="case1.png" alt="case1"></p>
<p><img src="case2.png" alt="case2"></p>

        <h3 id="二、分析代码"   >
          <a href="#二、分析代码" class="heading-link"><i class="fas fa-link"></i></a><a href="#二、分析代码" class="headerlink" title="二、分析代码"></a>二、分析代码</h3>
      <p>​    分析kafka本地日志删除的代码发现，本地日志删除通过<code>asyncDeleteSegment</code>进行，<code>asyncDeleteSegment</code>进行删除时首先会rename本地日志文件和索引文件，然后延迟一定时间进行删除。</p>
<figure class="highlight scala"><div class="table-container"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** a file that is scheduled to be deleted */</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">DeletedFileSuffix</span> = <span class="string">&quot;.deleted&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Perform an asynchronous delete on the given file if it exists (otherwise do nothing)</span></span><br><span class="line"><span class="comment">   *</span></span><br><span class="line"><span class="comment">   * @throws KafkaStorageException if the file can&#x27;t be renamed and still exists</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">asyncDeleteSegment</span></span>(segment: <span class="type">LogSegment</span>) &#123;</span><br><span class="line">    segment.changeFileSuffixes(<span class="string">&quot;&quot;</span>, <span class="type">Log</span>.<span class="type">DeletedFileSuffix</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteSeg</span></span>() &#123;</span><br><span class="line">      info(<span class="string">&quot;Deleting segment %d from log %s.&quot;</span>.format(segment.baseOffset, name))</span><br><span class="line">      segment.delete()</span><br><span class="line">    &#125;</span><br><span class="line">    scheduler.schedule(<span class="string">&quot;delete-file&quot;</span>, deleteSeg, delay = config.fileDeleteDelayMs)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">   * Change the suffix for the index and log file for this log segment</span></span><br><span class="line"><span class="comment">   */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">changeFileSuffixes</span></span>(oldSuffix: <span class="type">String</span>, newSuffix: <span class="type">String</span>) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">kafkaStorageException</span></span>(fileType: <span class="type">String</span>, e: <span class="type">IOException</span>) =</span><br><span class="line">      <span class="keyword">new</span> <span class="type">KafkaStorageException</span>(<span class="string">s&quot;Failed to change the <span class="subst">$fileType</span> file suffix from <span class="subst">$oldSuffix</span> to <span class="subst">$newSuffix</span> for log segment <span class="subst">$baseOffset</span>&quot;</span>, e)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span> log.renameTo(<span class="keyword">new</span> <span class="type">File</span>(<span class="type">CoreUtils</span>.replaceSuffix(log.file.getPath, oldSuffix, newSuffix)))</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; <span class="keyword">throw</span> kafkaStorageException(<span class="string">&quot;log&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> index.renameTo(<span class="keyword">new</span> <span class="type">File</span>(<span class="type">CoreUtils</span>.replaceSuffix(index.file.getPath, oldSuffix, newSuffix)))</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; <span class="keyword">throw</span> kafkaStorageException(<span class="string">&quot;index&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">try</span> timeIndex.renameTo(<span class="keyword">new</span> <span class="type">File</span>(<span class="type">CoreUtils</span>.replaceSuffix(timeIndex.file.getPath, oldSuffix, newSuffix)))</span><br><span class="line">    <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">IOException</span> =&gt; <span class="keyword">throw</span> kafkaStorageException(<span class="string">&quot;timeindex&quot;</span>, e)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></div></figure>

<p>​    但是在hdfs相关的清理功能中，直接进行的日志清理而没有rename和delay操作，所以推测清理日志和索引时，如果文件仍被读取，强行删除会导致core dump。</p>

        <h3 id="三、测试结论"   >
          <a href="#三、测试结论" class="heading-link"><i class="fas fa-link"></i></a><a href="#三、测试结论" class="headerlink" title="三、测试结论"></a>三、测试结论</h3>
      <p>编写单测，本地索引lookup过程中强行删除索引文件，确实出现了core dump现象。</p>

        <h2 id="解决方案"   >
          <a href="#解决方案" class="heading-link"><i class="fas fa-link"></i></a><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2>
      <p>仿照本地日志的清理策略，在hdfs相关的逻辑中，不直接删除文件，而是先rename文件，然后再延迟一定时间进行删除。</p>

        <h2 id="总结"   >
          <a href="#总结" class="heading-link"><i class="fas fa-link"></i></a><a href="#总结" class="headerlink" title="总结"></a>总结</h2>
      <ol>
<li>本次问题的出现属于偶发现象，只有在kafka consumer消费lag，读取即将被删除的日志时才有可能会发生。</li>
<li>core dump问题分析的过程中需要通过多个case的相似点来分析问题。</li>
</ol>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>kafka</tag>
        <tag>问题排查</tag>
      </tags>
  </entry>
  <entry>
    <title>二零二一年八月书单</title>
    <url>/2021/08/28/%E4%BA%8C%E9%9B%B6%E4%BA%8C%E4%B8%80%E5%B9%B4%E5%85%AB%E6%9C%88%E4%B9%A6%E5%8D%95/</url>
    <content><![CDATA[<p>第二篇书单如期而至。</p>
<span id="more"></span>

<blockquote>
<p>📚以下书籍出现的顺序代表我对这些书的评分排序。</p>
</blockquote>

        <h3 id="《蛤蟆先生去看心理医生》"   >
          <a href="#《蛤蟆先生去看心理医生》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《蛤蟆先生去看心理医生》" class="headerlink" title="《蛤蟆先生去看心理医生》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/35143790/" >《蛤蟆先生去看心理医生》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    一本以寓言故事的形式讲心理学的书，这个寓言故事并不是讲给孩子的，而是讲给大人的。书中提到了一组很有意思的概念：</p>
<ol>
<li>儿童自我状态：“孩子是成年人的父亲”，其实人们成年后的很多思维方式和行为方式都是孩子时的写照。</li>
<li>父母自我状态：成年后的思维方式和行为方式以模仿自己的父母进行。</li>
<li>成人自我状态：指我们用理性而不是情绪化的方式行事。</li>
</ol>
<p>​    反思自己和周围的人，会发现确实会有处于儿童状态，或者父母状态的情况，毕竟一方面无法抛弃自己的过往，另一方面父母又是孩子的老师。之所以处于这两种状态，是因为儿童和父母状态是不需要思考的，自己的思维或者行为就像是表演，表演自己所熟悉的东西。但同时，这两种状态又是最差的，因为没有思考就不会学习。只有处于成人状态下，我们才能够进行学习，才能应对此时正在发生的现实状况。</p>
<p>​    我们生活的样子就是我们自己想成为的样子，而不是别人造就了我们的生活。要想更幸福，就需要有足够的情商。情商真正的意思是：了解你内心的情感世界并且还能掌控它。</p>

        <h3 id="《牧羊少年的奇幻之旅》"   >
          <a href="#《牧羊少年的奇幻之旅》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《牧羊少年的奇幻之旅》" class="headerlink" title="《牧羊少年的奇幻之旅》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/3608208/" >《牧羊少年的奇幻之旅》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    一本奇幻的书，此处借用豆瓣网友Big Ben的短评：“《小王子》教你放下执念，而《牧羊少年奇幻之旅》是教你寻找执念；两种不同的方法，确有着相同的目的。重点不是你在这个世界上寻找什么，而是在过程中明白什么是不可丢弃的，那将是你生命的意义所在，超越一切，一旦了白于心，就将于永恒同在。”</p>
<p>​    不要放弃自己的“执念”，需要向其前进。现在的生活中，在一无所有时，可能会怀着有钱之后周游世界的梦想，但是在足够富有之后，因为会渴望更加富有，或者因为害怕风险，只选择相比周游世界更加平稳的享受当下的幸福。前进的过程中，可能会有很多的收获，甚至到达大众所谓的成功，但是这本书要说的不是前进过程中的收获，而是收获到这些附加东西之后，仍然不要忘记自己的“执念”，为了不让自己在看似优渥的生活中留下遗憾，也为了“执念”实现之后意义。</p>
<p>​    用书中不断重复的一个阿拉伯语来总结和思考：<strong>“马克图布”</strong>，可以理解为：命中注定。</p>

        <h3 id="《心流》"   >
          <a href="#《心流》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《心流》" class="headerlink" title="《心流》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/27186106/" >《心流》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书的序言确实挺长的，不到400页的书，序言就有50多页🐶。“心流”是积极心理学中的重要概念，是指我们在做某些事情时，那种全神贯注、投入忘我的状态——这种状态下，你甚至感觉不到时间的存在，在这件事情完成之后我们会有一种充满能量并且非常满足的感受。在我们的正常生活中，每个人都会有心流体验，只是多与少的区别，比如：中学上电脑课玩游戏时🐶、没有杂事干扰只有自己一个人专心写代码时🐶。这本书讲的是如何让自己尽可能多得体验心流，下面是一些书中观点的笔记：</p>
<ul>
<li>大部分人的心流体验来自于工作而非休息。</li>
<li>享乐与乐趣不同，享乐不需要消耗精神能量，而乐趣需要。</li>
<li>竞争只有在它以使个人技巧臻于完美为目标时，才有乐趣；当它本身成为目的时，就不再有乐趣了。</li>
<li>记忆的重要性：记忆足够充足的人，可以不需要外界刺激而保持心流。</li>
<li>未来不仅属于受过教育的人，更属于那些懂得善用闲暇的人。</li>
<li>培养自得其乐的性格：确立目标、全神贯注、避免过于自我、从当前体验中寻找乐趣。</li>
</ul>

        <h3 id="《政治是什么？》"   >
          <a href="#《政治是什么？》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《政治是什么？》" class="headerlink" title="《政治是什么？》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/26644832/" >《政治是什么？》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这是一本台湾人写的政治普及书籍。这本书对政治中的各种概念进行介绍，并且从作者的角度，结合各种观点进行了客观的分析。作者的表达中不会带着对哪种政治制度的偏见，读这本书的过程确实可以引发自己一些关于政治知识的思考，但是却感觉缺乏主线。下面只列举一些我在读书过程中思考记录的想法：</p>
<ul>
<li>政治是可以在违背他人意愿的情况下实现自己目的的可能性，分为“强制性权力”（例如：武力）和“象征性权力”（例如：信仰），相比强制性权力，象征性权力更会让人们潜意识服从，更不容易反抗推翻。</li>
<li>意识形态可以决定人们是否接受你成为领袖，而能否真正满足人们的需求才是决定你是否可以一直成为领袖的因素。因此，稳固的政治不仅需要一个好的意识形态（借口），还需要让人们感受到自己需求得到满足。</li>
<li>国家并不能称为实体，甚至是一个模糊的概念，比如古代各个国家之间并没有绝对明确的地理划分，也不需要签证。之所以现在这一切变得复杂，是因为各个国家之间的交流过于紧密，如果没有明确的边界感，就会产生争端，为了明确边界感，一个国家需要拥有被其他国家承认的“主权”，如：一个国家的居民必须要有户口等。为什么人不需要说我承认你是人，你才是人？而国家必须要拥有被其他国家承认的主权才是国家？因为人本来就是一个实体，有明确的边界感，而国家本身并非实体，而是一种概念，必须有各种条条框框才能被理解为实体。</li>
</ul>

        <h3 id="《什么是民粹主义？》"   >
          <a href="#《什么是民粹主义？》" class="heading-link"><i class="fas fa-link"></i></a><a href="#《什么是民粹主义？》" class="headerlink" title="《什么是民粹主义？》"></a><span class="exturl"><a class="exturl__link"   href="https://book.douban.com/subject/34879976/" >《什么是民粹主义？》</a><span class="exturl__icon"><i class="fas fa-external-link-alt"></i></span></span></h3>
      <p>​    这本书感觉像是一本表达作者本人政治观点的书籍，可能由于我政治知识不够，并没有兴趣读完整本书，只能依照自己的感觉描述一下对这本书的理解。</p>
<p>​    根据维基百科的解释，民粹主义通常是精英主义的反义词。在古希腊城邦发明民主制度之后，对于应由精英、贵族还是一般大众来掌握政治，出现了争论。支持民粹主义者则诉求直接民主与基层民主，认为政治精英（当下或未来）只追求自身利益，腐化且不可相信，希望由人民直接决定政治事务。</p>
<p>​    这本书作者认为，民粹主义者的本质不是反精英、反多元化、反建制等等，而是对“人民”的定义，民粹主义者们一方面认为只有他们才能代表人民的利益，另一方面又认为只有支持他们的人才算做“人民”，可谓是假民主、真偏见。</p>
<hr>
<p>​    从《你当像鸟飞往你的山》、《蛤蟆先生去看心理医生》和《心流》三本书中都可以看到掌握自己的重要性。了解自己，接纳他人，可以控制自己的情感和思维不被外界干扰，同时又可以完全平和地接纳他人的观点，这是一种很强大的能力，感觉自己现在远远不及，也是自己心理上努力的方向。</p>
]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>2021书单</tag>
      </tags>
  </entry>
</search>
